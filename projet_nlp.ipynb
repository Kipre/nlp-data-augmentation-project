{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "projet-nlp",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3c8cc5ea37c3469c89f162eadbcc9625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d05f34a1f15c44d1a1c69eeb52ce9404",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0b50dd2c31dd4976a97c226f1fb57a24",
              "IPY_MODEL_7c5b2bbcabe44f02a77f7e42596ab08f"
            ]
          }
        },
        "d05f34a1f15c44d1a1c69eeb52ce9404": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b50dd2c31dd4976a97c226f1fb57a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_239160f5bf3944968a5ac7627dea5e52",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 810912,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 810912,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80d2816c548d4a68afa82d5acd1c25a4"
          }
        },
        "7c5b2bbcabe44f02a77f7e42596ab08f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e00e334251f5424eab652ef0938e26c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 811k/811k [00:00&lt;00:00, 3.46MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bf87913230ae46eea16b9430e12c3bb5"
          }
        },
        "239160f5bf3944968a5ac7627dea5e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80d2816c548d4a68afa82d5acd1c25a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e00e334251f5424eab652ef0938e26c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bf87913230ae46eea16b9430e12c3bb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ab14eb80725f464eafa2fc10af34470b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c61b3d3821b54d1298b2a55a35bddfea",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f0d527e6ac6d4808a02f9689b01eb720",
              "IPY_MODEL_6865eaa7df2a484e8feec540745aeeec"
            ]
          }
        },
        "c61b3d3821b54d1298b2a55a35bddfea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0d527e6ac6d4808a02f9689b01eb720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_26dab97e4c9a458085e4554972b723e6",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 596,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 596,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22c4482304214808a41295240e661303"
          }
        },
        "6865eaa7df2a484e8feec540745aeeec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_73bf557fbf7146959ef034297cf7a7c5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 596/596 [00:00&lt;00:00, 16.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0adf48767da8488fa13830d36a3ac875"
          }
        },
        "26dab97e4c9a458085e4554972b723e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22c4482304214808a41295240e661303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73bf557fbf7146959ef034297cf7a7c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0adf48767da8488fa13830d36a3ac875": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ce1052989d248cda1531391eee323bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_285e22de0e784210abcdd338213c4654",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3459863140774c36b5ed1138c2dd801b",
              "IPY_MODEL_84a1efd9fb3943a7bcb0ae7668dbf092"
            ]
          }
        },
        "285e22de0e784210abcdd338213c4654": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3459863140774c36b5ed1138c2dd801b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_03ec8d53b9044c4d91ab54b7518b19b6",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 445032417,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 445032417,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c52aebf9149146f2a3e693c933ace407"
          }
        },
        "84a1efd9fb3943a7bcb0ae7668dbf092": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_289393650a464d1ba02bc3d3876414b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 445M/445M [00:07&lt;00:00, 60.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5d5ae1d9cd74459a8489ea7509cea6b"
          }
        },
        "03ec8d53b9044c4d91ab54b7518b19b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c52aebf9149146f2a3e693c933ace407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "289393650a464d1ba02bc3d3876414b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5d5ae1d9cd74459a8489ea7509cea6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij6fgwf0A-TJ",
        "colab_type": "text"
      },
      "source": [
        "# NLP Data augmantation project \n",
        "\n",
        "This notebook presents some different services to use a backtranslation approach for aumenting data for NLP tasks.\n",
        "\n",
        "__Warning:__ there are a few directories pointing to a private drive account but they can be easily changed to reproduce the work. API keys are not provided here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Tbe8GyFBDo5",
        "colab_type": "text"
      },
      "source": [
        "## Importing initial data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKJ5iwgB9VKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0970aeca-933e-430d-80d6-6a74129f2a5b"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/project_codebase/project/data/requests.csv', sep=';')\n",
        "demandes = data['demande']\n",
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>demande</th>\n",
              "      <th>motif</th>\n",
              "      <th>groupe_motif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>je viens enregistrer mon bac</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>je viens de pardon je viens pour dÃ©poser un do...</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>je souhaite enregistrer une convention de PACS...</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bonjour je viens pour un enregistrement de PACS</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>je souhaite enregistrer une convention de pact...</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1183</th>\n",
              "      <td>nous souhaitons annuler notre pacte civil de s...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1184</th>\n",
              "      <td>je viens de dÃ©poser mon dossier de PACS</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1185</th>\n",
              "      <td>je me PACS</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>je souhaite modifier mon contrat PACS</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1187</th>\n",
              "      <td>je souhaite faire dissoudre mon pacte civil de...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1188 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                demande  ...                                     groupe_motif\n",
              "0                          je viens enregistrer mon bac  ...             01c - Etat Civil PACS Enregistrement\n",
              "1     je viens de pardon je viens pour dÃ©poser un do...  ...             01c - Etat Civil PACS Enregistrement\n",
              "2     je souhaite enregistrer une convention de PACS...  ...             01c - Etat Civil PACS Enregistrement\n",
              "3       bonjour je viens pour un enregistrement de PACS  ...             01c - Etat Civil PACS Enregistrement\n",
              "4     je souhaite enregistrer une convention de pact...  ...             01c - Etat Civil PACS Enregistrement\n",
              "...                                                 ...  ...                                              ...\n",
              "1183  nous souhaitons annuler notre pacte civil de s...  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "1184            je viens de dÃ©poser mon dossier de PACS  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "1185                                         je me PACS  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "1186              je souhaite modifier mon contrat PACS  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "1187  je souhaite faire dissoudre mon pacte civil de...  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "\n",
              "[1188 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Mi5uuUf4T0",
        "colab_type": "text"
      },
      "source": [
        "## Back translation with Yandex"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5EbSRFjYbmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "api = 'https://translate.yandex.net/api/v1.5/tr.json/translate'\n",
        "key = '<Your API key>'\n",
        "\n",
        "languages = ['en', 'es', 'ru', 'de', 'ar', 'it'] # , 'ja', 'ca', 'zh'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBajDhGS9P2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "result = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbK_lnEXgBkt",
        "colab_type": "code",
        "outputId": "7182b766-2ee7-4604-a517-d5407b9bc5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "for i, request in demandes.loc[1168:].iteritems():\n",
        "    for lang in languages:\n",
        "        text = request\n",
        "        lang, back = f'fr-{lang}', f'{lang}-fr'\n",
        "\n",
        "        r = requests.post(api, data={'key':key,\n",
        "                                     'text':text,\n",
        "                                    'lang':lang})\n",
        "        answer = json.loads(r.text)\n",
        "        if answer['code'] != 200:\n",
        "            print(answer)\n",
        "        translated_text = answer['text'][0]\n",
        "\n",
        "        r = requests.post(api, data={'key':key,\n",
        "                                    'text':translated_text,\n",
        "                                    'lang':back})\n",
        "        answer = json.loads(r.text)\n",
        "        if answer['code'] != 200:\n",
        "            print(answer)\n",
        "        final = answer['text'][0]\n",
        "        result.append([i, final])\n",
        "    print(i)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1168\n",
            "1169\n",
            "1170\n",
            "1171\n",
            "1172\n",
            "1173\n",
            "1174\n",
            "1175\n",
            "1176\n",
            "1177\n",
            "1178\n",
            "1179\n",
            "1180\n",
            "1181\n",
            "1182\n",
            "1183\n",
            "1184\n",
            "1185\n",
            "1186\n",
            "1187\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZQumCIPeZ7D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "augmented = pd.DataFrame(result, columns=['corresponding_example_id', 'generated'])\n",
        "# augmented.to_csv('/content/drive/My Drive/project_codebase/project/generated_yandex.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74NcWsqxP7V0",
        "colab_type": "text"
      },
      "source": [
        "## Back translation with Azure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWTvy-54P5zv",
        "colab_type": "code",
        "outputId": "864204f5-bf29-4723-92eb-5ef8bc24ee4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import requests, uuid, json\n",
        "\n",
        "subscription_key = '<Your API key>'\n",
        "endpoint = '<Your endpoint>'\n",
        "\n",
        "path = '/translate?api-version=3.0'\n",
        "params = '&to=de&to=it'\n",
        "constructed_url = endpoint + path + params\n",
        "\n",
        "headers = {\n",
        "    'Ocp-Apim-Subscription-Key': subscription_key,\n",
        "    'Content-type': 'application/json',\n",
        "    'X-ClientTraceId': str(uuid.uuid4())\n",
        "}\n",
        "\n",
        "# You can pass more than one object in body.\n",
        "body = [{\n",
        "    'text' : 'Hello World!'\n",
        "}]\n",
        "request = requests.post(constructed_url, headers=headers, json=body)\n",
        "# response = request.json()\n",
        "\n",
        "# print(json.dumps(response, sort_keys=True, indent=4, separators=(',', ': ')))\n",
        "print(request.text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"error\":{\"code\":\"404\",\"message\": \"Resource not found\"}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CaNk00Fo5OS",
        "colab_type": "text"
      },
      "source": [
        "## Backtranslation with Goslate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSg0MXx9o4ui",
        "colab_type": "code",
        "outputId": "5c1d6fa9-8087-4e25-c247-1e043f62caf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        }
      },
      "source": [
        "pip install goslate"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting goslate\n",
            "  Downloading https://files.pythonhosted.org/packages/39/0b/50af938a1c3d4f4c595b6a22d37af11ebe666246b05a1a97573e8c8944e5/goslate-1.5.1.tar.gz\n",
            "Collecting futures\n",
            "  Downloading https://files.pythonhosted.org/packages/05/80/f41cca0ea1ff69bce7e7a7d76182b47bb4e1a494380a532af3e8ee70b9ec/futures-3.1.1-py3-none-any.whl\n",
            "Building wheels for collected packages: goslate\n",
            "  Building wheel for goslate (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for goslate: filename=goslate-1.5.1-cp36-none-any.whl size=11550 sha256=ffa17e20011a127799035cca55e239a353593a047eb978461ce7242d346a7853\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/7f/28/6f52271012a7649b54b1a7adaae329b4246bbbf9d1e4f6e51a\n",
            "Successfully built goslate\n",
            "Installing collected packages: futures, goslate\n",
            "Successfully installed futures-3.1.1 goslate-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdq1iaxJo3dl",
        "colab_type": "code",
        "outputId": "606d9646-12c7-4967-e97d-3e09ac200bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "import goslate\n",
        "import pandas as pd\n",
        "import sys\n",
        "import time\n",
        "\n",
        "translator = goslate.Goslate()\n",
        "d = pd.read_csv(\"/content/drive/My Drive/project_codebase/project/data/requests.csv\", sep=';')\n",
        "classes = d['motif'].unique()\n",
        "langs= ['en', 'es', 'de', 'ru', 'ar', 'it', 'ja', 'ca', 'zh']\n",
        "for cl in classes:\n",
        "\tdi = d.loc[d['motif']==cl]\n",
        "\tdi = di['demande'].values.tolist()\n",
        "\t# print(\"class : {}\".format(cl), file=sys.stderr)\n",
        "\tfor l in langs:\n",
        "\t\t# print(\"lang = {}\".format(l), file=sys.stderr)\n",
        "\t\tinter = translator.translate(di, l)\n",
        "\t\tres = translator.translate(inter, 'fr')\n",
        "\t\tfor x in res:\n",
        "\t\t\tprint(\"{};{}\".format(x, cl), file='results.csv')\n",
        "\t\ttime.sleep(5)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "HTTPError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-245e7d961e43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0minter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m                         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{};{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'results.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         return (_unwrapper_single_element(i) for i in\n\u001b[0m\u001b[1;32m    442\u001b[0m                 itertools.chain.from_iterable(self._execute(make_task(i) for i in join_texts(text))))\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfirst_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MIN_TASKS_FOR_CONCURRENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mfirst_tasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_MIN_TASKS_FOR_CONCURRENT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_tasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         return (_unwrapper_single_element(i) for i in\n\u001b[0;32m--> 442\u001b[0;31m                 itertools.chain.from_iterable(self._execute(make_task(i) for i in join_texts(text))))\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36mjoin_texts\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_utf8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m                 \u001b[0mnew_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUTF8_JOINT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36mconvert_to_utf8\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mjoin_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_utf8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         return (_unwrapper_single_element(i) for i in\n\u001b[0m\u001b[1;32m    442\u001b[0m                 itertools.chain.from_iterable(self._execute(make_task(i) for i in join_texts(text))))\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36mtask\u001b[0;34m()\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmake_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_translate_single_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m                 \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJOINT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mizip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_translate_single_text\u001b[0;34m(self, text, target_language, source_lauguage)\u001b[0m\n\u001b[1;32m    332\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basic_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lauguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_writing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_execute\u001b[0;34m(self, tasks)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfirst_tasks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtasks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0meach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mmake_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_basic_translate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_language\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_lauguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msplit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_basic_translate\u001b[0;34m(self, text, target_language, source_language)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0murl\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'&dt=rm'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0mresponse_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_empty_comma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'\\xA0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[,'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'[1,'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'src'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_open_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrentThread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'Connection reset by peer'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m                 \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/goslate.py\u001b[0m in \u001b[0;36m_open_url\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RETRY_TIMES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_TIMEOUT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m                 \u001b[0mresponse_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_DEBUG\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 642\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    502\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    505\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 429: Too Many Requests"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4FxxuxlRibZ",
        "colab_type": "text"
      },
      "source": [
        "## Augmented data\n",
        "\n",
        "Putting the dataset back together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ieXtZZ6Prkz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "f8bb12bb-40e4-46e6-f979-a8e412088c13"
      },
      "source": [
        "generated = pd.read_csv('/content/drive/My Drive/project_codebase/project/generated_yandex.csv')\n",
        "initial = pd.read_csv('/content/drive/My Drive/project_codebase/project/data/requests.csv', sep=';').reset_index()\n",
        "initial.rename(columns={'index': 'corresponding_example_id'}, inplace=True)\n",
        "generated = generated.join(initial, on='corresponding_example_id', lsuffix='0')\n",
        "generated.drop(['corresponding_example_id0', 'corresponding_example_id'], axis=1, inplace=True)\n",
        "generated.rename(columns={'demande':'demande_originale', 'generated':'demande'}, inplace=True)\n",
        "generated"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>demande</th>\n",
              "      <th>demande_originale</th>\n",
              "      <th>motif</th>\n",
              "      <th>groupe_motif</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Je viens de sauver mon rÃ©servoir</td>\n",
              "      <td>je viens enregistrer mon bac</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Je viens juste de garder mon dÃ©pÃ´t</td>\n",
              "      <td>je viens enregistrer mon bac</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>je viens d'enregistrer mon bac</td>\n",
              "      <td>je viens enregistrer mon bac</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>je viens d'enregistrer mon aquarium</td>\n",
              "      <td>je viens enregistrer mon bac</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Je ne sauvegarde que le rÃ©servoir</td>\n",
              "      <td>je viens enregistrer mon bac</td>\n",
              "      <td>Enregistrement de PACS</td>\n",
              "      <td>01c - Etat Civil PACS Enregistrement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7123</th>\n",
              "      <td>Je veux dissoudre mon pacte civil de solidaritÃ©</td>\n",
              "      <td>je souhaite faire dissoudre mon pacte civil de...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7124</th>\n",
              "      <td>je voudrais, pour dissoudre mon pacte civil de...</td>\n",
              "      <td>je souhaite faire dissoudre mon pacte civil de...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7125</th>\n",
              "      <td>je veux rÃ©soudre mon pacte civil de solidaritÃ©</td>\n",
              "      <td>je souhaite faire dissoudre mon pacte civil de...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7126</th>\n",
              "      <td>Je veux que ma solution de la Charte de civil ...</td>\n",
              "      <td>je souhaite faire dissoudre mon pacte civil de...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7127</th>\n",
              "      <td>Je veux dissoudre mon pacte de solidaritÃ©</td>\n",
              "      <td>je souhaite faire dissoudre mon pacte civil de...</td>\n",
              "      <td>PACS (DÃ©pÃ´t de dossier, modification ou dissol...</td>\n",
              "      <td>01d - Etat Civil PACS Modification, dissolution</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7128 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                demande  ...                                     groupe_motif\n",
              "0                      Je viens de sauver mon rÃ©servoir  ...             01c - Etat Civil PACS Enregistrement\n",
              "1                    Je viens juste de garder mon dÃ©pÃ´t  ...             01c - Etat Civil PACS Enregistrement\n",
              "2                        je viens d'enregistrer mon bac  ...             01c - Etat Civil PACS Enregistrement\n",
              "3                   je viens d'enregistrer mon aquarium  ...             01c - Etat Civil PACS Enregistrement\n",
              "4                     Je ne sauvegarde que le rÃ©servoir  ...             01c - Etat Civil PACS Enregistrement\n",
              "...                                                 ...  ...                                              ...\n",
              "7123    Je veux dissoudre mon pacte civil de solidaritÃ©  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "7124  je voudrais, pour dissoudre mon pacte civil de...  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "7125     je veux rÃ©soudre mon pacte civil de solidaritÃ©  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "7126  Je veux que ma solution de la Charte de civil ...  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "7127          Je veux dissoudre mon pacte de solidaritÃ©  ...  01d - Etat Civil PACS Modification, dissolution\n",
              "\n",
              "[7128 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBGyyWQkEgIy",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation\n",
        "\n",
        "The evaluation is done by commenting and uncommenting some lines so that the `dev.txt` and `test.txt` always remain the same and `train.txt` change according to the data provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XIReLzEEkx1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "2ca189aa-937f-492f-90a6-ae021e290d5e"
      },
      "source": [
        "from os import path\n",
        "\n",
        "import os\n",
        "import numpy\n",
        "import pandas\n",
        "corpus_path = \"corpus_splits/\"\n",
        "if not path.exists(corpus_path):\n",
        "    os.mkdir(corpus_path)\n",
        "\n",
        "#Loading dataset\n",
        "# df = pandas.read_csv(\"/content/drive/My Drive/project_codebase/project/data/requests.csv\", sep=\";\")\n",
        "df = generated\n",
        "df = df[[\"motif\", \"demande\"]]\n",
        "df[\"motif\"] = \"__label__\" + df[\"motif\"].astype(\"str\")\n",
        "df[\"motif\"] = df[\"motif\"].str.replace(\" \",\"_\",regex=False)\n",
        "\n",
        "# Number of splits\n",
        "num_splits = 10\n",
        "\n",
        "\n",
        "for split in range(num_splits):\n",
        "    base_path = corpus_path + \"split_\" + str(split)\n",
        "    if not path.exists(base_path):\n",
        "        os.mkdir(base_path)\n",
        "\n",
        "    train, test, dev = numpy.split(df.sample(frac=1), [int(.7 * len(df)), int(.9 * len(df))])  # type: # DataFrame\n",
        "\n",
        "    train.to_csv(base_path + \"/train.txt\", index=False, sep=\"\\t\", header=False)\n",
        "    # test.to_csv(base_path + \"/test.txt\", index=False, sep=\"\\t\", header=False)\n",
        "    # dev.to_csv(base_path + \"/dev.txt\", index=False, sep=\"\\t\", header=False)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4J1N6x1Gqhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZd5maN5narQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4a0944d-5b16-420c-c085-3a3f0cd1dae8"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ClassificationCorpus\n",
        "from flair.embeddings import CamembertEmbeddings, DocumentRNNEmbeddings\n",
        "from flair.models import TextClassifier\n",
        "from flair.trainers import ModelTrainer\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from torch.optim import Adam\n",
        "import numpy as np"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mz6-sNgGVQt",
        "colab_type": "code",
        "outputId": "d8fde17d-8cd1-4bd6-8ac1-6f36493e8db5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3c8cc5ea37c3469c89f162eadbcc9625",
            "d05f34a1f15c44d1a1c69eeb52ce9404",
            "0b50dd2c31dd4976a97c226f1fb57a24",
            "7c5b2bbcabe44f02a77f7e42596ab08f",
            "239160f5bf3944968a5ac7627dea5e52",
            "80d2816c548d4a68afa82d5acd1c25a4",
            "e00e334251f5424eab652ef0938e26c8",
            "bf87913230ae46eea16b9430e12c3bb5",
            "ab14eb80725f464eafa2fc10af34470b",
            "c61b3d3821b54d1298b2a55a35bddfea",
            "f0d527e6ac6d4808a02f9689b01eb720",
            "6865eaa7df2a484e8feec540745aeeec",
            "26dab97e4c9a458085e4554972b723e6",
            "22c4482304214808a41295240e661303",
            "73bf557fbf7146959ef034297cf7a7c5",
            "0adf48767da8488fa13830d36a3ac875",
            "7ce1052989d248cda1531391eee323bc",
            "285e22de0e784210abcdd338213c4654",
            "3459863140774c36b5ed1138c2dd801b",
            "84a1efd9fb3943a7bcb0ae7668dbf092",
            "03ec8d53b9044c4d91ab54b7518b19b6",
            "c52aebf9149146f2a3e693c933ace407",
            "289393650a464d1ba02bc3d3876414b8",
            "c5d5ae1d9cd74459a8489ea7509cea6b"
          ]
        }
      },
      "source": [
        "data_folder = 'corpus_splits/'\n",
        "\n",
        "# column format indicating which columns hold the text and label(s)\n",
        "column_name_map = {1: \"text\", 2: \"label_topic\", }\n",
        "\n",
        "# Camembert\n",
        "camembert = CamembertEmbeddings(layers=\"-1,-2,-3,-4\")\n",
        "\n",
        "embedding_list = [camembert]\n",
        "\n",
        "# Document embedding model\n",
        "document_embeddings = DocumentRNNEmbeddings(embedding_list, hidden_size=750, bidirectional=True,\n",
        "                                            rnn_layers=2,\n",
        "                                            rnn_type='GRU',\n",
        "                                            dropout=0.4,\n",
        "                                            word_dropout=0.1)\n",
        "results = []\n",
        "\n",
        "# 10-fold cross validation\n",
        "for root, dirs, files in os.walk(data_folder):\n",
        "    for dir in dirs:\n",
        "        if \"split\" in dir:\n",
        "            print(\"Processing \" + dir + \" ...\")\n",
        "            corpus: Corpus = ClassificationCorpus(data_folder + \"/\" + dir,\n",
        "                                                  test_file='test.txt',\n",
        "                                                  dev_file='dev.txt',\n",
        "                                                  train_file='train.txt', in_memory=True)\n",
        "\n",
        "            classifier = TextClassifier(document_embeddings, label_dictionary=corpus.make_label_dictionary(),\n",
        "                                        multi_label=False)\n",
        "            trainer = ModelTrainer(classifier, corpus)\n",
        "            model_path = data_folder + \"/\" + dir + \"/model/\"\n",
        "            scores = trainer.train(model_path, max_epochs=10,\n",
        "                                   embeddings_storage_mode=\"cpu\",\n",
        "                                   learning_rate=0.3,\n",
        "                                   mini_batch_size=32,\n",
        "                                   anneal_factor=0.5,\n",
        "                                   shuffle=False,\n",
        "                                   patience=5, save_final_model=False, anneal_with_restarts=False)\n",
        "            expected = [sentence.labels[0].value for sentence in corpus.test.sentences]\n",
        "            predictions = [sentence.labels[0].value for sentence in classifier.predict(corpus.test.sentences)]\n",
        "            scores['test_f1'] = f1_score(expected, predictions, average='micro')\n",
        "            results.append(scores)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c8cc5ea37c3469c89f162eadbcc9625",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=810912, style=ProgressStyle(description_widâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab14eb80725f464eafa2fc10af34470b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=596, style=ProgressStyle(description_width=â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ce1052989d248cda1531391eee323bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=445032417, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Processing split_4 ...\n",
            "2020-02-16 18:43:15,643 Reading data from corpus_splits/split_4\n",
            "2020-02-16 18:43:15,644 Train: corpus_splits/split_4/train.txt\n",
            "2020-02-16 18:43:15,644 Dev: corpus_splits/split_4/dev.txt\n",
            "2020-02-16 18:43:15,646 Test: corpus_splits/split_4/test.txt\n",
            "2020-02-16 18:43:16,285 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4965/4965 [00:00<00:00, 276858.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:43:16,313 [b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Recensement_des_jeunes', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'Livret_de_famille', b'Mariage', b'Renseignements,_modification_de_dossier', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'explication_r\\xc3\\xa9gularisation_des_charges', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b\"demandes_d'attestations_diverses\", b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'Enregistrement_de_PACS', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)']\n",
            "2020-02-16 18:43:16,323 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:43:16,326 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 18:43:16,328 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:43:16,329 Corpus: \"Corpus: 4965 train + 119 dev + 237 test sentences\"\n",
            "2020-02-16 18:43:16,331 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:43:16,335 Parameters:\n",
            "2020-02-16 18:43:16,336  - learning_rate: \"0.3\"\n",
            "2020-02-16 18:43:16,343  - mini_batch_size: \"32\"\n",
            "2020-02-16 18:43:16,344  - patience: \"5\"\n",
            "2020-02-16 18:43:16,345  - anneal_factor: \"0.5\"\n",
            "2020-02-16 18:43:16,345  - max_epochs: \"10\"\n",
            "2020-02-16 18:43:16,346  - shuffle: \"False\"\n",
            "2020-02-16 18:43:16,347  - train_with_dev: \"False\"\n",
            "2020-02-16 18:43:16,348  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 18:43:16,348 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:43:16,349 Model training base path: \"corpus_splits/split_4/model\"\n",
            "2020-02-16 18:43:16,350 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:43:16,350 Device: cuda:0\n",
            "2020-02-16 18:43:16,351 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:43:16,352 Embeddings storage mode: cpu\n",
            "2020-02-16 18:43:16,354 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:43:24,081 epoch 1 - iter 15/156 - loss 3.96433117 - samples/sec: 62.15\n",
            "2020-02-16 18:43:32,155 epoch 1 - iter 30/156 - loss 3.68901490 - samples/sec: 60.40\n",
            "2020-02-16 18:43:40,058 epoch 1 - iter 45/156 - loss 3.58013620 - samples/sec: 62.06\n",
            "2020-02-16 18:43:48,066 epoch 1 - iter 60/156 - loss 3.45231233 - samples/sec: 60.83\n",
            "2020-02-16 18:43:55,916 epoch 1 - iter 75/156 - loss 3.35290138 - samples/sec: 62.19\n",
            "2020-02-16 18:44:03,714 epoch 1 - iter 90/156 - loss 3.18601061 - samples/sec: 62.56\n",
            "2020-02-16 18:44:11,479 epoch 1 - iter 105/156 - loss 3.05470355 - samples/sec: 62.66\n",
            "2020-02-16 18:44:19,222 epoch 1 - iter 120/156 - loss 2.97526700 - samples/sec: 62.85\n",
            "2020-02-16 18:44:26,844 epoch 1 - iter 135/156 - loss 2.89168438 - samples/sec: 64.11\n",
            "2020-02-16 18:44:34,723 epoch 1 - iter 150/156 - loss 2.79264000 - samples/sec: 61.94\n",
            "2020-02-16 18:44:37,590 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:44:37,591 EPOCH 1 done: loss 2.7549 - lr 0.3000\n",
            "2020-02-16 18:44:39,466 DEV : loss 1.7703068256378174 - score 0.5714\n",
            "2020-02-16 18:44:39,473 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:44:41,326 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:44:42,606 epoch 2 - iter 15/156 - loss 1.88130391 - samples/sec: 376.34\n",
            "2020-02-16 18:44:43,854 epoch 2 - iter 30/156 - loss 1.71538039 - samples/sec: 422.50\n",
            "2020-02-16 18:44:45,244 epoch 2 - iter 45/156 - loss 1.60992405 - samples/sec: 382.14\n",
            "2020-02-16 18:44:46,539 epoch 2 - iter 60/156 - loss 1.53336796 - samples/sec: 403.03\n",
            "2020-02-16 18:44:47,763 epoch 2 - iter 75/156 - loss 1.50632733 - samples/sec: 432.93\n",
            "2020-02-16 18:44:49,060 epoch 2 - iter 90/156 - loss 1.48027512 - samples/sec: 412.91\n",
            "2020-02-16 18:44:50,389 epoch 2 - iter 105/156 - loss 1.45458695 - samples/sec: 402.29\n",
            "2020-02-16 18:44:51,729 epoch 2 - iter 120/156 - loss 1.44067638 - samples/sec: 399.26\n",
            "2020-02-16 18:44:53,019 epoch 2 - iter 135/156 - loss 1.43620685 - samples/sec: 406.76\n",
            "2020-02-16 18:44:54,335 epoch 2 - iter 150/156 - loss 1.39950680 - samples/sec: 406.03\n",
            "2020-02-16 18:44:54,894 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:44:54,894 EPOCH 2 done: loss 1.3997 - lr 0.3000\n",
            "2020-02-16 18:44:55,027 DEV : loss 1.796176552772522 - score 0.6471\n",
            "2020-02-16 18:44:55,032 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:44:56,920 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:44:58,219 epoch 3 - iter 15/156 - loss 1.21997126 - samples/sec: 373.91\n",
            "2020-02-16 18:44:59,506 epoch 3 - iter 30/156 - loss 1.09917003 - samples/sec: 414.65\n",
            "2020-02-16 18:45:00,907 epoch 3 - iter 45/156 - loss 0.99700789 - samples/sec: 379.17\n",
            "2020-02-16 18:45:02,214 epoch 3 - iter 60/156 - loss 0.93170684 - samples/sec: 402.41\n",
            "2020-02-16 18:45:03,465 epoch 3 - iter 75/156 - loss 0.92030222 - samples/sec: 430.28\n",
            "2020-02-16 18:45:04,741 epoch 3 - iter 90/156 - loss 0.90285030 - samples/sec: 416.45\n",
            "2020-02-16 18:45:06,050 epoch 3 - iter 105/156 - loss 0.90089867 - samples/sec: 410.30\n",
            "2020-02-16 18:45:07,378 epoch 3 - iter 120/156 - loss 0.90624794 - samples/sec: 394.68\n",
            "2020-02-16 18:45:08,635 epoch 3 - iter 135/156 - loss 0.89035701 - samples/sec: 423.33\n",
            "2020-02-16 18:45:09,900 epoch 3 - iter 150/156 - loss 0.85828484 - samples/sec: 414.77\n",
            "2020-02-16 18:45:10,481 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:10,482 EPOCH 3 done: loss 0.8592 - lr 0.3000\n",
            "2020-02-16 18:45:10,629 DEV : loss 1.0399816036224365 - score 0.8487\n",
            "2020-02-16 18:45:10,634 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:45:12,599 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:13,905 epoch 4 - iter 15/156 - loss 0.78442778 - samples/sec: 369.63\n",
            "2020-02-16 18:45:15,194 epoch 4 - iter 30/156 - loss 0.76267515 - samples/sec: 407.62\n",
            "2020-02-16 18:45:16,631 epoch 4 - iter 45/156 - loss 0.71264548 - samples/sec: 380.03\n",
            "2020-02-16 18:45:17,928 epoch 4 - iter 60/156 - loss 0.69106110 - samples/sec: 405.18\n",
            "2020-02-16 18:45:19,219 epoch 4 - iter 75/156 - loss 0.66690983 - samples/sec: 421.60\n",
            "2020-02-16 18:45:20,472 epoch 4 - iter 90/156 - loss 0.65679858 - samples/sec: 418.61\n",
            "2020-02-16 18:45:21,763 epoch 4 - iter 105/156 - loss 0.67174791 - samples/sec: 415.63\n",
            "2020-02-16 18:45:23,085 epoch 4 - iter 120/156 - loss 0.66776613 - samples/sec: 394.91\n",
            "2020-02-16 18:45:24,347 epoch 4 - iter 135/156 - loss 0.67383422 - samples/sec: 415.44\n",
            "2020-02-16 18:45:25,660 epoch 4 - iter 150/156 - loss 0.65273388 - samples/sec: 408.97\n",
            "2020-02-16 18:45:26,231 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:26,232 EPOCH 4 done: loss 0.6546 - lr 0.3000\n",
            "2020-02-16 18:45:26,375 DEV : loss 0.5992282629013062 - score 0.8403\n",
            "2020-02-16 18:45:26,380 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:45:26,381 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:27,593 epoch 5 - iter 15/156 - loss 0.53890610 - samples/sec: 397.08\n",
            "2020-02-16 18:45:28,863 epoch 5 - iter 30/156 - loss 0.50615782 - samples/sec: 411.86\n",
            "2020-02-16 18:45:30,260 epoch 5 - iter 45/156 - loss 0.50860177 - samples/sec: 375.05\n",
            "2020-02-16 18:45:31,612 epoch 5 - iter 60/156 - loss 0.48470962 - samples/sec: 392.69\n",
            "2020-02-16 18:45:32,889 epoch 5 - iter 75/156 - loss 0.48042450 - samples/sec: 418.55\n",
            "2020-02-16 18:45:34,145 epoch 5 - iter 90/156 - loss 0.47013915 - samples/sec: 418.27\n",
            "2020-02-16 18:45:35,458 epoch 5 - iter 105/156 - loss 0.49129818 - samples/sec: 407.83\n",
            "2020-02-16 18:45:36,798 epoch 5 - iter 120/156 - loss 0.49042757 - samples/sec: 389.00\n",
            "2020-02-16 18:45:38,086 epoch 5 - iter 135/156 - loss 0.49023908 - samples/sec: 405.64\n",
            "2020-02-16 18:45:39,412 epoch 5 - iter 150/156 - loss 0.48672296 - samples/sec: 401.79\n",
            "2020-02-16 18:45:39,980 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:39,981 EPOCH 5 done: loss 0.4963 - lr 0.3000\n",
            "2020-02-16 18:45:40,129 DEV : loss 0.7125278115272522 - score 0.8571\n",
            "2020-02-16 18:45:40,134 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:45:42,014 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:43,325 epoch 6 - iter 15/156 - loss 0.51128803 - samples/sec: 367.15\n",
            "2020-02-16 18:45:44,584 epoch 6 - iter 30/156 - loss 0.46188956 - samples/sec: 417.08\n",
            "2020-02-16 18:45:45,962 epoch 6 - iter 45/156 - loss 0.46028876 - samples/sec: 376.28\n",
            "2020-02-16 18:45:47,288 epoch 6 - iter 60/156 - loss 0.45527175 - samples/sec: 394.32\n",
            "2020-02-16 18:45:48,550 epoch 6 - iter 75/156 - loss 0.44490507 - samples/sec: 417.62\n",
            "2020-02-16 18:45:49,873 epoch 6 - iter 90/156 - loss 0.41763122 - samples/sec: 399.11\n",
            "2020-02-16 18:45:51,190 epoch 6 - iter 105/156 - loss 0.42514496 - samples/sec: 400.34\n",
            "2020-02-16 18:45:52,572 epoch 6 - iter 120/156 - loss 0.43248652 - samples/sec: 383.83\n",
            "2020-02-16 18:45:53,881 epoch 6 - iter 135/156 - loss 0.43520427 - samples/sec: 399.95\n",
            "2020-02-16 18:45:55,220 epoch 6 - iter 150/156 - loss 0.44346147 - samples/sec: 394.81\n",
            "2020-02-16 18:45:55,796 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:55,797 EPOCH 6 done: loss 0.4420 - lr 0.3000\n",
            "2020-02-16 18:45:55,939 DEV : loss 0.2441665530204773 - score 0.9328\n",
            "2020-02-16 18:45:55,944 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:45:57,794 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:45:59,117 epoch 7 - iter 15/156 - loss 0.34931613 - samples/sec: 363.55\n",
            "2020-02-16 18:46:00,438 epoch 7 - iter 30/156 - loss 0.30134838 - samples/sec: 400.56\n",
            "2020-02-16 18:46:01,836 epoch 7 - iter 45/156 - loss 0.30186503 - samples/sec: 379.29\n",
            "2020-02-16 18:46:03,189 epoch 7 - iter 60/156 - loss 0.32050700 - samples/sec: 388.70\n",
            "2020-02-16 18:46:04,445 epoch 7 - iter 75/156 - loss 0.36626595 - samples/sec: 416.86\n",
            "2020-02-16 18:46:05,728 epoch 7 - iter 90/156 - loss 0.35672602 - samples/sec: 416.51\n",
            "2020-02-16 18:46:07,055 epoch 7 - iter 105/156 - loss 0.36179094 - samples/sec: 402.10\n",
            "2020-02-16 18:46:08,408 epoch 7 - iter 120/156 - loss 0.38525851 - samples/sec: 389.70\n",
            "2020-02-16 18:46:09,714 epoch 7 - iter 135/156 - loss 0.40901268 - samples/sec: 405.15\n",
            "2020-02-16 18:46:11,023 epoch 7 - iter 150/156 - loss 0.39187419 - samples/sec: 398.44\n",
            "2020-02-16 18:46:11,598 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:11,599 EPOCH 7 done: loss 0.3971 - lr 0.3000\n",
            "2020-02-16 18:46:11,744 DEV : loss 0.3237534165382385 - score 0.9328\n",
            "2020-02-16 18:46:11,748 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:46:13,573 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:14,894 epoch 8 - iter 15/156 - loss 0.28508324 - samples/sec: 368.66\n",
            "2020-02-16 18:46:16,211 epoch 8 - iter 30/156 - loss 0.33315724 - samples/sec: 406.58\n",
            "2020-02-16 18:46:17,583 epoch 8 - iter 45/156 - loss 0.30772894 - samples/sec: 378.46\n",
            "2020-02-16 18:46:18,905 epoch 8 - iter 60/156 - loss 0.30120198 - samples/sec: 396.74\n",
            "2020-02-16 18:46:20,156 epoch 8 - iter 75/156 - loss 0.32208331 - samples/sec: 418.46\n",
            "2020-02-16 18:46:21,464 epoch 8 - iter 90/156 - loss 0.32051250 - samples/sec: 408.51\n",
            "2020-02-16 18:46:22,758 epoch 8 - iter 105/156 - loss 0.31329199 - samples/sec: 403.42\n",
            "2020-02-16 18:46:24,120 epoch 8 - iter 120/156 - loss 0.30548212 - samples/sec: 390.07\n",
            "2020-02-16 18:46:25,459 epoch 8 - iter 135/156 - loss 0.30665988 - samples/sec: 401.06\n",
            "2020-02-16 18:46:26,761 epoch 8 - iter 150/156 - loss 0.29553481 - samples/sec: 401.58\n",
            "2020-02-16 18:46:27,306 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:27,307 EPOCH 8 done: loss 0.2901 - lr 0.3000\n",
            "2020-02-16 18:46:27,446 DEV : loss 0.19845779240131378 - score 0.9748\n",
            "2020-02-16 18:46:27,450 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:46:29,359 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:30,680 epoch 9 - iter 15/156 - loss 0.31949545 - samples/sec: 365.48\n",
            "2020-02-16 18:46:31,964 epoch 9 - iter 30/156 - loss 0.32543188 - samples/sec: 409.21\n",
            "2020-02-16 18:46:33,377 epoch 9 - iter 45/156 - loss 0.30141041 - samples/sec: 369.46\n",
            "2020-02-16 18:46:34,715 epoch 9 - iter 60/156 - loss 0.26987971 - samples/sec: 395.09\n",
            "2020-02-16 18:46:35,974 epoch 9 - iter 75/156 - loss 0.26075265 - samples/sec: 415.85\n",
            "2020-02-16 18:46:37,281 epoch 9 - iter 90/156 - loss 0.25621747 - samples/sec: 404.19\n",
            "2020-02-16 18:46:38,601 epoch 9 - iter 105/156 - loss 0.26859757 - samples/sec: 403.83\n",
            "2020-02-16 18:46:39,974 epoch 9 - iter 120/156 - loss 0.28568723 - samples/sec: 385.67\n",
            "2020-02-16 18:46:41,302 epoch 9 - iter 135/156 - loss 0.29108789 - samples/sec: 396.49\n",
            "2020-02-16 18:46:42,632 epoch 9 - iter 150/156 - loss 0.27941992 - samples/sec: 392.35\n",
            "2020-02-16 18:46:43,214 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:43,215 EPOCH 9 done: loss 0.2884 - lr 0.3000\n",
            "2020-02-16 18:46:43,346 DEV : loss 0.24717390537261963 - score 0.9664\n",
            "2020-02-16 18:46:43,350 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:46:43,351 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:44,591 epoch 10 - iter 15/156 - loss 0.26733031 - samples/sec: 387.83\n",
            "2020-02-16 18:46:45,855 epoch 10 - iter 30/156 - loss 0.22862932 - samples/sec: 414.28\n",
            "2020-02-16 18:46:47,268 epoch 10 - iter 45/156 - loss 0.21794408 - samples/sec: 367.78\n",
            "2020-02-16 18:46:48,627 epoch 10 - iter 60/156 - loss 0.21732102 - samples/sec: 391.37\n",
            "2020-02-16 18:46:49,961 epoch 10 - iter 75/156 - loss 0.20832247 - samples/sec: 399.50\n",
            "2020-02-16 18:46:51,247 epoch 10 - iter 90/156 - loss 0.21477636 - samples/sec: 406.46\n",
            "2020-02-16 18:46:52,617 epoch 10 - iter 105/156 - loss 0.22454571 - samples/sec: 390.56\n",
            "2020-02-16 18:46:53,947 epoch 10 - iter 120/156 - loss 0.22200226 - samples/sec: 392.12\n",
            "2020-02-16 18:46:55,263 epoch 10 - iter 135/156 - loss 0.23073803 - samples/sec: 406.69\n",
            "2020-02-16 18:46:56,573 epoch 10 - iter 150/156 - loss 0.22282849 - samples/sec: 398.07\n",
            "2020-02-16 18:46:57,151 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:57,152 EPOCH 10 done: loss 0.2263 - lr 0.3000\n",
            "2020-02-16 18:46:57,282 DEV : loss 0.3345012068748474 - score 0.9496\n",
            "2020-02-16 18:46:57,286 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 18:46:57,287 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:46:57,288 Testing using best model ...\n",
            "2020-02-16 18:46:57,290 loading file corpus_splits/split_4/model/best-model.pt\n",
            "2020-02-16 18:47:01,820 0.9451\t0.9451\t0.9451\n",
            "2020-02-16 18:47:01,821 \n",
            "MICRO_AVG: acc 0.896 - f1-score 0.9451\n",
            "MACRO_AVG: acc 0.8949 - f1-score 0.940675\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 10 - fp: 0 - fn: 1 - tn: 226 - precision: 1.0000 - recall: 0.9091 - accuracy: 0.9091 - f1-score: 0.9524\n",
            "Certificats,_lÃ©galisation_de_signature tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 9 - fp: 1 - fn: 1 - tn: 226 - precision: 0.9000 - recall: 0.9000 - accuracy: 0.8182 - f1-score: 0.9000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 12 - fp: 2 - fn: 2 - tn: 221 - precision: 0.8571 - recall: 0.8571 - accuracy: 0.7500 - f1-score: 0.8571\n",
            "Enregistrement_de_PACS tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 8 - fp: 0 - fn: 1 - tn: 228 - precision: 1.0000 - recall: 0.8889 - accuracy: 0.8889 - f1-score: 0.9412\n",
            "Inscription_sur_liste_Ã©lectorale tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 11 - fp: 2 - fn: 0 - tn: 224 - precision: 0.8462 - recall: 1.0000 - accuracy: 0.8462 - f1-score: 0.9167\n",
            "Mariage    tp: 6 - fp: 1 - fn: 0 - tn: 230 - precision: 0.8571 - recall: 1.0000 - accuracy: 0.8571 - f1-score: 0.9231\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 10 - fp: 0 - fn: 1 - tn: 226 - precision: 1.0000 - recall: 0.9091 - accuracy: 0.9091 - f1-score: 0.9524\n",
            "Renseignements,_modification_de_dossier tp: 6 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 13 - fp: 1 - fn: 0 - tn: 223 - precision: 0.9286 - recall: 1.0000 - accuracy: 0.9286 - f1-score: 0.9630\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 6 - fp: 0 - fn: 2 - tn: 229 - precision: 1.0000 - recall: 0.7500 - accuracy: 0.7500 - f1-score: 0.8571\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 5 - fp: 0 - fn: 2 - tn: 230 - precision: 1.0000 - recall: 0.7143 - accuracy: 0.7143 - f1-score: 0.8333\n",
            "demandes_d'attestations_diverses tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 14 - fp: 2 - fn: 0 - tn: 221 - precision: 0.8750 - recall: 1.0000 - accuracy: 0.8750 - f1-score: 0.9333\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 9 - fp: 1 - fn: 1 - tn: 226 - precision: 0.9000 - recall: 0.9000 - accuracy: 0.8182 - f1-score: 0.9000\n",
            "explication_rÃ©gularisation_des_charges tp: 3 - fp: 0 - fn: 2 - tn: 232 - precision: 1.0000 - recall: 0.6000 - accuracy: 0.6000 - f1-score: 0.7500\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 13 - fp: 3 - fn: 0 - tn: 221 - precision: 0.8125 - recall: 1.0000 - accuracy: 0.8125 - f1-score: 0.8966\n",
            "2020-02-16 18:47:01,822 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_1 ...\n",
            "2020-02-16 18:47:05,158 Reading data from corpus_splits/split_1\n",
            "2020-02-16 18:47:05,158 Train: corpus_splits/split_1/train.txt\n",
            "2020-02-16 18:47:05,159 Dev: corpus_splits/split_1/dev.txt\n",
            "2020-02-16 18:47:05,160 Test: corpus_splits/split_1/test.txt\n",
            "2020-02-16 18:47:05,789 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4965/4965 [00:00<00:00, 231558.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:47:05,817 [b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Enregistrement_de_PACS', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b\"demandes_d'attestations_diverses\", b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Livret_de_famille', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'Recensement_des_jeunes', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'Renseignements,_modification_de_dossier', b'explication_r\\xc3\\xa9gularisation_des_charges', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'Mariage', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC']\n",
            "2020-02-16 18:47:05,832 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:47:05,836 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 18:47:05,837 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:47:05,838 Corpus: \"Corpus: 4965 train + 118 dev + 237 test sentences\"\n",
            "2020-02-16 18:47:05,839 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:47:05,839 Parameters:\n",
            "2020-02-16 18:47:05,840  - learning_rate: \"0.3\"\n",
            "2020-02-16 18:47:05,841  - mini_batch_size: \"32\"\n",
            "2020-02-16 18:47:05,842  - patience: \"5\"\n",
            "2020-02-16 18:47:05,843  - anneal_factor: \"0.5\"\n",
            "2020-02-16 18:47:05,843  - max_epochs: \"10\"\n",
            "2020-02-16 18:47:05,844  - shuffle: \"False\"\n",
            "2020-02-16 18:47:05,845  - train_with_dev: \"False\"\n",
            "2020-02-16 18:47:05,846  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 18:47:05,847 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:47:05,847 Model training base path: \"corpus_splits/split_1/model\"\n",
            "2020-02-16 18:47:05,848 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:47:05,849 Device: cuda:0\n",
            "2020-02-16 18:47:05,850 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:47:05,851 Embeddings storage mode: cpu\n",
            "2020-02-16 18:47:05,853 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:47:13,735 epoch 1 - iter 15/156 - loss 1.05282265 - samples/sec: 60.92\n",
            "2020-02-16 18:47:21,427 epoch 1 - iter 30/156 - loss 0.73885827 - samples/sec: 63.87\n",
            "2020-02-16 18:47:29,186 epoch 1 - iter 45/156 - loss 0.58744628 - samples/sec: 62.78\n",
            "2020-02-16 18:47:37,048 epoch 1 - iter 60/156 - loss 0.50671520 - samples/sec: 61.91\n",
            "2020-02-16 18:47:44,868 epoch 1 - iter 75/156 - loss 0.47177144 - samples/sec: 62.36\n",
            "2020-02-16 18:47:53,090 epoch 1 - iter 90/156 - loss 0.46099007 - samples/sec: 59.34\n",
            "2020-02-16 18:48:01,076 epoch 1 - iter 105/156 - loss 0.43257743 - samples/sec: 60.93\n",
            "2020-02-16 18:48:08,965 epoch 1 - iter 120/156 - loss 0.41261490 - samples/sec: 61.76\n",
            "2020-02-16 18:48:16,756 epoch 1 - iter 135/156 - loss 0.39294633 - samples/sec: 62.61\n",
            "2020-02-16 18:48:24,577 epoch 1 - iter 150/156 - loss 0.37496976 - samples/sec: 62.48\n",
            "2020-02-16 18:48:27,372 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:48:27,373 EPOCH 1 done: loss 0.3728 - lr 0.3000\n",
            "2020-02-16 18:48:29,150 DEV : loss 0.29088374972343445 - score 0.9407\n",
            "2020-02-16 18:48:29,156 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:48:31,001 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:48:32,277 epoch 2 - iter 15/156 - loss 0.19872674 - samples/sec: 377.10\n",
            "2020-02-16 18:48:33,601 epoch 2 - iter 30/156 - loss 0.21562802 - samples/sec: 415.17\n",
            "2020-02-16 18:48:34,932 epoch 2 - iter 45/156 - loss 0.18836504 - samples/sec: 402.56\n",
            "2020-02-16 18:48:36,332 epoch 2 - iter 60/156 - loss 0.20804406 - samples/sec: 380.03\n",
            "2020-02-16 18:48:37,670 epoch 2 - iter 75/156 - loss 0.20829601 - samples/sec: 402.14\n",
            "2020-02-16 18:48:38,997 epoch 2 - iter 90/156 - loss 0.23039171 - samples/sec: 393.46\n",
            "2020-02-16 18:48:40,328 epoch 2 - iter 105/156 - loss 0.23589380 - samples/sec: 396.92\n",
            "2020-02-16 18:48:41,676 epoch 2 - iter 120/156 - loss 0.23475131 - samples/sec: 395.30\n",
            "2020-02-16 18:48:42,932 epoch 2 - iter 135/156 - loss 0.22498719 - samples/sec: 421.54\n",
            "2020-02-16 18:48:44,256 epoch 2 - iter 150/156 - loss 0.21691110 - samples/sec: 395.06\n",
            "2020-02-16 18:48:44,866 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:48:44,867 EPOCH 2 done: loss 0.2145 - lr 0.3000\n",
            "2020-02-16 18:48:45,017 DEV : loss 0.13005898892879486 - score 0.9576\n",
            "2020-02-16 18:48:45,021 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:48:46,849 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:48:48,122 epoch 3 - iter 15/156 - loss 0.13757386 - samples/sec: 381.65\n",
            "2020-02-16 18:48:49,438 epoch 3 - iter 30/156 - loss 0.12672547 - samples/sec: 409.47\n",
            "2020-02-16 18:48:50,816 epoch 3 - iter 45/156 - loss 0.14368354 - samples/sec: 395.46\n",
            "2020-02-16 18:48:52,192 epoch 3 - iter 60/156 - loss 0.13384167 - samples/sec: 386.51\n",
            "2020-02-16 18:48:53,522 epoch 3 - iter 75/156 - loss 0.14759080 - samples/sec: 404.41\n",
            "2020-02-16 18:48:54,844 epoch 3 - iter 90/156 - loss 0.15407653 - samples/sec: 395.43\n",
            "2020-02-16 18:48:56,173 epoch 3 - iter 105/156 - loss 0.15874685 - samples/sec: 399.11\n",
            "2020-02-16 18:48:57,464 epoch 3 - iter 120/156 - loss 0.16733660 - samples/sec: 406.03\n",
            "2020-02-16 18:48:58,697 epoch 3 - iter 135/156 - loss 0.16736614 - samples/sec: 426.47\n",
            "2020-02-16 18:49:00,056 epoch 3 - iter 150/156 - loss 0.16591497 - samples/sec: 383.34\n",
            "2020-02-16 18:49:00,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:00,688 EPOCH 3 done: loss 0.1650 - lr 0.3000\n",
            "2020-02-16 18:49:00,819 DEV : loss 0.048082608729600906 - score 0.9746\n",
            "2020-02-16 18:49:00,824 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:49:02,742 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:04,017 epoch 4 - iter 15/156 - loss 0.15682169 - samples/sec: 380.41\n",
            "2020-02-16 18:49:05,273 epoch 4 - iter 30/156 - loss 0.17620974 - samples/sec: 419.58\n",
            "2020-02-16 18:49:06,617 epoch 4 - iter 45/156 - loss 0.18872656 - samples/sec: 396.07\n",
            "2020-02-16 18:49:07,991 epoch 4 - iter 60/156 - loss 0.16330212 - samples/sec: 389.40\n",
            "2020-02-16 18:49:09,324 epoch 4 - iter 75/156 - loss 0.17430145 - samples/sec: 401.13\n",
            "2020-02-16 18:49:10,648 epoch 4 - iter 90/156 - loss 0.18428269 - samples/sec: 394.36\n",
            "2020-02-16 18:49:11,982 epoch 4 - iter 105/156 - loss 0.18571922 - samples/sec: 400.44\n",
            "2020-02-16 18:49:13,328 epoch 4 - iter 120/156 - loss 0.18201106 - samples/sec: 396.29\n",
            "2020-02-16 18:49:14,616 epoch 4 - iter 135/156 - loss 0.18090056 - samples/sec: 419.19\n",
            "2020-02-16 18:49:15,989 epoch 4 - iter 150/156 - loss 0.18101580 - samples/sec: 380.19\n",
            "2020-02-16 18:49:16,594 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:16,595 EPOCH 4 done: loss 0.1794 - lr 0.3000\n",
            "2020-02-16 18:49:16,727 DEV : loss 0.05690043792128563 - score 0.9831\n",
            "2020-02-16 18:49:16,733 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:49:18,714 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:20,008 epoch 5 - iter 15/156 - loss 0.10619533 - samples/sec: 374.48\n",
            "2020-02-16 18:49:21,296 epoch 5 - iter 30/156 - loss 0.14878704 - samples/sec: 413.45\n",
            "2020-02-16 18:49:22,640 epoch 5 - iter 45/156 - loss 0.14373045 - samples/sec: 397.30\n",
            "2020-02-16 18:49:23,985 epoch 5 - iter 60/156 - loss 0.12489689 - samples/sec: 391.10\n",
            "2020-02-16 18:49:25,275 epoch 5 - iter 75/156 - loss 0.13099170 - samples/sec: 410.22\n",
            "2020-02-16 18:49:26,606 epoch 5 - iter 90/156 - loss 0.14251271 - samples/sec: 393.54\n",
            "2020-02-16 18:49:27,912 epoch 5 - iter 105/156 - loss 0.14796536 - samples/sec: 402.42\n",
            "2020-02-16 18:49:29,257 epoch 5 - iter 120/156 - loss 0.15184315 - samples/sec: 396.65\n",
            "2020-02-16 18:49:30,555 epoch 5 - iter 135/156 - loss 0.14275570 - samples/sec: 411.95\n",
            "2020-02-16 18:49:31,917 epoch 5 - iter 150/156 - loss 0.13523739 - samples/sec: 392.77\n",
            "2020-02-16 18:49:32,539 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:32,540 EPOCH 5 done: loss 0.1315 - lr 0.3000\n",
            "2020-02-16 18:49:32,676 DEV : loss 0.017105279490351677 - score 0.9831\n",
            "2020-02-16 18:49:32,682 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:49:34,533 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:35,791 epoch 6 - iter 15/156 - loss 0.05856385 - samples/sec: 382.39\n",
            "2020-02-16 18:49:37,092 epoch 6 - iter 30/156 - loss 0.06577679 - samples/sec: 415.08\n",
            "2020-02-16 18:49:38,445 epoch 6 - iter 45/156 - loss 0.09135236 - samples/sec: 397.21\n",
            "2020-02-16 18:49:39,799 epoch 6 - iter 60/156 - loss 0.09124265 - samples/sec: 390.61\n",
            "2020-02-16 18:49:41,082 epoch 6 - iter 75/156 - loss 0.10723541 - samples/sec: 409.21\n",
            "2020-02-16 18:49:42,421 epoch 6 - iter 90/156 - loss 0.10445573 - samples/sec: 399.01\n",
            "2020-02-16 18:49:43,734 epoch 6 - iter 105/156 - loss 0.11800473 - samples/sec: 407.65\n",
            "2020-02-16 18:49:45,028 epoch 6 - iter 120/156 - loss 0.12325406 - samples/sec: 404.81\n",
            "2020-02-16 18:49:46,351 epoch 6 - iter 135/156 - loss 0.12026773 - samples/sec: 411.54\n",
            "2020-02-16 18:49:47,730 epoch 6 - iter 150/156 - loss 0.12080441 - samples/sec: 387.97\n",
            "2020-02-16 18:49:48,357 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:48,358 EPOCH 6 done: loss 0.1179 - lr 0.3000\n",
            "2020-02-16 18:49:48,506 DEV : loss 0.21272586286067963 - score 0.9576\n",
            "2020-02-16 18:49:48,510 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 18:49:48,511 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:49:49,766 epoch 7 - iter 15/156 - loss 0.13780533 - samples/sec: 384.67\n",
            "2020-02-16 18:49:51,076 epoch 7 - iter 30/156 - loss 0.13559548 - samples/sec: 413.91\n",
            "2020-02-16 18:49:52,387 epoch 7 - iter 45/156 - loss 0.14700813 - samples/sec: 400.64\n",
            "2020-02-16 18:49:53,751 epoch 7 - iter 60/156 - loss 0.14555276 - samples/sec: 390.45\n",
            "2020-02-16 18:49:55,050 epoch 7 - iter 75/156 - loss 0.14683219 - samples/sec: 408.19\n",
            "2020-02-16 18:49:56,394 epoch 7 - iter 90/156 - loss 0.14847703 - samples/sec: 397.73\n",
            "2020-02-16 18:49:57,741 epoch 7 - iter 105/156 - loss 0.13732991 - samples/sec: 396.88\n",
            "2020-02-16 18:49:59,072 epoch 7 - iter 120/156 - loss 0.14127695 - samples/sec: 401.10\n",
            "2020-02-16 18:50:00,364 epoch 7 - iter 135/156 - loss 0.13219410 - samples/sec: 412.95\n",
            "2020-02-16 18:50:01,747 epoch 7 - iter 150/156 - loss 0.12400842 - samples/sec: 388.31\n",
            "2020-02-16 18:50:02,325 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:02,326 EPOCH 7 done: loss 0.1224 - lr 0.3000\n",
            "2020-02-16 18:50:02,476 DEV : loss 0.012892023660242558 - score 0.9915\n",
            "2020-02-16 18:50:02,482 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:50:04,420 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:05,709 epoch 8 - iter 15/156 - loss 0.09030515 - samples/sec: 373.58\n",
            "2020-02-16 18:50:06,992 epoch 8 - iter 30/156 - loss 0.11640707 - samples/sec: 419.68\n",
            "2020-02-16 18:50:08,308 epoch 8 - iter 45/156 - loss 0.10947197 - samples/sec: 400.03\n",
            "2020-02-16 18:50:09,637 epoch 8 - iter 60/156 - loss 0.10174423 - samples/sec: 392.69\n",
            "2020-02-16 18:50:10,966 epoch 8 - iter 75/156 - loss 0.11478894 - samples/sec: 401.02\n",
            "2020-02-16 18:50:12,263 epoch 8 - iter 90/156 - loss 0.10141685 - samples/sec: 403.67\n",
            "2020-02-16 18:50:13,595 epoch 8 - iter 105/156 - loss 0.10154857 - samples/sec: 394.32\n",
            "2020-02-16 18:50:14,925 epoch 8 - iter 120/156 - loss 0.10665337 - samples/sec: 397.08\n",
            "2020-02-16 18:50:16,213 epoch 8 - iter 135/156 - loss 0.10890542 - samples/sec: 417.22\n",
            "2020-02-16 18:50:17,595 epoch 8 - iter 150/156 - loss 0.10689166 - samples/sec: 385.10\n",
            "2020-02-16 18:50:18,183 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:18,183 EPOCH 8 done: loss 0.1062 - lr 0.3000\n",
            "2020-02-16 18:50:18,327 DEV : loss 0.039667561650276184 - score 0.9831\n",
            "2020-02-16 18:50:18,334 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:50:18,335 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:19,541 epoch 9 - iter 15/156 - loss 0.07905907 - samples/sec: 398.90\n",
            "2020-02-16 18:50:20,798 epoch 9 - iter 30/156 - loss 0.08593562 - samples/sec: 418.32\n",
            "2020-02-16 18:50:22,118 epoch 9 - iter 45/156 - loss 0.11156984 - samples/sec: 405.38\n",
            "2020-02-16 18:50:23,482 epoch 9 - iter 60/156 - loss 0.09572278 - samples/sec: 392.57\n",
            "2020-02-16 18:50:24,776 epoch 9 - iter 75/156 - loss 0.09406454 - samples/sec: 406.67\n",
            "2020-02-16 18:50:26,102 epoch 9 - iter 90/156 - loss 0.10005058 - samples/sec: 402.98\n",
            "2020-02-16 18:50:27,413 epoch 9 - iter 105/156 - loss 0.09945376 - samples/sec: 399.32\n",
            "2020-02-16 18:50:28,773 epoch 9 - iter 120/156 - loss 0.10733561 - samples/sec: 391.82\n",
            "2020-02-16 18:50:30,053 epoch 9 - iter 135/156 - loss 0.10076895 - samples/sec: 421.60\n",
            "2020-02-16 18:50:31,449 epoch 9 - iter 150/156 - loss 0.09789553 - samples/sec: 384.91\n",
            "2020-02-16 18:50:32,034 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:32,035 EPOCH 9 done: loss 0.0958 - lr 0.3000\n",
            "2020-02-16 18:50:32,196 DEV : loss 0.00024991549435071647 - score 1.0\n",
            "2020-02-16 18:50:32,204 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:50:34,158 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:35,436 epoch 10 - iter 15/156 - loss 0.05980312 - samples/sec: 376.39\n",
            "2020-02-16 18:50:36,730 epoch 10 - iter 30/156 - loss 0.06506826 - samples/sec: 410.43\n",
            "2020-02-16 18:50:38,028 epoch 10 - iter 45/156 - loss 0.07755505 - samples/sec: 403.57\n",
            "2020-02-16 18:50:39,393 epoch 10 - iter 60/156 - loss 0.06226884 - samples/sec: 387.71\n",
            "2020-02-16 18:50:40,704 epoch 10 - iter 75/156 - loss 0.07980393 - samples/sec: 409.32\n",
            "2020-02-16 18:50:42,009 epoch 10 - iter 90/156 - loss 0.07026116 - samples/sec: 401.08\n",
            "2020-02-16 18:50:43,322 epoch 10 - iter 105/156 - loss 0.07566021 - samples/sec: 401.17\n",
            "2020-02-16 18:50:44,640 epoch 10 - iter 120/156 - loss 0.08491759 - samples/sec: 396.76\n",
            "2020-02-16 18:50:45,936 epoch 10 - iter 135/156 - loss 0.08635456 - samples/sec: 412.19\n",
            "2020-02-16 18:50:47,297 epoch 10 - iter 150/156 - loss 0.08542135 - samples/sec: 390.04\n",
            "2020-02-16 18:50:47,921 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:47,926 EPOCH 10 done: loss 0.0827 - lr 0.3000\n",
            "2020-02-16 18:50:48,068 DEV : loss 0.02528904192149639 - score 0.9915\n",
            "2020-02-16 18:50:48,072 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:50:48,073 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:48,074 Testing using best model ...\n",
            "2020-02-16 18:50:48,076 loading file corpus_splits/split_1/model/best-model.pt\n",
            "2020-02-16 18:50:52,414 0.9916\t0.9916\t0.9916\n",
            "2020-02-16 18:50:52,416 \n",
            "MICRO_AVG: acc 0.9833 - f1-score 0.9916\n",
            "MACRO_AVG: acc 0.9809 - f1-score 0.9898041666666666\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 9 - fp: 1 - fn: 0 - tn: 227 - precision: 0.9000 - recall: 1.0000 - accuracy: 0.9000 - f1-score: 0.9474\n",
            "Certificats,_lÃ©galisation_de_signature tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 5 - fp: 0 - fn: 1 - tn: 231 - precision: 1.0000 - recall: 0.8333 - accuracy: 0.8333 - f1-score: 0.9091\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 7 - fp: 1 - fn: 0 - tn: 229 - precision: 0.8750 - recall: 1.0000 - accuracy: 0.8750 - f1-score: 0.9333\n",
            "Enregistrement_de_PACS tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 14 - fp: 0 - fn: 1 - tn: 222 - precision: 1.0000 - recall: 0.9333 - accuracy: 0.9333 - f1-score: 0.9655\n",
            "Mariage    tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 14 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 6 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 14 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 15 - fp: 0 - fn: 0 - tn: 222 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 18:50:52,418 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_9 ...\n",
            "2020-02-16 18:50:55,842 Reading data from corpus_splits/split_9\n",
            "2020-02-16 18:50:55,843 Train: corpus_splits/split_9/train.txt\n",
            "2020-02-16 18:50:55,844 Dev: corpus_splits/split_9/dev.txt\n",
            "2020-02-16 18:50:55,845 Test: corpus_splits/split_9/test.txt\n",
            "2020-02-16 18:50:56,770 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4967/4967 [00:00<00:00, 208362.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:50:56,797 [b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'Enregistrement_de_PACS', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'Mariage', b'Recensement_des_jeunes', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'Livret_de_famille', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'explication_r\\xc3\\xa9gularisation_des_charges', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b\"demandes_d'attestations_diverses\", b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'Renseignements,_modification_de_dossier', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)']\n",
            "2020-02-16 18:50:56,813 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:56,817 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 18:50:56,818 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:56,819 Corpus: \"Corpus: 4967 train + 118 dev + 237 test sentences\"\n",
            "2020-02-16 18:50:56,820 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:56,821 Parameters:\n",
            "2020-02-16 18:50:56,822  - learning_rate: \"0.3\"\n",
            "2020-02-16 18:50:56,822  - mini_batch_size: \"32\"\n",
            "2020-02-16 18:50:56,823  - patience: \"5\"\n",
            "2020-02-16 18:50:56,824  - anneal_factor: \"0.5\"\n",
            "2020-02-16 18:50:56,825  - max_epochs: \"10\"\n",
            "2020-02-16 18:50:56,826  - shuffle: \"False\"\n",
            "2020-02-16 18:50:56,827  - train_with_dev: \"False\"\n",
            "2020-02-16 18:50:56,828  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 18:50:56,829 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:56,829 Model training base path: \"corpus_splits/split_9/model\"\n",
            "2020-02-16 18:50:56,830 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:56,831 Device: cuda:0\n",
            "2020-02-16 18:50:56,832 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:50:56,833 Embeddings storage mode: cpu\n",
            "2020-02-16 18:50:56,836 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:51:04,763 epoch 1 - iter 15/156 - loss 0.84563943 - samples/sec: 60.58\n",
            "2020-02-16 18:51:13,037 epoch 1 - iter 30/156 - loss 0.52850599 - samples/sec: 59.21\n",
            "2020-02-16 18:51:20,927 epoch 1 - iter 45/156 - loss 0.41564273 - samples/sec: 61.78\n",
            "2020-02-16 18:51:28,773 epoch 1 - iter 60/156 - loss 0.35693765 - samples/sec: 62.03\n",
            "2020-02-16 18:51:36,622 epoch 1 - iter 75/156 - loss 0.31267708 - samples/sec: 62.10\n",
            "2020-02-16 18:51:44,340 epoch 1 - iter 90/156 - loss 0.28308592 - samples/sec: 63.10\n",
            "2020-02-16 18:51:52,287 epoch 1 - iter 105/156 - loss 0.25601876 - samples/sec: 61.22\n",
            "2020-02-16 18:52:07,992 epoch 1 - iter 135/156 - loss 0.22129925 - samples/sec: 60.47\n",
            "2020-02-16 18:52:15,812 epoch 1 - iter 150/156 - loss 0.20626879 - samples/sec: 62.51\n",
            "2020-02-16 18:52:18,502 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:52:18,503 EPOCH 1 done: loss 0.2014 - lr 0.3000\n",
            "2020-02-16 18:52:20,169 DEV : loss 0.0039529455825686455 - score 1.0\n",
            "2020-02-16 18:52:20,176 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:52:22,082 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:52:23,421 epoch 2 - iter 15/156 - loss 0.09671511 - samples/sec: 359.38\n",
            "2020-02-16 18:52:24,714 epoch 2 - iter 30/156 - loss 0.11457014 - samples/sec: 418.37\n",
            "2020-02-16 18:52:26,005 epoch 2 - iter 45/156 - loss 0.09119672 - samples/sec: 409.65\n",
            "2020-02-16 18:52:27,331 epoch 2 - iter 60/156 - loss 0.09171611 - samples/sec: 398.33\n",
            "2020-02-16 18:52:28,602 epoch 2 - iter 75/156 - loss 0.07950062 - samples/sec: 425.09\n",
            "2020-02-16 18:52:29,978 epoch 2 - iter 90/156 - loss 0.08082856 - samples/sec: 378.21\n",
            "2020-02-16 18:52:31,297 epoch 2 - iter 105/156 - loss 0.08035894 - samples/sec: 402.44\n",
            "2020-02-16 18:52:32,594 epoch 2 - iter 120/156 - loss 0.08024891 - samples/sec: 416.83\n",
            "2020-02-16 18:52:33,969 epoch 2 - iter 135/156 - loss 0.07791680 - samples/sec: 387.32\n",
            "2020-02-16 18:52:35,302 epoch 2 - iter 150/156 - loss 0.07573969 - samples/sec: 392.01\n",
            "2020-02-16 18:52:35,836 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:52:35,837 EPOCH 2 done: loss 0.0735 - lr 0.3000\n",
            "2020-02-16 18:52:35,979 DEV : loss 0.05353226512670517 - score 0.9915\n",
            "2020-02-16 18:52:35,985 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:52:35,986 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:52:37,250 epoch 3 - iter 15/156 - loss 0.03544631 - samples/sec: 380.68\n",
            "2020-02-16 18:52:38,527 epoch 3 - iter 30/156 - loss 0.09196790 - samples/sec: 419.83\n",
            "2020-02-16 18:52:39,827 epoch 3 - iter 45/156 - loss 0.08211265 - samples/sec: 408.76\n",
            "2020-02-16 18:52:41,167 epoch 3 - iter 60/156 - loss 0.08437152 - samples/sec: 395.87\n",
            "2020-02-16 18:52:42,433 epoch 3 - iter 75/156 - loss 0.07728629 - samples/sec: 423.91\n",
            "2020-02-16 18:52:43,801 epoch 3 - iter 90/156 - loss 0.07740224 - samples/sec: 380.49\n",
            "2020-02-16 18:52:45,127 epoch 3 - iter 105/156 - loss 0.07795629 - samples/sec: 403.40\n",
            "2020-02-16 18:52:46,374 epoch 3 - iter 120/156 - loss 0.07829280 - samples/sec: 420.80\n",
            "2020-02-16 18:52:47,755 epoch 3 - iter 135/156 - loss 0.07726583 - samples/sec: 385.00\n",
            "2020-02-16 18:52:49,128 epoch 3 - iter 150/156 - loss 0.07054741 - samples/sec: 381.12\n",
            "2020-02-16 18:52:49,721 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:52:49,726 EPOCH 3 done: loss 0.0714 - lr 0.3000\n",
            "2020-02-16 18:52:49,871 DEV : loss 0.007447052747011185 - score 1.0\n",
            "2020-02-16 18:52:49,878 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 18:52:51,871 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:52:53,192 epoch 4 - iter 15/156 - loss 0.05337294 - samples/sec: 365.54\n",
            "2020-02-16 18:52:54,485 epoch 4 - iter 30/156 - loss 0.05873320 - samples/sec: 415.81\n",
            "2020-02-16 18:52:55,800 epoch 4 - iter 45/156 - loss 0.06623893 - samples/sec: 408.66\n",
            "2020-02-16 18:52:57,143 epoch 4 - iter 60/156 - loss 0.06675948 - samples/sec: 395.56\n",
            "2020-02-16 18:52:58,420 epoch 4 - iter 75/156 - loss 0.06183555 - samples/sec: 423.88\n",
            "2020-02-16 18:52:59,830 epoch 4 - iter 90/156 - loss 0.06474028 - samples/sec: 376.23\n",
            "2020-02-16 18:53:01,136 epoch 4 - iter 105/156 - loss 0.06600667 - samples/sec: 408.92\n",
            "2020-02-16 18:53:02,441 epoch 4 - iter 120/156 - loss 0.07357905 - samples/sec: 410.32\n",
            "2020-02-16 18:53:03,818 epoch 4 - iter 135/156 - loss 0.06782591 - samples/sec: 385.64\n",
            "2020-02-16 18:53:05,168 epoch 4 - iter 150/156 - loss 0.06305321 - samples/sec: 390.63\n",
            "2020-02-16 18:53:05,674 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:05,675 EPOCH 4 done: loss 0.0627 - lr 0.3000\n",
            "2020-02-16 18:53:05,818 DEV : loss 0.00020623207092285156 - score 1.0\n",
            "2020-02-16 18:53:05,824 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 18:53:07,731 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:09,075 epoch 5 - iter 15/156 - loss 0.04002629 - samples/sec: 357.93\n",
            "2020-02-16 18:53:10,356 epoch 5 - iter 30/156 - loss 0.07337382 - samples/sec: 419.66\n",
            "2020-02-16 18:53:11,655 epoch 5 - iter 45/156 - loss 0.06634691 - samples/sec: 412.32\n",
            "2020-02-16 18:53:12,962 epoch 5 - iter 60/156 - loss 0.07674864 - samples/sec: 399.84\n",
            "2020-02-16 18:53:14,233 epoch 5 - iter 75/156 - loss 0.07462171 - samples/sec: 433.55\n",
            "2020-02-16 18:53:15,623 epoch 5 - iter 90/156 - loss 0.07615145 - samples/sec: 374.53\n",
            "2020-02-16 18:53:16,912 epoch 5 - iter 105/156 - loss 0.07301198 - samples/sec: 412.37\n",
            "2020-02-16 18:53:18,228 epoch 5 - iter 120/156 - loss 0.07328340 - samples/sec: 409.96\n",
            "2020-02-16 18:53:19,592 epoch 5 - iter 135/156 - loss 0.07011416 - samples/sec: 390.52\n",
            "2020-02-16 18:53:20,952 epoch 5 - iter 150/156 - loss 0.06601522 - samples/sec: 383.64\n",
            "2020-02-16 18:53:21,500 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:21,501 EPOCH 5 done: loss 0.0650 - lr 0.3000\n",
            "2020-02-16 18:53:21,648 DEV : loss 0.036636628210544586 - score 0.9831\n",
            "2020-02-16 18:53:21,654 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 18:53:21,655 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:22,921 epoch 6 - iter 15/156 - loss 0.01749712 - samples/sec: 379.97\n",
            "2020-02-16 18:53:24,193 epoch 6 - iter 30/156 - loss 0.04871921 - samples/sec: 422.53\n",
            "2020-02-16 18:53:25,530 epoch 6 - iter 45/156 - loss 0.05122972 - samples/sec: 403.82\n",
            "2020-02-16 18:53:26,882 epoch 6 - iter 60/156 - loss 0.07001899 - samples/sec: 394.85\n",
            "2020-02-16 18:53:28,139 epoch 6 - iter 75/156 - loss 0.07582384 - samples/sec: 427.64\n",
            "2020-02-16 18:53:29,513 epoch 6 - iter 90/156 - loss 0.06674621 - samples/sec: 380.15\n",
            "2020-02-16 18:53:30,829 epoch 6 - iter 105/156 - loss 0.06115995 - samples/sec: 406.34\n",
            "2020-02-16 18:53:32,081 epoch 6 - iter 120/156 - loss 0.06336063 - samples/sec: 419.72\n",
            "2020-02-16 18:53:33,461 epoch 6 - iter 135/156 - loss 0.06519697 - samples/sec: 390.78\n",
            "2020-02-16 18:53:34,837 epoch 6 - iter 150/156 - loss 0.06042278 - samples/sec: 385.94\n",
            "2020-02-16 18:53:35,379 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:35,380 EPOCH 6 done: loss 0.0587 - lr 0.3000\n",
            "2020-02-16 18:53:35,524 DEV : loss 0.003078354289755225 - score 1.0\n",
            "2020-02-16 18:53:35,530 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 18:53:37,379 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:38,704 epoch 7 - iter 15/156 - loss 0.02905907 - samples/sec: 362.98\n",
            "2020-02-16 18:53:39,993 epoch 7 - iter 30/156 - loss 0.04166619 - samples/sec: 420.28\n",
            "2020-02-16 18:53:41,321 epoch 7 - iter 45/156 - loss 0.03789633 - samples/sec: 403.08\n",
            "2020-02-16 18:53:42,670 epoch 7 - iter 60/156 - loss 0.05421122 - samples/sec: 398.09\n",
            "2020-02-16 18:53:43,912 epoch 7 - iter 75/156 - loss 0.04904364 - samples/sec: 423.38\n",
            "2020-02-16 18:53:45,322 epoch 7 - iter 90/156 - loss 0.05517458 - samples/sec: 376.55\n",
            "2020-02-16 18:53:46,629 epoch 7 - iter 105/156 - loss 0.06324751 - samples/sec: 410.18\n",
            "2020-02-16 18:53:47,882 epoch 7 - iter 120/156 - loss 0.06286233 - samples/sec: 420.48\n",
            "2020-02-16 18:53:49,253 epoch 7 - iter 135/156 - loss 0.06289260 - samples/sec: 382.97\n",
            "2020-02-16 18:53:50,688 epoch 7 - iter 150/156 - loss 0.06279231 - samples/sec: 379.59\n",
            "2020-02-16 18:53:51,242 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:51,243 EPOCH 7 done: loss 0.0618 - lr 0.3000\n",
            "2020-02-16 18:53:51,389 DEV : loss 0.01794562116265297 - score 0.9915\n",
            "Epoch     7: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 18:53:51,395 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 18:53:51,396 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:53:52,662 epoch 8 - iter 15/156 - loss 0.02941055 - samples/sec: 379.93\n",
            "2020-02-16 18:53:53,944 epoch 8 - iter 30/156 - loss 0.06005574 - samples/sec: 420.76\n",
            "2020-02-16 18:53:55,258 epoch 8 - iter 45/156 - loss 0.04921098 - samples/sec: 404.80\n",
            "2020-02-16 18:53:56,589 epoch 8 - iter 60/156 - loss 0.05981113 - samples/sec: 394.60\n",
            "2020-02-16 18:53:57,854 epoch 8 - iter 75/156 - loss 0.05779342 - samples/sec: 419.86\n",
            "2020-02-16 18:53:59,258 epoch 8 - iter 90/156 - loss 0.05403637 - samples/sec: 379.43\n",
            "2020-02-16 18:54:00,606 epoch 8 - iter 105/156 - loss 0.05264305 - samples/sec: 399.21\n",
            "2020-02-16 18:54:01,878 epoch 8 - iter 120/156 - loss 0.04921493 - samples/sec: 414.45\n",
            "2020-02-16 18:54:03,247 epoch 8 - iter 135/156 - loss 0.04693994 - samples/sec: 383.72\n",
            "2020-02-16 18:54:04,637 epoch 8 - iter 150/156 - loss 0.04407094 - samples/sec: 385.41\n",
            "2020-02-16 18:54:05,178 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:05,179 EPOCH 8 done: loss 0.0427 - lr 0.1500\n",
            "2020-02-16 18:54:05,323 DEV : loss 0.0003541985643096268 - score 1.0\n",
            "2020-02-16 18:54:05,329 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:54:07,374 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:08,697 epoch 9 - iter 15/156 - loss 0.01327748 - samples/sec: 364.91\n",
            "2020-02-16 18:54:09,960 epoch 9 - iter 30/156 - loss 0.03491927 - samples/sec: 419.37\n",
            "2020-02-16 18:54:11,253 epoch 9 - iter 45/156 - loss 0.03256715 - samples/sec: 404.81\n",
            "2020-02-16 18:54:12,578 epoch 9 - iter 60/156 - loss 0.02896220 - samples/sec: 402.76\n",
            "2020-02-16 18:54:13,853 epoch 9 - iter 75/156 - loss 0.03273604 - samples/sec: 420.49\n",
            "2020-02-16 18:54:15,226 epoch 9 - iter 90/156 - loss 0.03296786 - samples/sec: 384.70\n",
            "2020-02-16 18:54:16,557 epoch 9 - iter 105/156 - loss 0.03319334 - samples/sec: 408.33\n",
            "2020-02-16 18:54:17,794 epoch 9 - iter 120/156 - loss 0.03100158 - samples/sec: 424.86\n",
            "2020-02-16 18:54:19,175 epoch 9 - iter 135/156 - loss 0.02977650 - samples/sec: 385.70\n",
            "2020-02-16 18:54:20,508 epoch 9 - iter 150/156 - loss 0.02762582 - samples/sec: 390.55\n",
            "2020-02-16 18:54:21,052 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:21,053 EPOCH 9 done: loss 0.0268 - lr 0.1500\n",
            "2020-02-16 18:54:21,198 DEV : loss 0.00011454929335741326 - score 1.0\n",
            "2020-02-16 18:54:21,204 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 18:54:23,192 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:24,511 epoch 10 - iter 15/156 - loss 0.02077870 - samples/sec: 364.83\n",
            "2020-02-16 18:54:25,793 epoch 10 - iter 30/156 - loss 0.03452289 - samples/sec: 418.96\n",
            "2020-02-16 18:54:27,100 epoch 10 - iter 45/156 - loss 0.03014882 - samples/sec: 400.15\n",
            "2020-02-16 18:54:28,414 epoch 10 - iter 60/156 - loss 0.03789209 - samples/sec: 401.51\n",
            "2020-02-16 18:54:29,663 epoch 10 - iter 75/156 - loss 0.03456783 - samples/sec: 431.31\n",
            "2020-02-16 18:54:31,100 epoch 10 - iter 90/156 - loss 0.03487003 - samples/sec: 372.88\n",
            "2020-02-16 18:54:32,392 epoch 10 - iter 105/156 - loss 0.03337254 - samples/sec: 406.59\n",
            "2020-02-16 18:54:33,669 epoch 10 - iter 120/156 - loss 0.03330422 - samples/sec: 419.62\n",
            "2020-02-16 18:54:35,063 epoch 10 - iter 135/156 - loss 0.03166448 - samples/sec: 381.84\n",
            "2020-02-16 18:54:36,470 epoch 10 - iter 150/156 - loss 0.02944695 - samples/sec: 379.95\n",
            "2020-02-16 18:54:37,011 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:37,014 EPOCH 10 done: loss 0.0288 - lr 0.1500\n",
            "2020-02-16 18:54:37,153 DEV : loss 0.0005339702474884689 - score 1.0\n",
            "2020-02-16 18:54:37,159 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 18:54:39,070 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:39,075 Testing using best model ...\n",
            "2020-02-16 18:54:39,080 loading file corpus_splits/split_9/model/best-model.pt\n",
            "2020-02-16 18:54:43,275 0.9958\t0.9958\t0.9958\n",
            "2020-02-16 18:54:43,276 \n",
            "MICRO_AVG: acc 0.9916 - f1-score 0.9958\n",
            "MACRO_AVG: acc 0.991 - f1-score 0.9952375\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 17 - fp: 0 - fn: 0 - tn: 220 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Certificats,_lÃ©galisation_de_signature tp: 5 - fp: 0 - fn: 0 - tn: 232 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 6 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 7 - fp: 1 - fn: 0 - tn: 229 - precision: 0.8750 - recall: 1.0000 - accuracy: 0.8750 - f1-score: 0.9333\n",
            "Enregistrement_de_PACS tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 10 - fp: 0 - fn: 1 - tn: 226 - precision: 1.0000 - recall: 0.9091 - accuracy: 0.9091 - f1-score: 0.9524\n",
            "Mariage    tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 12 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 6 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 14 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 12 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 12 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 14 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 18:54:43,277 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_8 ...\n",
            "2020-02-16 18:54:46,634 Reading data from corpus_splits/split_8\n",
            "2020-02-16 18:54:46,635 Train: corpus_splits/split_8/train.txt\n",
            "2020-02-16 18:54:46,639 Dev: corpus_splits/split_8/dev.txt\n",
            "2020-02-16 18:54:46,640 Test: corpus_splits/split_8/test.txt\n",
            "2020-02-16 18:54:47,463 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4971/4971 [00:00<00:00, 266224.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:54:47,493 [b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b\"demandes_d'attestations_diverses\", b'explication_r\\xc3\\xa9gularisation_des_charges', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'Mariage', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'Livret_de_famille', b'Recensement_des_jeunes', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Renseignements,_modification_de_dossier', b'Enregistrement_de_PACS']\n",
            "2020-02-16 18:54:47,508 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:47,510 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 18:54:47,511 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:47,511 Corpus: \"Corpus: 4971 train + 116 dev + 237 test sentences\"\n",
            "2020-02-16 18:54:47,512 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:47,514 Parameters:\n",
            "2020-02-16 18:54:47,515  - learning_rate: \"0.3\"\n",
            "2020-02-16 18:54:47,517  - mini_batch_size: \"32\"\n",
            "2020-02-16 18:54:47,517  - patience: \"5\"\n",
            "2020-02-16 18:54:47,521  - anneal_factor: \"0.5\"\n",
            "2020-02-16 18:54:47,523  - max_epochs: \"10\"\n",
            "2020-02-16 18:54:47,524  - shuffle: \"False\"\n",
            "2020-02-16 18:54:47,524  - train_with_dev: \"False\"\n",
            "2020-02-16 18:54:47,525  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 18:54:47,528 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:47,529 Model training base path: \"corpus_splits/split_8/model\"\n",
            "2020-02-16 18:54:47,530 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:47,531 Device: cuda:0\n",
            "2020-02-16 18:54:47,533 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:54:47,534 Embeddings storage mode: cpu\n",
            "2020-02-16 18:54:47,537 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:54:55,777 epoch 1 - iter 15/156 - loss 0.75614556 - samples/sec: 58.28\n",
            "2020-02-16 18:55:03,454 epoch 1 - iter 30/156 - loss 0.44931348 - samples/sec: 63.70\n",
            "2020-02-16 18:55:11,448 epoch 1 - iter 45/156 - loss 0.34281796 - samples/sec: 61.06\n",
            "2020-02-16 18:55:19,243 epoch 1 - iter 60/156 - loss 0.28148861 - samples/sec: 62.64\n",
            "2020-02-16 18:55:27,280 epoch 1 - iter 75/156 - loss 0.23750490 - samples/sec: 60.63\n",
            "2020-02-16 18:55:35,038 epoch 1 - iter 90/156 - loss 0.21383898 - samples/sec: 62.73\n",
            "2020-02-16 18:55:42,740 epoch 1 - iter 105/156 - loss 0.20559717 - samples/sec: 63.45\n",
            "2020-02-16 18:55:50,798 epoch 1 - iter 120/156 - loss 0.19405362 - samples/sec: 60.56\n",
            "2020-02-16 18:55:58,672 epoch 1 - iter 135/156 - loss 0.17855375 - samples/sec: 62.20\n",
            "2020-02-16 18:56:06,342 epoch 1 - iter 150/156 - loss 0.17023895 - samples/sec: 63.49\n",
            "2020-02-16 18:56:09,344 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:09,345 EPOCH 1 done: loss 0.1643 - lr 0.3000\n",
            "2020-02-16 18:56:11,215 DEV : loss 0.008601291105151176 - score 0.9914\n",
            "2020-02-16 18:56:11,219 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:56:13,006 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:14,321 epoch 2 - iter 15/156 - loss 0.02425304 - samples/sec: 367.82\n",
            "2020-02-16 18:56:15,631 epoch 2 - iter 30/156 - loss 0.03642917 - samples/sec: 408.08\n",
            "2020-02-16 18:56:16,925 epoch 2 - iter 45/156 - loss 0.03197278 - samples/sec: 413.62\n",
            "2020-02-16 18:56:18,287 epoch 2 - iter 60/156 - loss 0.03827306 - samples/sec: 394.55\n",
            "2020-02-16 18:56:19,755 epoch 2 - iter 75/156 - loss 0.03717195 - samples/sec: 362.07\n",
            "2020-02-16 18:56:21,054 epoch 2 - iter 90/156 - loss 0.03981171 - samples/sec: 403.25\n",
            "2020-02-16 18:56:22,314 epoch 2 - iter 105/156 - loss 0.04974484 - samples/sec: 424.21\n",
            "2020-02-16 18:56:23,721 epoch 2 - iter 120/156 - loss 0.05800505 - samples/sec: 379.75\n",
            "2020-02-16 18:56:25,075 epoch 2 - iter 135/156 - loss 0.05530987 - samples/sec: 393.81\n",
            "2020-02-16 18:56:26,363 epoch 2 - iter 150/156 - loss 0.05885409 - samples/sec: 416.95\n",
            "2020-02-16 18:56:26,958 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:26,959 EPOCH 2 done: loss 0.0578 - lr 0.3000\n",
            "2020-02-16 18:56:27,104 DEV : loss 0.002826834563165903 - score 1.0\n",
            "2020-02-16 18:56:27,110 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 18:56:28,981 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:30,318 epoch 3 - iter 15/156 - loss 0.03257373 - samples/sec: 359.64\n",
            "2020-02-16 18:56:31,605 epoch 3 - iter 30/156 - loss 0.02905236 - samples/sec: 420.05\n",
            "2020-02-16 18:56:32,877 epoch 3 - iter 45/156 - loss 0.02797434 - samples/sec: 412.43\n",
            "2020-02-16 18:56:34,220 epoch 3 - iter 60/156 - loss 0.03987291 - samples/sec: 389.54\n",
            "2020-02-16 18:56:35,693 epoch 3 - iter 75/156 - loss 0.03824014 - samples/sec: 359.64\n",
            "2020-02-16 18:56:37,003 epoch 3 - iter 90/156 - loss 0.04193401 - samples/sec: 404.97\n",
            "2020-02-16 18:56:38,299 epoch 3 - iter 105/156 - loss 0.04457853 - samples/sec: 413.20\n",
            "2020-02-16 18:56:39,691 epoch 3 - iter 120/156 - loss 0.05018621 - samples/sec: 381.91\n",
            "2020-02-16 18:56:41,065 epoch 3 - iter 135/156 - loss 0.05177791 - samples/sec: 389.58\n",
            "2020-02-16 18:56:42,363 epoch 3 - iter 150/156 - loss 0.05625190 - samples/sec: 411.41\n",
            "2020-02-16 18:56:42,910 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:42,911 EPOCH 3 done: loss 0.0556 - lr 0.3000\n",
            "2020-02-16 18:56:43,053 DEV : loss 0.004473974462598562 - score 1.0\n",
            "2020-02-16 18:56:43,059 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:56:44,912 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:46,240 epoch 4 - iter 15/156 - loss 0.00216591 - samples/sec: 362.11\n",
            "2020-02-16 18:56:47,475 epoch 4 - iter 30/156 - loss 0.02306229 - samples/sec: 425.84\n",
            "2020-02-16 18:56:48,747 epoch 4 - iter 45/156 - loss 0.03211618 - samples/sec: 411.44\n",
            "2020-02-16 18:56:50,139 epoch 4 - iter 60/156 - loss 0.03572369 - samples/sec: 379.61\n",
            "2020-02-16 18:56:51,616 epoch 4 - iter 75/156 - loss 0.03107020 - samples/sec: 357.63\n",
            "2020-02-16 18:56:52,933 epoch 4 - iter 90/156 - loss 0.03690267 - samples/sec: 401.24\n",
            "2020-02-16 18:56:54,211 epoch 4 - iter 105/156 - loss 0.03852704 - samples/sec: 426.39\n",
            "2020-02-16 18:56:55,617 epoch 4 - iter 120/156 - loss 0.04481748 - samples/sec: 380.58\n",
            "2020-02-16 18:56:56,966 epoch 4 - iter 135/156 - loss 0.04561162 - samples/sec: 395.16\n",
            "2020-02-16 18:56:58,225 epoch 4 - iter 150/156 - loss 0.04559168 - samples/sec: 417.34\n",
            "2020-02-16 18:56:58,779 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:56:58,780 EPOCH 4 done: loss 0.0451 - lr 0.3000\n",
            "2020-02-16 18:56:58,925 DEV : loss 0.0042384108528494835 - score 1.0\n",
            "2020-02-16 18:56:58,929 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 18:57:00,830 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:02,155 epoch 5 - iter 15/156 - loss 0.00715628 - samples/sec: 364.14\n",
            "2020-02-16 18:57:03,431 epoch 5 - iter 30/156 - loss 0.01804690 - samples/sec: 423.69\n",
            "2020-02-16 18:57:04,700 epoch 5 - iter 45/156 - loss 0.02136109 - samples/sec: 413.06\n",
            "2020-02-16 18:57:06,070 epoch 5 - iter 60/156 - loss 0.02170042 - samples/sec: 389.70\n",
            "2020-02-16 18:57:07,510 epoch 5 - iter 75/156 - loss 0.02103654 - samples/sec: 360.34\n",
            "2020-02-16 18:57:08,812 epoch 5 - iter 90/156 - loss 0.02797407 - samples/sec: 402.01\n",
            "2020-02-16 18:57:10,087 epoch 5 - iter 105/156 - loss 0.02936896 - samples/sec: 416.05\n",
            "2020-02-16 18:57:11,481 epoch 5 - iter 120/156 - loss 0.03337629 - samples/sec: 382.50\n",
            "2020-02-16 18:57:12,834 epoch 5 - iter 135/156 - loss 0.03266976 - samples/sec: 394.63\n",
            "2020-02-16 18:57:14,140 epoch 5 - iter 150/156 - loss 0.03521919 - samples/sec: 417.19\n",
            "2020-02-16 18:57:14,716 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:14,717 EPOCH 5 done: loss 0.0339 - lr 0.3000\n",
            "2020-02-16 18:57:14,862 DEV : loss 0.008332738652825356 - score 1.0\n",
            "2020-02-16 18:57:14,869 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 18:57:16,814 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:18,137 epoch 6 - iter 15/156 - loss 0.01908784 - samples/sec: 365.34\n",
            "2020-02-16 18:57:19,420 epoch 6 - iter 30/156 - loss 0.01887525 - samples/sec: 421.48\n",
            "2020-02-16 18:57:22,059 epoch 6 - iter 60/156 - loss 0.03213172 - samples/sec: 395.21\n",
            "2020-02-16 18:57:23,496 epoch 6 - iter 75/156 - loss 0.02932110 - samples/sec: 362.12\n",
            "2020-02-16 18:57:24,782 epoch 6 - iter 90/156 - loss 0.03311420 - samples/sec: 406.91\n",
            "2020-02-16 18:57:26,056 epoch 6 - iter 105/156 - loss 0.03663691 - samples/sec: 421.54\n",
            "2020-02-16 18:57:27,438 epoch 6 - iter 120/156 - loss 0.04689547 - samples/sec: 385.60\n",
            "2020-02-16 18:57:28,741 epoch 6 - iter 135/156 - loss 0.04766304 - samples/sec: 400.34\n",
            "2020-02-16 18:57:30,006 epoch 6 - iter 150/156 - loss 0.04942667 - samples/sec: 415.67\n",
            "2020-02-16 18:57:30,573 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:30,573 EPOCH 6 done: loss 0.0477 - lr 0.3000\n",
            "2020-02-16 18:57:30,702 DEV : loss 0.008261965587735176 - score 0.9914\n",
            "2020-02-16 18:57:30,705 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 18:57:30,707 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:31,920 epoch 7 - iter 15/156 - loss 0.00367461 - samples/sec: 396.24\n",
            "2020-02-16 18:57:33,167 epoch 7 - iter 30/156 - loss 0.01750082 - samples/sec: 422.79\n",
            "2020-02-16 18:57:34,429 epoch 7 - iter 45/156 - loss 0.02188753 - samples/sec: 422.52\n",
            "2020-02-16 18:57:35,760 epoch 7 - iter 60/156 - loss 0.02606886 - samples/sec: 400.73\n",
            "2020-02-16 18:57:37,210 epoch 7 - iter 75/156 - loss 0.02386318 - samples/sec: 364.28\n",
            "2020-02-16 18:57:38,531 epoch 7 - iter 90/156 - loss 0.02851090 - samples/sec: 403.97\n",
            "2020-02-16 18:57:39,792 epoch 7 - iter 105/156 - loss 0.03079613 - samples/sec: 426.63\n",
            "2020-02-16 18:57:41,180 epoch 7 - iter 120/156 - loss 0.03188613 - samples/sec: 382.44\n",
            "2020-02-16 18:57:42,501 epoch 7 - iter 135/156 - loss 0.03541553 - samples/sec: 395.02\n",
            "2020-02-16 18:57:43,790 epoch 7 - iter 150/156 - loss 0.03941058 - samples/sec: 415.50\n",
            "2020-02-16 18:57:44,353 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:44,354 EPOCH 7 done: loss 0.0383 - lr 0.3000\n",
            "2020-02-16 18:57:44,484 DEV : loss 0.006810285151004791 - score 0.9914\n",
            "2020-02-16 18:57:44,489 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 18:57:44,490 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:45,721 epoch 8 - iter 15/156 - loss 0.01535992 - samples/sec: 390.54\n",
            "2020-02-16 18:57:46,972 epoch 8 - iter 30/156 - loss 0.01179165 - samples/sec: 420.47\n",
            "2020-02-16 18:57:48,237 epoch 8 - iter 45/156 - loss 0.01481615 - samples/sec: 424.69\n",
            "2020-02-16 18:57:49,641 epoch 8 - iter 60/156 - loss 0.01661573 - samples/sec: 381.92\n",
            "2020-02-16 18:57:51,156 epoch 8 - iter 75/156 - loss 0.01950767 - samples/sec: 355.30\n",
            "2020-02-16 18:57:52,473 epoch 8 - iter 90/156 - loss 0.02475882 - samples/sec: 398.23\n",
            "2020-02-16 18:57:53,742 epoch 8 - iter 105/156 - loss 0.03258928 - samples/sec: 422.85\n",
            "2020-02-16 18:57:55,117 epoch 8 - iter 120/156 - loss 0.03950524 - samples/sec: 382.82\n",
            "2020-02-16 18:57:56,441 epoch 8 - iter 135/156 - loss 0.03895941 - samples/sec: 398.94\n",
            "2020-02-16 18:57:57,746 epoch 8 - iter 150/156 - loss 0.04398667 - samples/sec: 411.04\n",
            "2020-02-16 18:57:58,303 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:58,304 EPOCH 8 done: loss 0.0427 - lr 0.3000\n",
            "2020-02-16 18:57:58,450 DEV : loss 0.015178811736404896 - score 0.9914\n",
            "Epoch     8: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 18:57:58,459 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 18:57:58,460 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:57:59,726 epoch 9 - iter 15/156 - loss 0.01110268 - samples/sec: 380.08\n",
            "2020-02-16 18:58:01,033 epoch 9 - iter 30/156 - loss 0.01623898 - samples/sec: 411.01\n",
            "2020-02-16 18:58:02,312 epoch 9 - iter 45/156 - loss 0.01762591 - samples/sec: 420.46\n",
            "2020-02-16 18:58:03,692 epoch 9 - iter 60/156 - loss 0.02217288 - samples/sec: 385.45\n",
            "2020-02-16 18:58:05,150 epoch 9 - iter 75/156 - loss 0.02095927 - samples/sec: 356.47\n",
            "2020-02-16 18:58:06,495 epoch 9 - iter 90/156 - loss 0.02537913 - samples/sec: 400.02\n",
            "2020-02-16 18:58:07,793 epoch 9 - iter 105/156 - loss 0.02741563 - samples/sec: 415.29\n",
            "2020-02-16 18:58:09,189 epoch 9 - iter 120/156 - loss 0.03259448 - samples/sec: 380.04\n",
            "2020-02-16 18:58:10,513 epoch 9 - iter 135/156 - loss 0.03191337 - samples/sec: 399.07\n",
            "2020-02-16 18:58:11,813 epoch 9 - iter 150/156 - loss 0.03131454 - samples/sec: 413.33\n",
            "2020-02-16 18:58:12,347 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:12,348 EPOCH 9 done: loss 0.0301 - lr 0.1500\n",
            "2020-02-16 18:58:12,495 DEV : loss 0.006644016597419977 - score 1.0\n",
            "2020-02-16 18:58:12,502 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 18:58:14,365 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:15,695 epoch 10 - iter 15/156 - loss 0.00697015 - samples/sec: 361.89\n",
            "2020-02-16 18:58:16,945 epoch 10 - iter 30/156 - loss 0.01511829 - samples/sec: 420.95\n",
            "2020-02-16 18:58:18,228 epoch 10 - iter 45/156 - loss 0.01340873 - samples/sec: 419.10\n",
            "2020-02-16 18:58:19,590 epoch 10 - iter 60/156 - loss 0.01620867 - samples/sec: 396.88\n",
            "2020-02-16 18:58:21,061 epoch 10 - iter 75/156 - loss 0.01491957 - samples/sec: 354.93\n",
            "2020-02-16 18:58:22,369 epoch 10 - iter 90/156 - loss 0.01470684 - samples/sec: 410.76\n",
            "2020-02-16 18:58:23,663 epoch 10 - iter 105/156 - loss 0.01554945 - samples/sec: 417.65\n",
            "2020-02-16 18:58:25,030 epoch 10 - iter 120/156 - loss 0.01881613 - samples/sec: 383.38\n",
            "2020-02-16 18:58:26,368 epoch 10 - iter 135/156 - loss 0.01850045 - samples/sec: 393.13\n",
            "2020-02-16 18:58:27,642 epoch 10 - iter 150/156 - loss 0.02034953 - samples/sec: 411.80\n",
            "2020-02-16 18:58:28,176 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:28,177 EPOCH 10 done: loss 0.0205 - lr 0.1500\n",
            "2020-02-16 18:58:28,327 DEV : loss 0.0019041389459744096 - score 1.0\n",
            "2020-02-16 18:58:28,330 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 18:58:30,323 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:30,328 Testing using best model ...\n",
            "2020-02-16 18:58:30,333 loading file corpus_splits/split_8/model/best-model.pt\n",
            "2020-02-16 18:58:34,730 0.9916\t0.9916\t0.9916\n",
            "2020-02-16 18:58:34,731 \n",
            "MICRO_AVG: acc 0.9833 - f1-score 0.9916\n",
            "MACRO_AVG: acc 0.9817 - f1-score 0.9901750000000001\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 15 - fp: 0 - fn: 0 - tn: 222 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Certificats,_lÃ©galisation_de_signature tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 6 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 11 - fp: 1 - fn: 0 - tn: 225 - precision: 0.9167 - recall: 1.0000 - accuracy: 0.9167 - f1-score: 0.9565\n",
            "Enregistrement_de_PACS tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 17 - fp: 0 - fn: 1 - tn: 219 - precision: 1.0000 - recall: 0.9444 - accuracy: 0.9444 - f1-score: 0.9714\n",
            "Mariage    tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 5 - fp: 0 - fn: 0 - tn: 232 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 9 - fp: 0 - fn: 1 - tn: 227 - precision: 1.0000 - recall: 0.9000 - accuracy: 0.9000 - f1-score: 0.9474\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 4 - fp: 1 - fn: 0 - tn: 232 - precision: 0.8000 - recall: 1.0000 - accuracy: 0.8000 - f1-score: 0.8889\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 18:58:34,732 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_7 ...\n",
            "2020-02-16 18:58:38,213 Reading data from corpus_splits/split_7\n",
            "2020-02-16 18:58:38,214 Train: corpus_splits/split_7/train.txt\n",
            "2020-02-16 18:58:38,215 Dev: corpus_splits/split_7/dev.txt\n",
            "2020-02-16 18:58:38,216 Test: corpus_splits/split_7/test.txt\n",
            "2020-02-16 18:58:39,137 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4962/4962 [00:00<00:00, 206923.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:58:39,165 [b'Livret_de_famille', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'explication_r\\xc3\\xa9gularisation_des_charges', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b\"demandes_d'attestations_diverses\", b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'Renseignements,_modification_de_dossier', b'Recensement_des_jeunes', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'Enregistrement_de_PACS', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'Mariage', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)']\n",
            "2020-02-16 18:58:39,182 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:39,186 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 18:58:39,187 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:39,188 Corpus: \"Corpus: 4962 train + 118 dev + 238 test sentences\"\n",
            "2020-02-16 18:58:39,189 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:39,190 Parameters:\n",
            "2020-02-16 18:58:39,191  - learning_rate: \"0.3\"\n",
            "2020-02-16 18:58:39,192  - mini_batch_size: \"32\"\n",
            "2020-02-16 18:58:39,193  - patience: \"5\"\n",
            "2020-02-16 18:58:39,195  - anneal_factor: \"0.5\"\n",
            "2020-02-16 18:58:39,196  - max_epochs: \"10\"\n",
            "2020-02-16 18:58:39,197  - shuffle: \"False\"\n",
            "2020-02-16 18:58:39,198  - train_with_dev: \"False\"\n",
            "2020-02-16 18:58:39,199  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 18:58:39,200 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:39,201 Model training base path: \"corpus_splits/split_7/model\"\n",
            "2020-02-16 18:58:39,202 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:39,203 Device: cuda:0\n",
            "2020-02-16 18:58:39,204 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 18:58:39,205 Embeddings storage mode: cpu\n",
            "2020-02-16 18:58:39,208 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 18:58:46,912 epoch 1 - iter 15/156 - loss 0.62548945 - samples/sec: 62.33\n",
            "2020-02-16 18:58:55,297 epoch 1 - iter 30/156 - loss 0.36460742 - samples/sec: 58.15\n",
            "2020-02-16 18:59:03,478 epoch 1 - iter 45/156 - loss 0.27682351 - samples/sec: 59.47\n",
            "2020-02-16 18:59:11,324 epoch 1 - iter 60/156 - loss 0.22702121 - samples/sec: 62.03\n",
            "2020-02-16 18:59:19,527 epoch 1 - iter 75/156 - loss 0.18691550 - samples/sec: 59.49\n",
            "2020-02-16 18:59:27,466 epoch 1 - iter 90/156 - loss 0.16231866 - samples/sec: 61.29\n",
            "2020-02-16 18:59:35,318 epoch 1 - iter 105/156 - loss 0.14864532 - samples/sec: 62.18\n",
            "2020-02-16 18:59:43,179 epoch 1 - iter 120/156 - loss 0.13444437 - samples/sec: 62.01\n",
            "2020-02-16 18:59:51,508 epoch 1 - iter 135/156 - loss 0.12274236 - samples/sec: 58.38\n",
            "2020-02-16 18:59:59,406 epoch 1 - iter 150/156 - loss 0.11508873 - samples/sec: 61.91\n",
            "2020-02-16 19:00:02,287 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:02,288 EPOCH 1 done: loss 0.1112 - lr 0.3000\n",
            "2020-02-16 19:00:04,014 DEV : loss 0.015130587853491306 - score 0.9915\n",
            "2020-02-16 19:00:04,017 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:00:05,799 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:07,055 epoch 2 - iter 15/156 - loss 0.01627423 - samples/sec: 383.32\n",
            "2020-02-16 19:00:08,394 epoch 2 - iter 30/156 - loss 0.04838132 - samples/sec: 404.80\n",
            "2020-02-16 19:00:09,728 epoch 2 - iter 45/156 - loss 0.04114457 - samples/sec: 400.45\n",
            "2020-02-16 19:00:10,986 epoch 2 - iter 60/156 - loss 0.05014926 - samples/sec: 420.64\n",
            "2020-02-16 19:00:12,388 epoch 2 - iter 75/156 - loss 0.05080769 - samples/sec: 378.03\n",
            "2020-02-16 19:00:13,653 epoch 2 - iter 90/156 - loss 0.04953362 - samples/sec: 415.98\n",
            "2020-02-16 19:00:15,009 epoch 2 - iter 105/156 - loss 0.04804291 - samples/sec: 393.32\n",
            "2020-02-16 19:00:16,343 epoch 2 - iter 120/156 - loss 0.04610044 - samples/sec: 399.46\n",
            "2020-02-16 19:00:17,727 epoch 2 - iter 135/156 - loss 0.04291177 - samples/sec: 378.00\n",
            "2020-02-16 19:00:19,023 epoch 2 - iter 150/156 - loss 0.04304537 - samples/sec: 405.02\n",
            "2020-02-16 19:00:19,556 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:19,557 EPOCH 2 done: loss 0.0417 - lr 0.3000\n",
            "2020-02-16 19:00:19,691 DEV : loss 0.005809244699776173 - score 1.0\n",
            "2020-02-16 19:00:19,696 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:00:21,677 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:22,909 epoch 3 - iter 15/156 - loss 0.01088419 - samples/sec: 392.64\n",
            "2020-02-16 19:00:24,219 epoch 3 - iter 30/156 - loss 0.02896136 - samples/sec: 403.22\n",
            "2020-02-16 19:00:25,578 epoch 3 - iter 45/156 - loss 0.03725651 - samples/sec: 394.37\n",
            "2020-02-16 19:00:26,877 epoch 3 - iter 60/156 - loss 0.03615416 - samples/sec: 414.56\n",
            "2020-02-16 19:00:28,269 epoch 3 - iter 75/156 - loss 0.03627420 - samples/sec: 374.07\n",
            "2020-02-16 19:00:29,529 epoch 3 - iter 90/156 - loss 0.03831985 - samples/sec: 417.55\n",
            "2020-02-16 19:00:30,893 epoch 3 - iter 105/156 - loss 0.03996695 - samples/sec: 390.13\n",
            "2020-02-16 19:00:32,215 epoch 3 - iter 120/156 - loss 0.03793528 - samples/sec: 405.06\n",
            "2020-02-16 19:00:33,688 epoch 3 - iter 135/156 - loss 0.03546312 - samples/sec: 367.73\n",
            "2020-02-16 19:00:35,007 epoch 3 - iter 150/156 - loss 0.03453162 - samples/sec: 401.52\n",
            "2020-02-16 19:00:35,562 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:35,563 EPOCH 3 done: loss 0.0332 - lr 0.3000\n",
            "2020-02-16 19:00:35,683 DEV : loss 0.022038020193576813 - score 0.9915\n",
            "2020-02-16 19:00:35,689 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:00:35,690 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:36,882 epoch 4 - iter 15/156 - loss 0.00557039 - samples/sec: 403.49\n",
            "2020-02-16 19:00:38,210 epoch 4 - iter 30/156 - loss 0.02170852 - samples/sec: 402.74\n",
            "2020-02-16 19:00:39,560 epoch 4 - iter 45/156 - loss 0.02426153 - samples/sec: 395.28\n",
            "2020-02-16 19:00:40,855 epoch 4 - iter 60/156 - loss 0.03377804 - samples/sec: 413.24\n",
            "2020-02-16 19:00:42,252 epoch 4 - iter 75/156 - loss 0.02850862 - samples/sec: 373.03\n",
            "2020-02-16 19:00:43,539 epoch 4 - iter 90/156 - loss 0.03157133 - samples/sec: 417.03\n",
            "2020-02-16 19:00:44,873 epoch 4 - iter 105/156 - loss 0.03253010 - samples/sec: 400.21\n",
            "2020-02-16 19:00:46,199 epoch 4 - iter 120/156 - loss 0.03008649 - samples/sec: 402.78\n",
            "2020-02-16 19:00:47,642 epoch 4 - iter 135/156 - loss 0.02789631 - samples/sec: 368.73\n",
            "2020-02-16 19:00:48,957 epoch 4 - iter 150/156 - loss 0.02724573 - samples/sec: 403.75\n",
            "2020-02-16 19:00:49,520 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:49,522 EPOCH 4 done: loss 0.0263 - lr 0.3000\n",
            "2020-02-16 19:00:49,672 DEV : loss 0.02417078986763954 - score 0.9915\n",
            "2020-02-16 19:00:49,676 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:00:49,678 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:00:50,884 epoch 5 - iter 15/156 - loss 0.02539105 - samples/sec: 398.94\n",
            "2020-02-16 19:00:52,222 epoch 5 - iter 30/156 - loss 0.02576689 - samples/sec: 401.95\n",
            "2020-02-16 19:00:53,565 epoch 5 - iter 45/156 - loss 0.02528301 - samples/sec: 401.37\n",
            "2020-02-16 19:00:54,846 epoch 5 - iter 60/156 - loss 0.02915562 - samples/sec: 409.69\n",
            "2020-02-16 19:00:56,259 epoch 5 - iter 75/156 - loss 0.02853265 - samples/sec: 377.79\n",
            "2020-02-16 19:00:57,538 epoch 5 - iter 90/156 - loss 0.03182758 - samples/sec: 418.84\n",
            "2020-02-16 19:00:58,897 epoch 5 - iter 105/156 - loss 0.03510357 - samples/sec: 391.38\n",
            "2020-02-16 19:01:00,234 epoch 5 - iter 120/156 - loss 0.03237964 - samples/sec: 399.12\n",
            "2020-02-16 19:01:01,641 epoch 5 - iter 135/156 - loss 0.03140402 - samples/sec: 372.76\n",
            "2020-02-16 19:01:02,968 epoch 5 - iter 150/156 - loss 0.03039908 - samples/sec: 403.11\n",
            "2020-02-16 19:01:03,497 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:03,498 EPOCH 5 done: loss 0.0301 - lr 0.3000\n",
            "2020-02-16 19:01:03,632 DEV : loss 0.026829734444618225 - score 0.9831\n",
            "2020-02-16 19:01:03,636 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:01:03,638 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:04,800 epoch 6 - iter 15/156 - loss 0.00952846 - samples/sec: 414.31\n",
            "2020-02-16 19:01:06,104 epoch 6 - iter 30/156 - loss 0.02797076 - samples/sec: 401.05\n",
            "2020-02-16 19:01:07,455 epoch 6 - iter 45/156 - loss 0.04221672 - samples/sec: 394.37\n",
            "2020-02-16 19:01:08,759 epoch 6 - iter 60/156 - loss 0.04489297 - samples/sec: 406.72\n",
            "2020-02-16 19:01:10,153 epoch 6 - iter 75/156 - loss 0.04517259 - samples/sec: 376.33\n",
            "2020-02-16 19:01:11,452 epoch 6 - iter 90/156 - loss 0.04419495 - samples/sec: 416.11\n",
            "2020-02-16 19:01:12,786 epoch 6 - iter 105/156 - loss 0.04502923 - samples/sec: 392.89\n",
            "2020-02-16 19:01:14,111 epoch 6 - iter 120/156 - loss 0.04213611 - samples/sec: 407.13\n",
            "2020-02-16 19:01:15,570 epoch 6 - iter 135/156 - loss 0.04026427 - samples/sec: 365.67\n",
            "2020-02-16 19:01:16,899 epoch 6 - iter 150/156 - loss 0.04193570 - samples/sec: 408.51\n",
            "2020-02-16 19:01:17,427 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:17,427 EPOCH 6 done: loss 0.0404 - lr 0.3000\n",
            "2020-02-16 19:01:17,560 DEV : loss 0.003986010327935219 - score 1.0\n",
            "2020-02-16 19:01:17,568 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 19:01:19,510 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:20,768 epoch 7 - iter 15/156 - loss 0.00925867 - samples/sec: 383.19\n",
            "2020-02-16 19:01:22,107 epoch 7 - iter 30/156 - loss 0.02061644 - samples/sec: 405.51\n",
            "2020-02-16 19:01:23,415 epoch 7 - iter 45/156 - loss 0.01739934 - samples/sec: 399.85\n",
            "2020-02-16 19:01:24,727 epoch 7 - iter 60/156 - loss 0.02778923 - samples/sec: 412.08\n",
            "2020-02-16 19:01:26,104 epoch 7 - iter 75/156 - loss 0.02861636 - samples/sec: 380.57\n",
            "2020-02-16 19:01:27,367 epoch 7 - iter 90/156 - loss 0.02840824 - samples/sec: 421.84\n",
            "2020-02-16 19:01:28,705 epoch 7 - iter 105/156 - loss 0.02804624 - samples/sec: 390.44\n",
            "2020-02-16 19:01:30,018 epoch 7 - iter 120/156 - loss 0.02509570 - samples/sec: 407.16\n",
            "2020-02-16 19:01:31,424 epoch 7 - iter 135/156 - loss 0.02339954 - samples/sec: 369.43\n",
            "2020-02-16 19:01:32,738 epoch 7 - iter 150/156 - loss 0.02474783 - samples/sec: 400.58\n",
            "2020-02-16 19:01:33,268 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:33,268 EPOCH 7 done: loss 0.0247 - lr 0.3000\n",
            "2020-02-16 19:01:33,388 DEV : loss 0.004172108136117458 - score 1.0\n",
            "2020-02-16 19:01:33,393 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 19:01:35,309 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:36,577 epoch 8 - iter 15/156 - loss 0.01480453 - samples/sec: 381.84\n",
            "2020-02-16 19:01:37,915 epoch 8 - iter 30/156 - loss 0.02329450 - samples/sec: 398.18\n",
            "2020-02-16 19:01:39,229 epoch 8 - iter 45/156 - loss 0.02276732 - samples/sec: 397.77\n",
            "2020-02-16 19:01:40,523 epoch 8 - iter 60/156 - loss 0.03082148 - samples/sec: 416.97\n",
            "2020-02-16 19:01:41,920 epoch 8 - iter 75/156 - loss 0.03299222 - samples/sec: 379.42\n",
            "2020-02-16 19:01:43,181 epoch 8 - iter 90/156 - loss 0.03774508 - samples/sec: 418.82\n",
            "2020-02-16 19:01:44,519 epoch 8 - iter 105/156 - loss 0.03824809 - samples/sec: 390.75\n",
            "2020-02-16 19:01:45,860 epoch 8 - iter 120/156 - loss 0.03638217 - samples/sec: 399.17\n",
            "2020-02-16 19:01:47,253 epoch 8 - iter 135/156 - loss 0.03310235 - samples/sec: 373.11\n",
            "2020-02-16 19:01:48,546 epoch 8 - iter 150/156 - loss 0.03324001 - samples/sec: 404.55\n",
            "2020-02-16 19:01:49,102 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:49,103 EPOCH 8 done: loss 0.0320 - lr 0.3000\n",
            "2020-02-16 19:01:49,227 DEV : loss 0.02322525531053543 - score 0.9831\n",
            "Epoch     8: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 19:01:49,230 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 19:01:49,231 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:01:50,441 epoch 9 - iter 15/156 - loss 0.01312525 - samples/sec: 397.89\n",
            "2020-02-16 19:01:51,792 epoch 9 - iter 30/156 - loss 0.01822855 - samples/sec: 395.55\n",
            "2020-02-16 19:01:53,128 epoch 9 - iter 45/156 - loss 0.01652229 - samples/sec: 393.42\n",
            "2020-02-16 19:01:54,403 epoch 9 - iter 60/156 - loss 0.02118405 - samples/sec: 417.46\n",
            "2020-02-16 19:01:55,823 epoch 9 - iter 75/156 - loss 0.02134198 - samples/sec: 373.98\n",
            "2020-02-16 19:01:57,095 epoch 9 - iter 90/156 - loss 0.02676903 - samples/sec: 415.92\n",
            "2020-02-16 19:01:58,446 epoch 9 - iter 105/156 - loss 0.02684077 - samples/sec: 387.30\n",
            "2020-02-16 19:01:59,783 epoch 9 - iter 120/156 - loss 0.02584621 - samples/sec: 405.34\n",
            "2020-02-16 19:02:01,233 epoch 9 - iter 135/156 - loss 0.02631937 - samples/sec: 366.45\n",
            "2020-02-16 19:02:02,525 epoch 9 - iter 150/156 - loss 0.02584514 - samples/sec: 405.68\n",
            "2020-02-16 19:02:03,092 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:03,093 EPOCH 9 done: loss 0.0250 - lr 0.1500\n",
            "2020-02-16 19:02:03,214 DEV : loss 0.017631741240620613 - score 0.9915\n",
            "2020-02-16 19:02:03,218 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:02:03,220 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:04,378 epoch 10 - iter 15/156 - loss 0.01029023 - samples/sec: 415.73\n",
            "2020-02-16 19:02:05,714 epoch 10 - iter 30/156 - loss 0.02636324 - samples/sec: 399.37\n",
            "2020-02-16 19:02:07,067 epoch 10 - iter 45/156 - loss 0.02182111 - samples/sec: 391.89\n",
            "2020-02-16 19:02:08,345 epoch 10 - iter 60/156 - loss 0.02397596 - samples/sec: 410.41\n",
            "2020-02-16 19:02:09,765 epoch 10 - iter 75/156 - loss 0.02241511 - samples/sec: 372.88\n",
            "2020-02-16 19:02:11,030 epoch 10 - iter 90/156 - loss 0.02532331 - samples/sec: 414.33\n",
            "2020-02-16 19:02:12,378 epoch 10 - iter 105/156 - loss 0.02264888 - samples/sec: 399.14\n",
            "2020-02-16 19:02:13,709 epoch 10 - iter 120/156 - loss 0.02027403 - samples/sec: 401.48\n",
            "2020-02-16 19:02:15,134 epoch 10 - iter 135/156 - loss 0.01946827 - samples/sec: 366.37\n",
            "2020-02-16 19:02:16,463 epoch 10 - iter 150/156 - loss 0.01860522 - samples/sec: 402.50\n",
            "2020-02-16 19:02:17,019 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:17,020 EPOCH 10 done: loss 0.0181 - lr 0.1500\n",
            "2020-02-16 19:02:17,143 DEV : loss 0.011764675378799438 - score 0.9915\n",
            "2020-02-16 19:02:17,146 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:02:17,147 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:17,148 Testing using best model ...\n",
            "2020-02-16 19:02:17,152 loading file corpus_splits/split_7/model/best-model.pt\n",
            "2020-02-16 19:02:21,337 0.9958\t0.9958\t0.9958\n",
            "2020-02-16 19:02:21,339 \n",
            "MICRO_AVG: acc 0.9916 - f1-score 0.9958\n",
            "MACRO_AVG: acc 0.9936 - f1-score 0.9966458333333333\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 13 - fp: 0 - fn: 1 - tn: 224 - precision: 1.0000 - recall: 0.9286 - accuracy: 0.9286 - f1-score: 0.9630\n",
            "Certificats,_lÃ©galisation_de_signature tp: 11 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 7 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 11 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 11 - fp: 1 - fn: 0 - tn: 226 - precision: 0.9167 - recall: 1.0000 - accuracy: 0.9167 - f1-score: 0.9565\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 6 - fp: 0 - fn: 0 - tn: 232 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Enregistrement_de_PACS tp: 11 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 14 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 8 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 18 - fp: 0 - fn: 0 - tn: 220 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Mariage    tp: 9 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 9 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 11 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 7 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 9 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 7 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 2 - fp: 0 - fn: 0 - tn: 236 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 7 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 13 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 8 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 14 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 9 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 8 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 14 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 19:02:21,339 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_0 ...\n",
            "2020-02-16 19:02:24,653 Reading data from corpus_splits/split_0\n",
            "2020-02-16 19:02:24,654 Train: corpus_splits/split_0/train.txt\n",
            "2020-02-16 19:02:24,655 Dev: corpus_splits/split_0/dev.txt\n",
            "2020-02-16 19:02:24,656 Test: corpus_splits/split_0/test.txt\n",
            "2020-02-16 19:02:25,251 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4967/4967 [00:00<00:00, 243673.48it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:02:25,277 [b'Livret_de_famille', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Recensement_des_jeunes', b'Renseignements,_modification_de_dossier', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Mariage', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b'explication_r\\xc3\\xa9gularisation_des_charges', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b\"demandes_d'attestations_diverses\", b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'Enregistrement_de_PACS', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\"]\n",
            "2020-02-16 19:02:25,296 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:25,299 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 19:02:25,299 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:25,300 Corpus: \"Corpus: 4967 train + 118 dev + 235 test sentences\"\n",
            "2020-02-16 19:02:25,301 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:25,302 Parameters:\n",
            "2020-02-16 19:02:25,304  - learning_rate: \"0.3\"\n",
            "2020-02-16 19:02:25,305  - mini_batch_size: \"32\"\n",
            "2020-02-16 19:02:25,307  - patience: \"5\"\n",
            "2020-02-16 19:02:25,308  - anneal_factor: \"0.5\"\n",
            "2020-02-16 19:02:25,311  - max_epochs: \"10\"\n",
            "2020-02-16 19:02:25,312  - shuffle: \"False\"\n",
            "2020-02-16 19:02:25,316  - train_with_dev: \"False\"\n",
            "2020-02-16 19:02:25,318  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 19:02:25,319 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:25,320 Model training base path: \"corpus_splits/split_0/model\"\n",
            "2020-02-16 19:02:25,322 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:25,323 Device: cuda:0\n",
            "2020-02-16 19:02:25,325 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:02:25,327 Embeddings storage mode: cpu\n",
            "2020-02-16 19:02:25,330 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:02:33,794 epoch 1 - iter 15/156 - loss 0.66981849 - samples/sec: 56.74\n",
            "2020-02-16 19:02:41,453 epoch 1 - iter 30/156 - loss 0.38610579 - samples/sec: 63.71\n",
            "2020-02-16 19:02:49,101 epoch 1 - iter 45/156 - loss 0.27506845 - samples/sec: 63.71\n",
            "2020-02-16 19:02:57,250 epoch 1 - iter 60/156 - loss 0.21826743 - samples/sec: 59.88\n",
            "2020-02-16 19:03:05,213 epoch 1 - iter 75/156 - loss 0.18674200 - samples/sec: 61.10\n",
            "2020-02-16 19:03:12,946 epoch 1 - iter 90/156 - loss 0.16235987 - samples/sec: 62.95\n",
            "2020-02-16 19:03:20,868 epoch 1 - iter 105/156 - loss 0.14265246 - samples/sec: 61.93\n",
            "2020-02-16 19:03:28,625 epoch 1 - iter 120/156 - loss 0.13335114 - samples/sec: 63.06\n",
            "2020-02-16 19:03:36,472 epoch 1 - iter 135/156 - loss 0.12324204 - samples/sec: 62.30\n",
            "2020-02-16 19:03:44,242 epoch 1 - iter 150/156 - loss 0.11544076 - samples/sec: 62.68\n",
            "2020-02-16 19:03:46,977 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:03:46,978 EPOCH 1 done: loss 0.1127 - lr 0.3000\n",
            "2020-02-16 19:03:48,775 DEV : loss 0.010907813906669617 - score 0.9915\n",
            "2020-02-16 19:03:48,784 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:03:50,570 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:03:51,825 epoch 2 - iter 15/156 - loss 0.07055736 - samples/sec: 383.68\n",
            "2020-02-16 19:03:53,152 epoch 2 - iter 30/156 - loss 0.05517861 - samples/sec: 395.07\n",
            "2020-02-16 19:03:54,471 epoch 2 - iter 45/156 - loss 0.04572267 - samples/sec: 396.97\n",
            "2020-02-16 19:03:55,832 epoch 2 - iter 60/156 - loss 0.04193496 - samples/sec: 396.40\n",
            "2020-02-16 19:03:57,083 epoch 2 - iter 75/156 - loss 0.04529543 - samples/sec: 419.67\n",
            "2020-02-16 19:03:58,394 epoch 2 - iter 90/156 - loss 0.04568706 - samples/sec: 398.58\n",
            "2020-02-16 19:03:59,690 epoch 2 - iter 105/156 - loss 0.04322088 - samples/sec: 419.18\n",
            "2020-02-16 19:04:01,103 epoch 2 - iter 120/156 - loss 0.04555283 - samples/sec: 374.33\n",
            "2020-02-16 19:04:02,394 epoch 2 - iter 135/156 - loss 0.04363366 - samples/sec: 407.63\n",
            "2020-02-16 19:04:03,710 epoch 2 - iter 150/156 - loss 0.04311005 - samples/sec: 411.38\n",
            "2020-02-16 19:04:04,233 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:04,234 EPOCH 2 done: loss 0.0417 - lr 0.3000\n",
            "2020-02-16 19:04:04,387 DEV : loss 0.00042655589641071856 - score 1.0\n",
            "2020-02-16 19:04:04,394 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:04:06,274 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:07,547 epoch 3 - iter 15/156 - loss 0.06636548 - samples/sec: 378.69\n",
            "2020-02-16 19:04:08,905 epoch 3 - iter 30/156 - loss 0.05549073 - samples/sec: 391.92\n",
            "2020-02-16 19:04:10,249 epoch 3 - iter 45/156 - loss 0.04733575 - samples/sec: 396.32\n",
            "2020-02-16 19:04:11,608 epoch 3 - iter 60/156 - loss 0.04251804 - samples/sec: 396.90\n",
            "2020-02-16 19:04:12,899 epoch 3 - iter 75/156 - loss 0.04716646 - samples/sec: 413.29\n",
            "2020-02-16 19:04:14,261 epoch 3 - iter 90/156 - loss 0.04620215 - samples/sec: 400.77\n",
            "2020-02-16 19:04:15,531 epoch 3 - iter 105/156 - loss 0.04296327 - samples/sec: 414.41\n",
            "2020-02-16 19:04:16,963 epoch 3 - iter 120/156 - loss 0.04712626 - samples/sec: 378.52\n",
            "2020-02-16 19:04:18,238 epoch 3 - iter 135/156 - loss 0.04346566 - samples/sec: 410.67\n",
            "2020-02-16 19:04:19,556 epoch 3 - iter 150/156 - loss 0.04029566 - samples/sec: 410.14\n",
            "2020-02-16 19:04:20,073 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:20,074 EPOCH 3 done: loss 0.0398 - lr 0.3000\n",
            "2020-02-16 19:04:20,216 DEV : loss 0.02428143098950386 - score 0.9915\n",
            "2020-02-16 19:04:20,220 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:04:20,221 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:21,424 epoch 4 - iter 15/156 - loss 0.02804925 - samples/sec: 400.30\n",
            "2020-02-16 19:04:22,768 epoch 4 - iter 30/156 - loss 0.04056822 - samples/sec: 392.23\n",
            "2020-02-16 19:04:24,060 epoch 4 - iter 45/156 - loss 0.04075640 - samples/sec: 404.29\n",
            "2020-02-16 19:04:25,404 epoch 4 - iter 60/156 - loss 0.03328027 - samples/sec: 394.99\n",
            "2020-02-16 19:04:26,670 epoch 4 - iter 75/156 - loss 0.03805186 - samples/sec: 414.60\n",
            "2020-02-16 19:04:27,976 epoch 4 - iter 90/156 - loss 0.03883572 - samples/sec: 406.91\n",
            "2020-02-16 19:04:29,232 epoch 4 - iter 105/156 - loss 0.03525153 - samples/sec: 417.28\n",
            "2020-02-16 19:04:30,608 epoch 4 - iter 120/156 - loss 0.03771400 - samples/sec: 381.95\n",
            "2020-02-16 19:04:31,914 epoch 4 - iter 135/156 - loss 0.03783866 - samples/sec: 413.55\n",
            "2020-02-16 19:04:33,183 epoch 4 - iter 150/156 - loss 0.03673408 - samples/sec: 412.56\n",
            "2020-02-16 19:04:33,701 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:33,702 EPOCH 4 done: loss 0.0358 - lr 0.3000\n",
            "2020-02-16 19:04:33,847 DEV : loss 0.01406718511134386 - score 0.9831\n",
            "2020-02-16 19:04:33,852 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:04:33,853 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:35,009 epoch 5 - iter 15/156 - loss 0.04082648 - samples/sec: 416.12\n",
            "2020-02-16 19:04:36,350 epoch 5 - iter 30/156 - loss 0.05625823 - samples/sec: 391.13\n",
            "2020-02-16 19:04:37,715 epoch 5 - iter 45/156 - loss 0.04699348 - samples/sec: 393.20\n",
            "2020-02-16 19:04:39,049 epoch 5 - iter 60/156 - loss 0.04046208 - samples/sec: 394.66\n",
            "2020-02-16 19:04:40,306 epoch 5 - iter 75/156 - loss 0.04480597 - samples/sec: 420.70\n",
            "2020-02-16 19:04:41,620 epoch 5 - iter 90/156 - loss 0.04358112 - samples/sec: 401.57\n",
            "2020-02-16 19:04:42,864 epoch 5 - iter 105/156 - loss 0.03942313 - samples/sec: 421.97\n",
            "2020-02-16 19:04:44,207 epoch 5 - iter 120/156 - loss 0.04032432 - samples/sec: 390.93\n",
            "2020-02-16 19:04:45,521 epoch 5 - iter 135/156 - loss 0.03866196 - samples/sec: 403.99\n",
            "2020-02-16 19:04:46,808 epoch 5 - iter 150/156 - loss 0.03861969 - samples/sec: 416.40\n",
            "2020-02-16 19:04:47,322 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:47,323 EPOCH 5 done: loss 0.0381 - lr 0.3000\n",
            "2020-02-16 19:04:47,476 DEV : loss 0.015495910309255123 - score 0.9915\n",
            "2020-02-16 19:04:47,482 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:04:47,483 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:04:48,675 epoch 6 - iter 15/156 - loss 0.05877106 - samples/sec: 403.45\n",
            "2020-02-16 19:04:50,041 epoch 6 - iter 30/156 - loss 0.05256752 - samples/sec: 386.60\n",
            "2020-02-16 19:04:51,358 epoch 6 - iter 45/156 - loss 0.04803151 - samples/sec: 399.75\n",
            "2020-02-16 19:04:52,699 epoch 6 - iter 60/156 - loss 0.03963458 - samples/sec: 391.32\n",
            "2020-02-16 19:04:53,952 epoch 6 - iter 75/156 - loss 0.04326761 - samples/sec: 424.33\n",
            "2020-02-16 19:04:55,280 epoch 6 - iter 90/156 - loss 0.04358995 - samples/sec: 401.75\n",
            "2020-02-16 19:04:56,507 epoch 6 - iter 105/156 - loss 0.03810486 - samples/sec: 427.81\n",
            "2020-02-16 19:04:57,863 epoch 6 - iter 120/156 - loss 0.03957331 - samples/sec: 386.93\n",
            "2020-02-16 19:04:59,138 epoch 6 - iter 135/156 - loss 0.03672222 - samples/sec: 411.50\n",
            "2020-02-16 19:05:00,432 epoch 6 - iter 150/156 - loss 0.03647147 - samples/sec: 403.09\n",
            "2020-02-16 19:05:00,982 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:00,986 EPOCH 6 done: loss 0.0352 - lr 0.3000\n",
            "2020-02-16 19:05:01,129 DEV : loss 0.004869326017796993 - score 1.0\n",
            "2020-02-16 19:05:01,135 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 19:05:03,041 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:04,321 epoch 7 - iter 15/156 - loss 0.02254125 - samples/sec: 375.87\n",
            "2020-02-16 19:05:05,689 epoch 7 - iter 30/156 - loss 0.03888970 - samples/sec: 393.31\n",
            "2020-02-16 19:05:07,037 epoch 7 - iter 45/156 - loss 0.03991868 - samples/sec: 392.35\n",
            "2020-02-16 19:05:08,356 epoch 7 - iter 60/156 - loss 0.03370565 - samples/sec: 396.26\n",
            "2020-02-16 19:05:09,662 epoch 7 - iter 75/156 - loss 0.03194734 - samples/sec: 412.73\n",
            "2020-02-16 19:05:10,970 epoch 7 - iter 90/156 - loss 0.03440956 - samples/sec: 405.05\n",
            "2020-02-16 19:05:12,229 epoch 7 - iter 105/156 - loss 0.03211001 - samples/sec: 417.46\n",
            "2020-02-16 19:05:13,596 epoch 7 - iter 120/156 - loss 0.03265541 - samples/sec: 380.53\n",
            "2020-02-16 19:05:14,885 epoch 7 - iter 135/156 - loss 0.03022860 - samples/sec: 415.21\n",
            "2020-02-16 19:05:16,215 epoch 7 - iter 150/156 - loss 0.02885191 - samples/sec: 404.03\n",
            "2020-02-16 19:05:16,769 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:16,770 EPOCH 7 done: loss 0.0280 - lr 0.3000\n",
            "2020-02-16 19:05:16,928 DEV : loss 0.018498975783586502 - score 0.9915\n",
            "2020-02-16 19:05:16,932 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 19:05:16,933 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:18,105 epoch 8 - iter 15/156 - loss 0.02427295 - samples/sec: 410.70\n",
            "2020-02-16 19:05:19,455 epoch 8 - iter 30/156 - loss 0.03645741 - samples/sec: 394.52\n",
            "2020-02-16 19:05:20,759 epoch 8 - iter 45/156 - loss 0.03867172 - samples/sec: 400.36\n",
            "2020-02-16 19:05:22,095 epoch 8 - iter 60/156 - loss 0.03720411 - samples/sec: 398.64\n",
            "2020-02-16 19:05:23,384 epoch 8 - iter 75/156 - loss 0.04371832 - samples/sec: 414.52\n",
            "2020-02-16 19:05:24,715 epoch 8 - iter 90/156 - loss 0.04471578 - samples/sec: 400.84\n",
            "2020-02-16 19:05:25,974 epoch 8 - iter 105/156 - loss 0.03964135 - samples/sec: 419.86\n",
            "2020-02-16 19:05:27,367 epoch 8 - iter 120/156 - loss 0.04090129 - samples/sec: 382.69\n",
            "2020-02-16 19:05:28,686 epoch 8 - iter 135/156 - loss 0.03775837 - samples/sec: 404.78\n",
            "2020-02-16 19:05:29,969 epoch 8 - iter 150/156 - loss 0.03432454 - samples/sec: 410.98\n",
            "2020-02-16 19:05:30,488 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:30,489 EPOCH 8 done: loss 0.0338 - lr 0.3000\n",
            "2020-02-16 19:05:30,644 DEV : loss 0.0025132603477686644 - score 1.0\n",
            "Epoch     8: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 19:05:30,651 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 19:05:32,504 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:33,759 epoch 9 - iter 15/156 - loss 0.04562048 - samples/sec: 383.36\n",
            "2020-02-16 19:05:35,121 epoch 9 - iter 30/156 - loss 0.04294087 - samples/sec: 390.51\n",
            "2020-02-16 19:05:36,475 epoch 9 - iter 45/156 - loss 0.03461835 - samples/sec: 392.67\n",
            "2020-02-16 19:05:37,835 epoch 9 - iter 60/156 - loss 0.02966098 - samples/sec: 392.89\n",
            "2020-02-16 19:05:39,117 epoch 9 - iter 75/156 - loss 0.02719979 - samples/sec: 412.33\n",
            "2020-02-16 19:05:40,470 epoch 9 - iter 90/156 - loss 0.02782982 - samples/sec: 395.76\n",
            "2020-02-16 19:05:41,738 epoch 9 - iter 105/156 - loss 0.02581120 - samples/sec: 422.20\n",
            "2020-02-16 19:05:43,091 epoch 9 - iter 120/156 - loss 0.02555036 - samples/sec: 384.97\n",
            "2020-02-16 19:05:44,399 epoch 9 - iter 135/156 - loss 0.02379659 - samples/sec: 406.61\n",
            "2020-02-16 19:05:45,692 epoch 9 - iter 150/156 - loss 0.02387009 - samples/sec: 414.80\n",
            "2020-02-16 19:05:46,219 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:46,220 EPOCH 9 done: loss 0.0231 - lr 0.1500\n",
            "2020-02-16 19:05:46,377 DEV : loss 0.001774512231349945 - score 1.0\n",
            "2020-02-16 19:05:46,383 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:05:48,316 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:05:49,641 epoch 10 - iter 15/156 - loss 0.02529494 - samples/sec: 363.37\n",
            "2020-02-16 19:05:51,044 epoch 10 - iter 30/156 - loss 0.02673776 - samples/sec: 388.39\n",
            "2020-02-16 19:05:52,371 epoch 10 - iter 45/156 - loss 0.02694826 - samples/sec: 393.13\n",
            "2020-02-16 19:05:53,707 epoch 10 - iter 60/156 - loss 0.02408008 - samples/sec: 401.64\n",
            "2020-02-16 19:05:55,004 epoch 10 - iter 75/156 - loss 0.02600556 - samples/sec: 409.93\n",
            "2020-02-16 19:05:56,303 epoch 10 - iter 90/156 - loss 0.02358031 - samples/sec: 405.68\n",
            "2020-02-16 19:05:57,575 epoch 10 - iter 105/156 - loss 0.02051081 - samples/sec: 424.54\n",
            "2020-02-16 19:05:58,930 epoch 10 - iter 120/156 - loss 0.02042496 - samples/sec: 384.65\n",
            "2020-02-16 19:06:00,234 epoch 10 - iter 135/156 - loss 0.01930400 - samples/sec: 402.83\n",
            "2020-02-16 19:06:01,541 epoch 10 - iter 150/156 - loss 0.01845494 - samples/sec: 414.86\n",
            "2020-02-16 19:06:02,084 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:02,085 EPOCH 10 done: loss 0.0180 - lr 0.1500\n",
            "2020-02-16 19:06:02,242 DEV : loss 0.005816365592181683 - score 1.0\n",
            "2020-02-16 19:06:02,248 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:06:04,092 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:04,093 Testing using best model ...\n",
            "2020-02-16 19:06:04,100 loading file corpus_splits/split_0/model/best-model.pt\n",
            "2020-02-16 19:06:08,516 0.9915\t0.9915\t0.9915\n",
            "2020-02-16 19:06:08,517 \n",
            "MICRO_AVG: acc 0.9831 - f1-score 0.9915\n",
            "MACRO_AVG: acc 0.9832 - f1-score 0.9911249999999999\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 6 - fp: 0 - fn: 1 - tn: 228 - precision: 1.0000 - recall: 0.8571 - accuracy: 0.8571 - f1-score: 0.9231\n",
            "Certificats,_lÃ©galisation_de_signature tp: 10 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 12 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 7 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 12 - fp: 1 - fn: 0 - tn: 222 - precision: 0.9231 - recall: 1.0000 - accuracy: 0.9231 - f1-score: 0.9600\n",
            "Enregistrement_de_PACS tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 12 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 19 - fp: 0 - fn: 0 - tn: 216 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Mariage    tp: 7 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 12 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 13 - fp: 0 - fn: 0 - tn: 222 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 9 - fp: 0 - fn: 1 - tn: 225 - precision: 1.0000 - recall: 0.9000 - accuracy: 0.9000 - f1-score: 0.9474\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 11 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 7 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 11 - fp: 1 - fn: 0 - tn: 223 - precision: 0.9167 - recall: 1.0000 - accuracy: 0.9167 - f1-score: 0.9565\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 6 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 8 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 9 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 14 - fp: 0 - fn: 0 - tn: 221 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 19:06:08,518 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_5 ...\n",
            "2020-02-16 19:06:12,067 Reading data from corpus_splits/split_5\n",
            "2020-02-16 19:06:12,068 Train: corpus_splits/split_5/train.txt\n",
            "2020-02-16 19:06:12,069 Dev: corpus_splits/split_5/dev.txt\n",
            "2020-02-16 19:06:12,069 Test: corpus_splits/split_5/test.txt\n",
            "2020-02-16 19:06:12,679 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4968/4968 [00:00<00:00, 242850.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:06:12,706 [b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'explication_r\\xc3\\xa9gularisation_des_charges', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b\"demandes_d'attestations_diverses\", b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'Mariage', b'Enregistrement_de_PACS', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'Livret_de_famille', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'Recensement_des_jeunes', b'Renseignements,_modification_de_dossier', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s']\n",
            "2020-02-16 19:06:12,723 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:12,725 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 19:06:12,726 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:12,727 Corpus: \"Corpus: 4968 train + 119 dev + 236 test sentences\"\n",
            "2020-02-16 19:06:12,728 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:12,729 Parameters:\n",
            "2020-02-16 19:06:12,730  - learning_rate: \"0.3\"\n",
            "2020-02-16 19:06:12,731  - mini_batch_size: \"32\"\n",
            "2020-02-16 19:06:12,732  - patience: \"5\"\n",
            "2020-02-16 19:06:12,733  - anneal_factor: \"0.5\"\n",
            "2020-02-16 19:06:12,735  - max_epochs: \"10\"\n",
            "2020-02-16 19:06:12,737  - shuffle: \"False\"\n",
            "2020-02-16 19:06:12,742  - train_with_dev: \"False\"\n",
            "2020-02-16 19:06:12,743  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 19:06:12,770 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:12,772 Model training base path: \"corpus_splits/split_5/model\"\n",
            "2020-02-16 19:06:12,775 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:12,779 Device: cuda:0\n",
            "2020-02-16 19:06:12,780 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:06:12,787 Embeddings storage mode: cpu\n",
            "2020-02-16 19:06:12,791 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:06:20,402 epoch 1 - iter 15/156 - loss 0.64334982 - samples/sec: 63.08\n",
            "2020-02-16 19:06:28,145 epoch 1 - iter 30/156 - loss 0.34279539 - samples/sec: 63.42\n",
            "2020-02-16 19:06:36,049 epoch 1 - iter 45/156 - loss 0.24296944 - samples/sec: 61.85\n",
            "2020-02-16 19:06:43,972 epoch 1 - iter 60/156 - loss 0.19965013 - samples/sec: 61.43\n",
            "2020-02-16 19:06:51,856 epoch 1 - iter 75/156 - loss 0.16803787 - samples/sec: 61.89\n",
            "2020-02-16 19:06:59,373 epoch 1 - iter 90/156 - loss 0.15060153 - samples/sec: 64.99\n",
            "2020-02-16 19:07:07,183 epoch 1 - iter 105/156 - loss 0.13249747 - samples/sec: 62.54\n",
            "2020-02-16 19:07:15,119 epoch 1 - iter 120/156 - loss 0.11993155 - samples/sec: 61.36\n",
            "2020-02-16 19:07:23,084 epoch 1 - iter 135/156 - loss 0.11204876 - samples/sec: 61.35\n",
            "2020-02-16 19:07:30,984 epoch 1 - iter 150/156 - loss 0.10319167 - samples/sec: 61.60\n",
            "2020-02-16 19:07:33,754 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:07:33,755 EPOCH 1 done: loss 0.1001 - lr 0.3000\n",
            "2020-02-16 19:07:35,495 DEV : loss 0.028145138174295425 - score 0.9916\n",
            "2020-02-16 19:07:35,503 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:07:37,319 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:07:38,613 epoch 2 - iter 15/156 - loss 0.04115170 - samples/sec: 371.94\n",
            "2020-02-16 19:07:39,964 epoch 2 - iter 30/156 - loss 0.03186526 - samples/sec: 396.89\n",
            "2020-02-16 19:07:41,257 epoch 2 - iter 45/156 - loss 0.03021655 - samples/sec: 404.59\n",
            "2020-02-16 19:07:42,529 epoch 2 - iter 60/156 - loss 0.02821317 - samples/sec: 412.74\n",
            "2020-02-16 19:07:43,813 epoch 2 - iter 75/156 - loss 0.02685196 - samples/sec: 416.90\n",
            "2020-02-16 19:07:45,035 epoch 2 - iter 90/156 - loss 0.03624197 - samples/sec: 430.74\n",
            "2020-02-16 19:07:46,350 epoch 2 - iter 105/156 - loss 0.03216587 - samples/sec: 403.26\n",
            "2020-02-16 19:07:47,635 epoch 2 - iter 120/156 - loss 0.03570604 - samples/sec: 417.80\n",
            "2020-02-16 19:07:49,043 epoch 2 - iter 135/156 - loss 0.03529251 - samples/sec: 374.45\n",
            "2020-02-16 19:07:50,442 epoch 2 - iter 150/156 - loss 0.03428579 - samples/sec: 371.52\n",
            "2020-02-16 19:07:51,057 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:07:51,058 EPOCH 2 done: loss 0.0334 - lr 0.3000\n",
            "2020-02-16 19:07:51,200 DEV : loss 0.033287495374679565 - score 0.9832\n",
            "2020-02-16 19:07:51,207 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:07:51,208 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:07:52,443 epoch 3 - iter 15/156 - loss 0.03326849 - samples/sec: 389.33\n",
            "2020-02-16 19:07:53,813 epoch 3 - iter 30/156 - loss 0.02053727 - samples/sec: 391.70\n",
            "2020-02-16 19:07:55,106 epoch 3 - iter 45/156 - loss 0.02138983 - samples/sec: 404.07\n",
            "2020-02-16 19:07:56,403 epoch 3 - iter 60/156 - loss 0.02286344 - samples/sec: 408.08\n",
            "2020-02-16 19:07:57,701 epoch 3 - iter 75/156 - loss 0.02263011 - samples/sec: 411.80\n",
            "2020-02-16 19:07:58,968 epoch 3 - iter 90/156 - loss 0.03239109 - samples/sec: 423.48\n",
            "2020-02-16 19:08:00,259 epoch 3 - iter 105/156 - loss 0.03076040 - samples/sec: 406.09\n",
            "2020-02-16 19:08:01,516 epoch 3 - iter 120/156 - loss 0.03308422 - samples/sec: 421.65\n",
            "2020-02-16 19:08:02,916 epoch 3 - iter 135/156 - loss 0.03233084 - samples/sec: 379.42\n",
            "2020-02-16 19:08:04,299 epoch 3 - iter 150/156 - loss 0.03125520 - samples/sec: 376.07\n",
            "2020-02-16 19:08:04,880 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:04,881 EPOCH 3 done: loss 0.0304 - lr 0.3000\n",
            "2020-02-16 19:08:05,034 DEV : loss 0.08153573423624039 - score 0.9748\n",
            "2020-02-16 19:08:05,038 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:08:05,039 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:06,258 epoch 4 - iter 15/156 - loss 0.05982971 - samples/sec: 395.17\n",
            "2020-02-16 19:08:07,649 epoch 4 - iter 30/156 - loss 0.04902909 - samples/sec: 380.16\n",
            "2020-02-16 19:08:08,958 epoch 4 - iter 45/156 - loss 0.04312329 - samples/sec: 404.71\n",
            "2020-02-16 19:08:10,260 epoch 4 - iter 60/156 - loss 0.03984913 - samples/sec: 403.40\n",
            "2020-02-16 19:08:11,571 epoch 4 - iter 75/156 - loss 0.03630034 - samples/sec: 411.59\n",
            "2020-02-16 19:08:12,822 epoch 4 - iter 90/156 - loss 0.04242357 - samples/sec: 429.29\n",
            "2020-02-16 19:08:14,139 epoch 4 - iter 105/156 - loss 0.03746669 - samples/sec: 397.75\n",
            "2020-02-16 19:08:15,441 epoch 4 - iter 120/156 - loss 0.04012389 - samples/sec: 410.62\n",
            "2020-02-16 19:08:16,875 epoch 4 - iter 135/156 - loss 0.04031983 - samples/sec: 380.88\n",
            "2020-02-16 19:08:18,237 epoch 4 - iter 150/156 - loss 0.03735465 - samples/sec: 382.35\n",
            "2020-02-16 19:08:18,861 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:18,862 EPOCH 4 done: loss 0.0360 - lr 0.3000\n",
            "2020-02-16 19:08:19,011 DEV : loss 0.03898603469133377 - score 0.9916\n",
            "2020-02-16 19:08:19,017 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:08:20,915 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:22,206 epoch 5 - iter 15/156 - loss 0.04286733 - samples/sec: 374.34\n",
            "2020-02-16 19:08:23,566 epoch 5 - iter 30/156 - loss 0.03523061 - samples/sec: 391.71\n",
            "2020-02-16 19:08:24,882 epoch 5 - iter 45/156 - loss 0.03065309 - samples/sec: 399.56\n",
            "2020-02-16 19:08:26,196 epoch 5 - iter 60/156 - loss 0.02766966 - samples/sec: 408.78\n",
            "2020-02-16 19:08:27,518 epoch 5 - iter 75/156 - loss 0.02830933 - samples/sec: 406.90\n",
            "2020-02-16 19:08:28,741 epoch 5 - iter 90/156 - loss 0.03228413 - samples/sec: 433.40\n",
            "2020-02-16 19:08:30,060 epoch 5 - iter 105/156 - loss 0.02908790 - samples/sec: 406.95\n",
            "2020-02-16 19:08:31,321 epoch 5 - iter 120/156 - loss 0.02982113 - samples/sec: 417.11\n",
            "2020-02-16 19:08:32,764 epoch 5 - iter 135/156 - loss 0.03206390 - samples/sec: 369.25\n",
            "2020-02-16 19:08:34,157 epoch 5 - iter 150/156 - loss 0.03196462 - samples/sec: 383.36\n",
            "2020-02-16 19:08:34,747 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:34,748 EPOCH 5 done: loss 0.0310 - lr 0.3000\n",
            "2020-02-16 19:08:34,898 DEV : loss 0.046375297009944916 - score 0.9832\n",
            "2020-02-16 19:08:34,904 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 19:08:34,905 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:36,112 epoch 6 - iter 15/156 - loss 0.04314348 - samples/sec: 398.50\n",
            "2020-02-16 19:08:37,421 epoch 6 - iter 30/156 - loss 0.03293462 - samples/sec: 399.54\n",
            "2020-02-16 19:08:38,712 epoch 6 - iter 45/156 - loss 0.03033683 - samples/sec: 404.86\n",
            "2020-02-16 19:08:39,991 epoch 6 - iter 60/156 - loss 0.02673589 - samples/sec: 411.89\n",
            "2020-02-16 19:08:41,254 epoch 6 - iter 75/156 - loss 0.02396518 - samples/sec: 414.19\n",
            "2020-02-16 19:08:42,497 epoch 6 - iter 90/156 - loss 0.03313843 - samples/sec: 425.31\n",
            "2020-02-16 19:08:43,758 epoch 6 - iter 105/156 - loss 0.02908348 - samples/sec: 415.33\n",
            "2020-02-16 19:08:45,041 epoch 6 - iter 120/156 - loss 0.03342995 - samples/sec: 418.02\n",
            "2020-02-16 19:08:46,453 epoch 6 - iter 135/156 - loss 0.03550059 - samples/sec: 377.18\n",
            "2020-02-16 19:08:47,823 epoch 6 - iter 150/156 - loss 0.03395514 - samples/sec: 387.97\n",
            "2020-02-16 19:08:48,402 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:48,402 EPOCH 6 done: loss 0.0336 - lr 0.3000\n",
            "2020-02-16 19:08:48,555 DEV : loss 0.024195317178964615 - score 0.9916\n",
            "2020-02-16 19:08:48,561 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 19:08:50,537 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:08:51,837 epoch 7 - iter 15/156 - loss 0.04090872 - samples/sec: 371.47\n",
            "2020-02-16 19:08:53,171 epoch 7 - iter 30/156 - loss 0.03091492 - samples/sec: 392.31\n",
            "2020-02-16 19:08:54,509 epoch 7 - iter 45/156 - loss 0.02793049 - samples/sec: 396.44\n",
            "2020-02-16 19:08:55,824 epoch 7 - iter 60/156 - loss 0.02690607 - samples/sec: 406.61\n",
            "2020-02-16 19:08:57,076 epoch 7 - iter 75/156 - loss 0.02561295 - samples/sec: 419.56\n",
            "2020-02-16 19:08:58,290 epoch 7 - iter 90/156 - loss 0.03347512 - samples/sec: 433.69\n",
            "2020-02-16 19:08:59,621 epoch 7 - iter 105/156 - loss 0.03113460 - samples/sec: 407.37\n",
            "2020-02-16 19:09:00,898 epoch 7 - iter 120/156 - loss 0.03290806 - samples/sec: 418.90\n",
            "2020-02-16 19:09:02,285 epoch 7 - iter 135/156 - loss 0.03299803 - samples/sec: 382.27\n",
            "2020-02-16 19:09:03,693 epoch 7 - iter 150/156 - loss 0.03311366 - samples/sec: 378.74\n",
            "2020-02-16 19:09:04,276 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:04,277 EPOCH 7 done: loss 0.0321 - lr 0.3000\n",
            "2020-02-16 19:09:04,425 DEV : loss 0.044103119522333145 - score 0.9916\n",
            "Epoch     7: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 19:09:04,431 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 19:09:06,331 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:07,653 epoch 8 - iter 15/156 - loss 0.04951937 - samples/sec: 364.04\n",
            "2020-02-16 19:09:09,029 epoch 8 - iter 30/156 - loss 0.02591279 - samples/sec: 387.25\n",
            "2020-02-16 19:09:10,363 epoch 8 - iter 45/156 - loss 0.02534828 - samples/sec: 402.51\n",
            "2020-02-16 19:09:11,687 epoch 8 - iter 60/156 - loss 0.02005501 - samples/sec: 405.85\n",
            "2020-02-16 19:09:12,967 epoch 8 - iter 75/156 - loss 0.01944697 - samples/sec: 413.83\n",
            "2020-02-16 19:09:14,291 epoch 8 - iter 90/156 - loss 0.02313805 - samples/sec: 417.10\n",
            "2020-02-16 19:09:15,608 epoch 8 - iter 105/156 - loss 0.02052558 - samples/sec: 400.57\n",
            "2020-02-16 19:09:16,944 epoch 8 - iter 120/156 - loss 0.02085364 - samples/sec: 414.57\n",
            "2020-02-16 19:09:18,313 epoch 8 - iter 135/156 - loss 0.02030131 - samples/sec: 380.65\n",
            "2020-02-16 19:09:19,721 epoch 8 - iter 150/156 - loss 0.01855811 - samples/sec: 382.74\n",
            "2020-02-16 19:09:20,320 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:20,321 EPOCH 8 done: loss 0.0185 - lr 0.1500\n",
            "2020-02-16 19:09:20,462 DEV : loss 0.047690752893686295 - score 0.9916\n",
            "2020-02-16 19:09:20,469 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:09:22,384 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:23,712 epoch 9 - iter 15/156 - loss 0.01890123 - samples/sec: 364.03\n",
            "2020-02-16 19:09:25,057 epoch 9 - iter 30/156 - loss 0.01290269 - samples/sec: 388.89\n",
            "2020-02-16 19:09:26,376 epoch 9 - iter 45/156 - loss 0.01689272 - samples/sec: 403.10\n",
            "2020-02-16 19:09:27,681 epoch 9 - iter 60/156 - loss 0.01453174 - samples/sec: 410.10\n",
            "2020-02-16 19:09:28,952 epoch 9 - iter 75/156 - loss 0.01598409 - samples/sec: 413.05\n",
            "2020-02-16 19:09:30,204 epoch 9 - iter 90/156 - loss 0.02081463 - samples/sec: 422.06\n",
            "2020-02-16 19:09:31,516 epoch 9 - iter 105/156 - loss 0.01872166 - samples/sec: 406.15\n",
            "2020-02-16 19:09:32,798 epoch 9 - iter 120/156 - loss 0.01957005 - samples/sec: 418.26\n",
            "2020-02-16 19:09:34,173 epoch 9 - iter 135/156 - loss 0.01858358 - samples/sec: 378.52\n",
            "2020-02-16 19:09:35,562 epoch 9 - iter 150/156 - loss 0.01772357 - samples/sec: 382.08\n",
            "2020-02-16 19:09:36,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:36,173 EPOCH 9 done: loss 0.0175 - lr 0.1500\n",
            "2020-02-16 19:09:36,311 DEV : loss 0.03072626143693924 - score 0.9916\n",
            "2020-02-16 19:09:36,317 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:09:38,240 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:39,529 epoch 10 - iter 15/156 - loss 0.02704002 - samples/sec: 375.41\n",
            "2020-02-16 19:09:40,862 epoch 10 - iter 30/156 - loss 0.01535235 - samples/sec: 392.50\n",
            "2020-02-16 19:09:42,216 epoch 10 - iter 45/156 - loss 0.01684455 - samples/sec: 396.95\n",
            "2020-02-16 19:09:43,505 epoch 10 - iter 60/156 - loss 0.01365981 - samples/sec: 411.85\n",
            "2020-02-16 19:09:44,789 epoch 10 - iter 75/156 - loss 0.01309548 - samples/sec: 407.90\n",
            "2020-02-16 19:09:46,015 epoch 10 - iter 90/156 - loss 0.01814591 - samples/sec: 428.22\n",
            "2020-02-16 19:09:47,310 epoch 10 - iter 105/156 - loss 0.01675001 - samples/sec: 411.16\n",
            "2020-02-16 19:09:48,624 epoch 10 - iter 120/156 - loss 0.01716097 - samples/sec: 409.37\n",
            "2020-02-16 19:09:50,054 epoch 10 - iter 135/156 - loss 0.01681532 - samples/sec: 370.27\n",
            "2020-02-16 19:09:51,436 epoch 10 - iter 150/156 - loss 0.01543446 - samples/sec: 378.77\n",
            "2020-02-16 19:09:52,062 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:52,063 EPOCH 10 done: loss 0.0150 - lr 0.1500\n",
            "2020-02-16 19:09:52,215 DEV : loss 0.02611781470477581 - score 0.9916\n",
            "2020-02-16 19:09:52,223 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:09:54,182 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:09:54,185 Testing using best model ...\n",
            "2020-02-16 19:09:54,188 loading file corpus_splits/split_5/model/best-model.pt\n",
            "2020-02-16 19:09:58,315 0.9831\t0.9831\t0.9831\n",
            "2020-02-16 19:09:58,316 \n",
            "MICRO_AVG: acc 0.9667 - f1-score 0.9831\n",
            "MACRO_AVG: acc 0.9715 - f1-score 0.984325\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 8 - fp: 1 - fn: 2 - tn: 225 - precision: 0.8889 - recall: 0.8000 - accuracy: 0.7273 - f1-score: 0.8421\n",
            "Certificats,_lÃ©galisation_de_signature tp: 12 - fp: 1 - fn: 0 - tn: 223 - precision: 0.9231 - recall: 1.0000 - accuracy: 0.9231 - f1-score: 0.9600\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 8 - fp: 0 - fn: 1 - tn: 227 - precision: 1.0000 - recall: 0.8889 - accuracy: 0.8889 - f1-score: 0.9412\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 10 - fp: 2 - fn: 0 - tn: 224 - precision: 0.8333 - recall: 1.0000 - accuracy: 0.8333 - f1-score: 0.9091\n",
            "Enregistrement_de_PACS tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 17 - fp: 0 - fn: 1 - tn: 218 - precision: 1.0000 - recall: 0.9444 - accuracy: 0.9444 - f1-score: 0.9714\n",
            "Mariage    tp: 4 - fp: 0 - fn: 0 - tn: 232 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 12 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 7 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 16 - fp: 0 - fn: 0 - tn: 220 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 17 - fp: 0 - fn: 0 - tn: 219 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 13 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 13 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 19:09:58,321 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_6 ...\n",
            "2020-02-16 19:10:01,769 Reading data from corpus_splits/split_6\n",
            "2020-02-16 19:10:01,770 Train: corpus_splits/split_6/train.txt\n",
            "2020-02-16 19:10:01,771 Dev: corpus_splits/split_6/dev.txt\n",
            "2020-02-16 19:10:01,773 Test: corpus_splits/split_6/test.txt\n",
            "2020-02-16 19:10:02,674 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4966/4966 [00:00<00:00, 212323.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:10:02,702 [b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'Renseignements,_modification_de_dossier', b\"demandes_d'attestations_diverses\", b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'Recensement_des_jeunes', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'explication_r\\xc3\\xa9gularisation_des_charges', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'Enregistrement_de_PACS', b'Mariage', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'Livret_de_famille', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer']\n",
            "2020-02-16 19:10:02,719 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:10:02,722 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 19:10:02,722 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:10:02,723 Corpus: \"Corpus: 4966 train + 118 dev + 237 test sentences\"\n",
            "2020-02-16 19:10:02,724 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:10:02,725 Parameters:\n",
            "2020-02-16 19:10:02,726  - learning_rate: \"0.3\"\n",
            "2020-02-16 19:10:02,727  - mini_batch_size: \"32\"\n",
            "2020-02-16 19:10:02,728  - patience: \"5\"\n",
            "2020-02-16 19:10:02,729  - anneal_factor: \"0.5\"\n",
            "2020-02-16 19:10:02,730  - max_epochs: \"10\"\n",
            "2020-02-16 19:10:02,731  - shuffle: \"False\"\n",
            "2020-02-16 19:10:02,733  - train_with_dev: \"False\"\n",
            "2020-02-16 19:10:02,734  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 19:10:02,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:10:02,735 Model training base path: \"corpus_splits/split_6/model\"\n",
            "2020-02-16 19:10:02,736 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:10:02,738 Device: cuda:0\n",
            "2020-02-16 19:10:02,748 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:10:02,748 Embeddings storage mode: cpu\n",
            "2020-02-16 19:10:02,751 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:10:10,443 epoch 1 - iter 15/156 - loss 0.65915275 - samples/sec: 62.44\n",
            "2020-02-16 19:10:19,004 epoch 1 - iter 30/156 - loss 0.37332314 - samples/sec: 57.25\n",
            "2020-02-16 19:10:27,103 epoch 1 - iter 45/156 - loss 0.27575239 - samples/sec: 60.18\n",
            "2020-02-16 19:10:34,895 epoch 1 - iter 60/156 - loss 0.21951715 - samples/sec: 62.46\n",
            "2020-02-16 19:10:42,663 epoch 1 - iter 75/156 - loss 0.18796014 - samples/sec: 62.75\n",
            "2020-02-16 19:10:50,723 epoch 1 - iter 90/156 - loss 0.16661746 - samples/sec: 60.58\n",
            "2020-02-16 19:10:58,428 epoch 1 - iter 105/156 - loss 0.14692962 - samples/sec: 63.24\n",
            "2020-02-16 19:11:06,481 epoch 1 - iter 120/156 - loss 0.13174993 - samples/sec: 60.53\n",
            "2020-02-16 19:11:14,114 epoch 1 - iter 135/156 - loss 0.12225621 - samples/sec: 64.02\n",
            "2020-02-16 19:11:21,837 epoch 1 - iter 150/156 - loss 0.11249273 - samples/sec: 63.04\n",
            "2020-02-16 19:11:24,712 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:11:24,713 EPOCH 1 done: loss 0.1111 - lr 0.3000\n",
            "2020-02-16 19:11:26,496 DEV : loss 0.01553421188145876 - score 0.9915\n",
            "2020-02-16 19:11:26,505 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:11:28,328 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:11:29,558 epoch 2 - iter 15/156 - loss 0.03755181 - samples/sec: 392.23\n",
            "2020-02-16 19:11:30,971 epoch 2 - iter 30/156 - loss 0.02640540 - samples/sec: 369.60\n",
            "2020-02-16 19:11:32,400 epoch 2 - iter 45/156 - loss 0.02639070 - samples/sec: 362.38\n",
            "2020-02-16 19:11:33,753 epoch 2 - iter 60/156 - loss 0.02823475 - samples/sec: 399.74\n",
            "2020-02-16 19:11:35,097 epoch 2 - iter 75/156 - loss 0.03141103 - samples/sec: 393.06\n",
            "2020-02-16 19:11:36,374 epoch 2 - iter 90/156 - loss 0.03095508 - samples/sec: 418.53\n",
            "2020-02-16 19:11:37,665 epoch 2 - iter 105/156 - loss 0.03000671 - samples/sec: 416.40\n",
            "2020-02-16 19:11:38,997 epoch 2 - iter 120/156 - loss 0.02837898 - samples/sec: 399.44\n",
            "2020-02-16 19:11:40,215 epoch 2 - iter 135/156 - loss 0.02887435 - samples/sec: 441.79\n",
            "2020-02-16 19:11:41,465 epoch 2 - iter 150/156 - loss 0.02826270 - samples/sec: 419.34\n",
            "2020-02-16 19:11:42,051 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:11:42,052 EPOCH 2 done: loss 0.0308 - lr 0.3000\n",
            "2020-02-16 19:11:42,195 DEV : loss 0.014206254854798317 - score 0.9915\n",
            "2020-02-16 19:11:42,202 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:11:44,284 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:11:45,555 epoch 3 - iter 15/156 - loss 0.05079289 - samples/sec: 379.25\n",
            "2020-02-16 19:11:46,989 epoch 3 - iter 30/156 - loss 0.03455625 - samples/sec: 370.64\n",
            "2020-02-16 19:11:48,420 epoch 3 - iter 45/156 - loss 0.03737439 - samples/sec: 361.97\n",
            "2020-02-16 19:11:49,791 epoch 3 - iter 60/156 - loss 0.03412977 - samples/sec: 387.47\n",
            "2020-02-16 19:11:51,189 epoch 3 - iter 75/156 - loss 0.03684676 - samples/sec: 389.57\n",
            "2020-02-16 19:11:52,431 epoch 3 - iter 90/156 - loss 0.03692261 - samples/sec: 422.06\n",
            "2020-02-16 19:11:53,729 epoch 3 - iter 105/156 - loss 0.03432758 - samples/sec: 411.19\n",
            "2020-02-16 19:11:55,043 epoch 3 - iter 120/156 - loss 0.03220378 - samples/sec: 397.65\n",
            "2020-02-16 19:11:56,268 epoch 3 - iter 135/156 - loss 0.03396085 - samples/sec: 443.57\n",
            "2020-02-16 19:11:57,530 epoch 3 - iter 150/156 - loss 0.03254127 - samples/sec: 415.22\n",
            "2020-02-16 19:11:58,125 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:11:58,126 EPOCH 3 done: loss 0.0340 - lr 0.3000\n",
            "2020-02-16 19:11:58,266 DEV : loss 0.023000655695796013 - score 0.9915\n",
            "2020-02-16 19:11:58,272 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:12:00,366 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:01,646 epoch 4 - iter 15/156 - loss 0.04110619 - samples/sec: 376.87\n",
            "2020-02-16 19:12:03,060 epoch 4 - iter 30/156 - loss 0.03811946 - samples/sec: 372.93\n",
            "2020-02-16 19:12:04,478 epoch 4 - iter 45/156 - loss 0.03664145 - samples/sec: 366.66\n",
            "2020-02-16 19:12:05,822 epoch 4 - iter 60/156 - loss 0.03478493 - samples/sec: 395.96\n",
            "2020-02-16 19:12:07,182 epoch 4 - iter 75/156 - loss 0.03250199 - samples/sec: 391.30\n",
            "2020-02-16 19:12:08,441 epoch 4 - iter 90/156 - loss 0.03574178 - samples/sec: 425.24\n",
            "2020-02-16 19:12:09,677 epoch 4 - iter 105/156 - loss 0.03304038 - samples/sec: 424.46\n",
            "2020-02-16 19:12:10,984 epoch 4 - iter 120/156 - loss 0.02993666 - samples/sec: 403.71\n",
            "2020-02-16 19:12:12,202 epoch 4 - iter 135/156 - loss 0.03059949 - samples/sec: 442.81\n",
            "2020-02-16 19:12:13,476 epoch 4 - iter 150/156 - loss 0.03003091 - samples/sec: 410.90\n",
            "2020-02-16 19:12:14,069 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:14,070 EPOCH 4 done: loss 0.0311 - lr 0.3000\n",
            "2020-02-16 19:12:14,201 DEV : loss 0.004992768634110689 - score 1.0\n",
            "2020-02-16 19:12:14,207 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:12:16,098 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:17,346 epoch 5 - iter 15/156 - loss 0.03072779 - samples/sec: 385.37\n",
            "2020-02-16 19:12:18,812 epoch 5 - iter 30/156 - loss 0.01924732 - samples/sec: 360.31\n",
            "2020-02-16 19:12:20,285 epoch 5 - iter 45/156 - loss 0.02352290 - samples/sec: 363.08\n",
            "2020-02-16 19:12:21,659 epoch 5 - iter 60/156 - loss 0.02329709 - samples/sec: 390.65\n",
            "2020-02-16 19:12:23,002 epoch 5 - iter 75/156 - loss 0.02370013 - samples/sec: 396.23\n",
            "2020-02-16 19:12:24,246 epoch 5 - iter 90/156 - loss 0.02641564 - samples/sec: 422.17\n",
            "2020-02-16 19:12:25,506 epoch 5 - iter 105/156 - loss 0.02391173 - samples/sec: 420.11\n",
            "2020-02-16 19:12:26,835 epoch 5 - iter 120/156 - loss 0.02205317 - samples/sec: 400.79\n",
            "2020-02-16 19:12:28,072 epoch 5 - iter 135/156 - loss 0.02287894 - samples/sec: 437.94\n",
            "2020-02-16 19:12:29,388 epoch 5 - iter 150/156 - loss 0.02224747 - samples/sec: 406.16\n",
            "2020-02-16 19:12:29,990 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:29,991 EPOCH 5 done: loss 0.0236 - lr 0.3000\n",
            "2020-02-16 19:12:30,135 DEV : loss 0.01417649257928133 - score 0.9915\n",
            "2020-02-16 19:12:30,142 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:12:30,143 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:31,338 epoch 6 - iter 15/156 - loss 0.03168007 - samples/sec: 402.87\n",
            "2020-02-16 19:12:32,791 epoch 6 - iter 30/156 - loss 0.01740499 - samples/sec: 363.28\n",
            "2020-02-16 19:12:34,201 epoch 6 - iter 45/156 - loss 0.01938510 - samples/sec: 368.26\n",
            "2020-02-16 19:12:35,541 epoch 6 - iter 60/156 - loss 0.01994251 - samples/sec: 399.25\n",
            "2020-02-16 19:12:36,900 epoch 6 - iter 75/156 - loss 0.02290589 - samples/sec: 391.88\n",
            "2020-02-16 19:12:38,178 epoch 6 - iter 90/156 - loss 0.02278368 - samples/sec: 423.43\n",
            "2020-02-16 19:12:39,458 epoch 6 - iter 105/156 - loss 0.02304848 - samples/sec: 421.38\n",
            "2020-02-16 19:12:40,777 epoch 6 - iter 120/156 - loss 0.02269380 - samples/sec: 405.37\n",
            "2020-02-16 19:12:41,952 epoch 6 - iter 135/156 - loss 0.02309272 - samples/sec: 450.03\n",
            "2020-02-16 19:12:43,226 epoch 6 - iter 150/156 - loss 0.02296643 - samples/sec: 417.51\n",
            "2020-02-16 19:12:43,793 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:43,794 EPOCH 6 done: loss 0.0242 - lr 0.3000\n",
            "2020-02-16 19:12:43,933 DEV : loss 0.03127078711986542 - score 0.9915\n",
            "2020-02-16 19:12:43,939 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:12:43,940 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:45,119 epoch 7 - iter 15/156 - loss 0.04815369 - samples/sec: 408.03\n",
            "2020-02-16 19:12:46,515 epoch 7 - iter 30/156 - loss 0.03174344 - samples/sec: 372.92\n",
            "2020-02-16 19:12:47,930 epoch 7 - iter 45/156 - loss 0.03132942 - samples/sec: 367.23\n",
            "2020-02-16 19:12:49,269 epoch 7 - iter 60/156 - loss 0.03486010 - samples/sec: 396.26\n",
            "2020-02-16 19:12:50,676 epoch 7 - iter 75/156 - loss 0.03359082 - samples/sec: 389.55\n",
            "2020-02-16 19:12:51,942 epoch 7 - iter 90/156 - loss 0.03299723 - samples/sec: 422.98\n",
            "2020-02-16 19:12:53,203 epoch 7 - iter 105/156 - loss 0.03153659 - samples/sec: 419.11\n",
            "2020-02-16 19:12:54,540 epoch 7 - iter 120/156 - loss 0.02889464 - samples/sec: 399.09\n",
            "2020-02-16 19:12:55,775 epoch 7 - iter 135/156 - loss 0.03019991 - samples/sec: 436.25\n",
            "2020-02-16 19:12:57,038 epoch 7 - iter 150/156 - loss 0.03032210 - samples/sec: 414.93\n",
            "2020-02-16 19:12:57,607 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:57,611 EPOCH 7 done: loss 0.0315 - lr 0.3000\n",
            "2020-02-16 19:12:57,748 DEV : loss 0.03265196457505226 - score 0.9915\n",
            "2020-02-16 19:12:57,753 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:12:57,754 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:12:58,930 epoch 8 - iter 15/156 - loss 0.05068737 - samples/sec: 409.27\n",
            "2020-02-16 19:13:00,349 epoch 8 - iter 30/156 - loss 0.02702975 - samples/sec: 367.10\n",
            "2020-02-16 19:13:01,821 epoch 8 - iter 45/156 - loss 0.02370284 - samples/sec: 358.72\n",
            "2020-02-16 19:13:03,162 epoch 8 - iter 60/156 - loss 0.02960901 - samples/sec: 397.44\n",
            "2020-02-16 19:13:04,516 epoch 8 - iter 75/156 - loss 0.03202425 - samples/sec: 393.79\n",
            "2020-02-16 19:13:05,777 epoch 8 - iter 90/156 - loss 0.03204886 - samples/sec: 428.80\n",
            "2020-02-16 19:13:07,061 epoch 8 - iter 105/156 - loss 0.02954018 - samples/sec: 417.42\n",
            "2020-02-16 19:13:08,393 epoch 8 - iter 120/156 - loss 0.02743505 - samples/sec: 402.93\n",
            "2020-02-16 19:13:09,563 epoch 8 - iter 135/156 - loss 0.02878883 - samples/sec: 450.67\n",
            "2020-02-16 19:13:10,848 epoch 8 - iter 150/156 - loss 0.02788531 - samples/sec: 408.20\n",
            "2020-02-16 19:13:11,416 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:11,417 EPOCH 8 done: loss 0.0293 - lr 0.3000\n",
            "2020-02-16 19:13:11,557 DEV : loss 0.05227038264274597 - score 0.9831\n",
            "2020-02-16 19:13:11,561 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 19:13:11,562 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:12,759 epoch 9 - iter 15/156 - loss 0.04437576 - samples/sec: 402.06\n",
            "2020-02-16 19:13:14,169 epoch 9 - iter 30/156 - loss 0.02610112 - samples/sec: 369.74\n",
            "2020-02-16 19:13:15,625 epoch 9 - iter 45/156 - loss 0.02878321 - samples/sec: 358.78\n",
            "2020-02-16 19:13:16,953 epoch 9 - iter 60/156 - loss 0.02874546 - samples/sec: 403.17\n",
            "2020-02-16 19:13:18,281 epoch 9 - iter 75/156 - loss 0.02533481 - samples/sec: 397.10\n",
            "2020-02-16 19:13:19,564 epoch 9 - iter 90/156 - loss 0.02817202 - samples/sec: 424.84\n",
            "2020-02-16 19:13:20,855 epoch 9 - iter 105/156 - loss 0.02697367 - samples/sec: 417.81\n",
            "2020-02-16 19:13:22,226 epoch 9 - iter 120/156 - loss 0.02573642 - samples/sec: 397.37\n",
            "2020-02-16 19:13:23,465 epoch 9 - iter 135/156 - loss 0.02689765 - samples/sec: 438.76\n",
            "2020-02-16 19:13:24,732 epoch 9 - iter 150/156 - loss 0.02579733 - samples/sec: 413.48\n",
            "2020-02-16 19:13:25,310 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:25,311 EPOCH 9 done: loss 0.0276 - lr 0.3000\n",
            "2020-02-16 19:13:25,453 DEV : loss 0.006549546495079994 - score 1.0\n",
            "2020-02-16 19:13:25,457 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 19:13:27,317 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:28,562 epoch 10 - iter 15/156 - loss 0.06164904 - samples/sec: 387.15\n",
            "2020-02-16 19:13:30,012 epoch 10 - iter 30/156 - loss 0.03483179 - samples/sec: 365.53\n",
            "2020-02-16 19:13:31,475 epoch 10 - iter 45/156 - loss 0.03679535 - samples/sec: 358.71\n",
            "2020-02-16 19:13:32,855 epoch 10 - iter 60/156 - loss 0.03531330 - samples/sec: 388.19\n",
            "2020-02-16 19:13:34,161 epoch 10 - iter 75/156 - loss 0.03650457 - samples/sec: 400.27\n",
            "2020-02-16 19:13:35,440 epoch 10 - iter 90/156 - loss 0.03801923 - samples/sec: 418.34\n",
            "2020-02-16 19:13:36,726 epoch 10 - iter 105/156 - loss 0.03390456 - samples/sec: 415.45\n",
            "2020-02-16 19:13:38,017 epoch 10 - iter 120/156 - loss 0.03174414 - samples/sec: 406.31\n",
            "2020-02-16 19:13:39,190 epoch 10 - iter 135/156 - loss 0.03165859 - samples/sec: 451.10\n",
            "2020-02-16 19:13:40,475 epoch 10 - iter 150/156 - loss 0.03011691 - samples/sec: 410.14\n",
            "2020-02-16 19:13:41,076 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:41,077 EPOCH 10 done: loss 0.0312 - lr 0.3000\n",
            "2020-02-16 19:13:41,215 DEV : loss 0.00709887919947505 - score 1.0\n",
            "Epoch    10: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 19:13:41,223 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 19:13:43,064 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:43,065 Testing using best model ...\n",
            "2020-02-16 19:13:43,073 loading file corpus_splits/split_6/model/best-model.pt\n",
            "2020-02-16 19:13:47,179 0.9916\t0.9916\t0.9916\n",
            "2020-02-16 19:13:47,180 \n",
            "MICRO_AVG: acc 0.9833 - f1-score 0.9916\n",
            "MACRO_AVG: acc 0.9865 - f1-score 0.9927958333333334\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 11 - fp: 1 - fn: 1 - tn: 224 - precision: 0.9167 - recall: 0.9167 - accuracy: 0.8462 - f1-score: 0.9167\n",
            "Certificats,_lÃ©galisation_de_signature tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 9 - fp: 0 - fn: 1 - tn: 227 - precision: 1.0000 - recall: 0.9000 - accuracy: 0.9000 - f1-score: 0.9474\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 13 - fp: 1 - fn: 0 - tn: 223 - precision: 0.9286 - recall: 1.0000 - accuracy: 0.9286 - f1-score: 0.9630\n",
            "Enregistrement_de_PACS tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 14 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 12 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Mariage    tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 11 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 4 - fp: 0 - fn: 0 - tn: 233 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 17 - fp: 0 - fn: 0 - tn: 220 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 10 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 9 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 13 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 7 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 8 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 19:13:47,181 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_3 ...\n",
            "2020-02-16 19:13:50,809 Reading data from corpus_splits/split_3\n",
            "2020-02-16 19:13:50,810 Train: corpus_splits/split_3/train.txt\n",
            "2020-02-16 19:13:50,811 Dev: corpus_splits/split_3/dev.txt\n",
            "2020-02-16 19:13:50,812 Test: corpus_splits/split_3/test.txt\n",
            "2020-02-16 19:13:51,669 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4965/4965 [00:00<00:00, 204647.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:13:51,697 [b'Livret_de_famille', b'Mariage', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'explication_r\\xc3\\xa9gularisation_des_charges', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'Recensement_des_jeunes', b\"demandes_d'attestations_diverses\", b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'Renseignements,_modification_de_dossier', b'Enregistrement_de_PACS', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer']\n",
            "2020-02-16 19:13:51,714 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:51,717 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 19:13:51,718 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:51,719 Corpus: \"Corpus: 4965 train + 119 dev + 236 test sentences\"\n",
            "2020-02-16 19:13:51,720 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:51,721 Parameters:\n",
            "2020-02-16 19:13:51,722  - learning_rate: \"0.3\"\n",
            "2020-02-16 19:13:51,723  - mini_batch_size: \"32\"\n",
            "2020-02-16 19:13:51,724  - patience: \"5\"\n",
            "2020-02-16 19:13:51,725  - anneal_factor: \"0.5\"\n",
            "2020-02-16 19:13:51,726  - max_epochs: \"10\"\n",
            "2020-02-16 19:13:51,727  - shuffle: \"False\"\n",
            "2020-02-16 19:13:51,728  - train_with_dev: \"False\"\n",
            "2020-02-16 19:13:51,729  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 19:13:51,730 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:51,731 Model training base path: \"corpus_splits/split_3/model\"\n",
            "2020-02-16 19:13:51,732 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:51,733 Device: cuda:0\n",
            "2020-02-16 19:13:51,734 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:13:51,734 Embeddings storage mode: cpu\n",
            "2020-02-16 19:13:51,737 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:13:59,447 epoch 1 - iter 15/156 - loss 0.58097178 - samples/sec: 62.28\n",
            "2020-02-16 19:14:07,159 epoch 1 - iter 30/156 - loss 0.34241506 - samples/sec: 63.66\n",
            "2020-02-16 19:14:15,167 epoch 1 - iter 45/156 - loss 0.24537440 - samples/sec: 60.79\n",
            "2020-02-16 19:14:23,092 epoch 1 - iter 60/156 - loss 0.19720873 - samples/sec: 61.56\n",
            "2020-02-16 19:14:31,037 epoch 1 - iter 75/156 - loss 0.16584913 - samples/sec: 61.46\n",
            "2020-02-16 19:14:38,798 epoch 1 - iter 90/156 - loss 0.14680903 - samples/sec: 62.68\n",
            "2020-02-16 19:14:46,801 epoch 1 - iter 105/156 - loss 0.13320354 - samples/sec: 60.95\n",
            "2020-02-16 19:14:54,906 epoch 1 - iter 120/156 - loss 0.12452953 - samples/sec: 60.13\n",
            "2020-02-16 19:15:02,951 epoch 1 - iter 135/156 - loss 0.11296552 - samples/sec: 60.51\n",
            "2020-02-16 19:15:11,092 epoch 1 - iter 150/156 - loss 0.10313566 - samples/sec: 59.81\n",
            "2020-02-16 19:15:14,006 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:15:14,007 EPOCH 1 done: loss 0.0995 - lr 0.3000\n",
            "2020-02-16 19:15:15,814 DEV : loss 0.06254127621650696 - score 0.9916\n",
            "2020-02-16 19:15:15,819 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:15:17,684 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:15:18,922 epoch 2 - iter 15/156 - loss 0.03930311 - samples/sec: 389.99\n",
            "2020-02-16 19:15:20,260 epoch 2 - iter 30/156 - loss 0.04589201 - samples/sec: 398.50\n",
            "2020-02-16 19:15:21,570 epoch 2 - iter 45/156 - loss 0.03576117 - samples/sec: 399.09\n",
            "2020-02-16 19:15:22,872 epoch 2 - iter 60/156 - loss 0.03655283 - samples/sec: 403.94\n",
            "2020-02-16 19:15:24,149 epoch 2 - iter 75/156 - loss 0.03464320 - samples/sec: 410.54\n",
            "2020-02-16 19:15:25,443 epoch 2 - iter 90/156 - loss 0.03617235 - samples/sec: 408.34\n",
            "2020-02-16 19:15:26,771 epoch 2 - iter 105/156 - loss 0.03742713 - samples/sec: 401.68\n",
            "2020-02-16 19:15:28,032 epoch 2 - iter 120/156 - loss 0.04103781 - samples/sec: 415.58\n",
            "2020-02-16 19:15:29,347 epoch 2 - iter 135/156 - loss 0.03850287 - samples/sec: 400.24\n",
            "2020-02-16 19:15:30,661 epoch 2 - iter 150/156 - loss 0.03551226 - samples/sec: 406.48\n",
            "2020-02-16 19:15:31,166 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:15:31,168 EPOCH 2 done: loss 0.0343 - lr 0.3000\n",
            "2020-02-16 19:15:31,298 DEV : loss 0.05660727992653847 - score 0.9916\n",
            "2020-02-16 19:15:31,304 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:15:33,256 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:15:34,457 epoch 3 - iter 15/156 - loss 0.02054351 - samples/sec: 401.72\n",
            "2020-02-16 19:15:35,739 epoch 3 - iter 30/156 - loss 0.02996316 - samples/sec: 408.50\n",
            "2020-02-16 19:15:37,101 epoch 3 - iter 45/156 - loss 0.02609046 - samples/sec: 392.30\n",
            "2020-02-16 19:15:38,449 epoch 3 - iter 60/156 - loss 0.02422942 - samples/sec: 395.45\n",
            "2020-02-16 19:15:39,709 epoch 3 - iter 75/156 - loss 0.02714541 - samples/sec: 416.33\n",
            "2020-02-16 19:15:40,974 epoch 3 - iter 90/156 - loss 0.02924403 - samples/sec: 416.47\n",
            "2020-02-16 19:15:42,297 epoch 3 - iter 105/156 - loss 0.03059123 - samples/sec: 404.77\n",
            "2020-02-16 19:15:43,563 epoch 3 - iter 120/156 - loss 0.03062884 - samples/sec: 414.22\n",
            "2020-02-16 19:15:44,906 epoch 3 - iter 135/156 - loss 0.02955974 - samples/sec: 396.02\n",
            "2020-02-16 19:15:46,218 epoch 3 - iter 150/156 - loss 0.02817079 - samples/sec: 407.98\n",
            "2020-02-16 19:15:46,762 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:15:46,763 EPOCH 3 done: loss 0.0273 - lr 0.3000\n",
            "2020-02-16 19:15:46,887 DEV : loss 0.06077774986624718 - score 0.9916\n",
            "2020-02-16 19:15:46,892 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:15:48,815 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:15:50,095 epoch 4 - iter 15/156 - loss 0.02189900 - samples/sec: 379.48\n",
            "2020-02-16 19:15:51,404 epoch 4 - iter 30/156 - loss 0.02442629 - samples/sec: 400.57\n",
            "2020-02-16 19:15:52,779 epoch 4 - iter 45/156 - loss 0.02684856 - samples/sec: 386.61\n",
            "2020-02-16 19:15:54,129 epoch 4 - iter 60/156 - loss 0.03137543 - samples/sec: 395.46\n",
            "2020-02-16 19:15:55,393 epoch 4 - iter 75/156 - loss 0.02943531 - samples/sec: 421.46\n",
            "2020-02-16 19:15:56,640 epoch 4 - iter 90/156 - loss 0.03070423 - samples/sec: 421.40\n",
            "2020-02-16 19:15:57,941 epoch 4 - iter 105/156 - loss 0.03218701 - samples/sec: 402.11\n",
            "2020-02-16 19:15:59,258 epoch 4 - iter 120/156 - loss 0.03475972 - samples/sec: 408.15\n",
            "2020-02-16 19:16:00,628 epoch 4 - iter 135/156 - loss 0.03279495 - samples/sec: 393.30\n",
            "2020-02-16 19:16:01,894 epoch 4 - iter 150/156 - loss 0.03007067 - samples/sec: 413.85\n",
            "2020-02-16 19:16:02,410 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:02,413 EPOCH 4 done: loss 0.0291 - lr 0.3000\n",
            "2020-02-16 19:16:02,560 DEV : loss 0.07113117724657059 - score 0.9916\n",
            "2020-02-16 19:16:02,567 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:16:04,391 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:05,619 epoch 5 - iter 15/156 - loss 0.05130182 - samples/sec: 391.68\n",
            "2020-02-16 19:16:06,929 epoch 5 - iter 30/156 - loss 0.04280620 - samples/sec: 401.42\n",
            "2020-02-16 19:16:08,253 epoch 5 - iter 45/156 - loss 0.03434019 - samples/sec: 394.77\n",
            "2020-02-16 19:16:09,576 epoch 5 - iter 60/156 - loss 0.03277635 - samples/sec: 398.66\n",
            "2020-02-16 19:16:10,862 epoch 5 - iter 75/156 - loss 0.03160017 - samples/sec: 419.48\n",
            "2020-02-16 19:16:12,171 epoch 5 - iter 90/156 - loss 0.03279691 - samples/sec: 408.06\n",
            "2020-02-16 19:16:13,457 epoch 5 - iter 105/156 - loss 0.03437288 - samples/sec: 407.91\n",
            "2020-02-16 19:16:14,728 epoch 5 - iter 120/156 - loss 0.03646418 - samples/sec: 412.04\n",
            "2020-02-16 19:16:16,074 epoch 5 - iter 135/156 - loss 0.03555217 - samples/sec: 390.00\n",
            "2020-02-16 19:16:17,324 epoch 5 - iter 150/156 - loss 0.03438063 - samples/sec: 419.93\n",
            "2020-02-16 19:16:17,824 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:17,827 EPOCH 5 done: loss 0.0333 - lr 0.3000\n",
            "2020-02-16 19:16:17,959 DEV : loss 0.06264033168554306 - score 0.9916\n",
            "2020-02-16 19:16:17,965 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 19:16:19,883 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:21,134 epoch 6 - iter 15/156 - loss 0.03139773 - samples/sec: 385.96\n",
            "2020-02-16 19:16:22,443 epoch 6 - iter 30/156 - loss 0.02831947 - samples/sec: 404.46\n",
            "2020-02-16 19:16:23,789 epoch 6 - iter 45/156 - loss 0.02917902 - samples/sec: 395.76\n",
            "2020-02-16 19:16:25,144 epoch 6 - iter 60/156 - loss 0.02726349 - samples/sec: 396.63\n",
            "2020-02-16 19:16:26,402 epoch 6 - iter 75/156 - loss 0.02744831 - samples/sec: 417.14\n",
            "2020-02-16 19:16:27,689 epoch 6 - iter 90/156 - loss 0.03069898 - samples/sec: 415.55\n",
            "2020-02-16 19:16:28,976 epoch 6 - iter 105/156 - loss 0.03475134 - samples/sec: 410.42\n",
            "2020-02-16 19:16:30,296 epoch 6 - iter 120/156 - loss 0.03877640 - samples/sec: 407.12\n",
            "2020-02-16 19:16:31,637 epoch 6 - iter 135/156 - loss 0.03893241 - samples/sec: 399.18\n",
            "2020-02-16 19:16:32,950 epoch 6 - iter 150/156 - loss 0.03682087 - samples/sec: 406.82\n",
            "2020-02-16 19:16:33,471 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:33,472 EPOCH 6 done: loss 0.0359 - lr 0.3000\n",
            "2020-02-16 19:16:33,598 DEV : loss 0.040296413004398346 - score 0.9916\n",
            "2020-02-16 19:16:33,601 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 19:16:35,448 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:36,693 epoch 7 - iter 15/156 - loss 0.03559275 - samples/sec: 386.51\n",
            "2020-02-16 19:16:37,981 epoch 7 - iter 30/156 - loss 0.03486754 - samples/sec: 410.13\n",
            "2020-02-16 19:16:39,331 epoch 7 - iter 45/156 - loss 0.03054460 - samples/sec: 394.28\n",
            "2020-02-16 19:16:40,675 epoch 7 - iter 60/156 - loss 0.02764030 - samples/sec: 397.66\n",
            "2020-02-16 19:16:41,946 epoch 7 - iter 75/156 - loss 0.02827368 - samples/sec: 419.04\n",
            "2020-02-16 19:16:43,233 epoch 7 - iter 90/156 - loss 0.02939174 - samples/sec: 420.58\n",
            "2020-02-16 19:16:44,567 epoch 7 - iter 105/156 - loss 0.03204132 - samples/sec: 403.77\n",
            "2020-02-16 19:16:45,864 epoch 7 - iter 120/156 - loss 0.03465928 - samples/sec: 412.41\n",
            "2020-02-16 19:16:47,188 epoch 7 - iter 135/156 - loss 0.03322792 - samples/sec: 394.61\n",
            "2020-02-16 19:16:48,510 epoch 7 - iter 150/156 - loss 0.03027119 - samples/sec: 410.60\n",
            "2020-02-16 19:16:49,056 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:49,057 EPOCH 7 done: loss 0.0292 - lr 0.3000\n",
            "2020-02-16 19:16:49,182 DEV : loss 0.060465164482593536 - score 0.9832\n",
            "Epoch     7: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 19:16:49,188 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 19:16:49,189 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:16:50,376 epoch 8 - iter 15/156 - loss 0.03051386 - samples/sec: 405.72\n",
            "2020-02-16 19:16:51,702 epoch 8 - iter 30/156 - loss 0.03802661 - samples/sec: 404.01\n",
            "2020-02-16 19:16:53,058 epoch 8 - iter 45/156 - loss 0.03636552 - samples/sec: 390.20\n",
            "2020-02-16 19:16:54,363 epoch 8 - iter 60/156 - loss 0.03095417 - samples/sec: 401.08\n",
            "2020-02-16 19:16:55,657 epoch 8 - iter 75/156 - loss 0.02655591 - samples/sec: 418.01\n",
            "2020-02-16 19:16:56,934 epoch 8 - iter 90/156 - loss 0.02438634 - samples/sec: 410.59\n",
            "2020-02-16 19:16:58,249 epoch 8 - iter 105/156 - loss 0.02431409 - samples/sec: 405.16\n",
            "2020-02-16 19:16:59,570 epoch 8 - iter 120/156 - loss 0.02438907 - samples/sec: 405.34\n",
            "2020-02-16 19:17:00,934 epoch 8 - iter 135/156 - loss 0.02248143 - samples/sec: 390.03\n",
            "2020-02-16 19:17:02,179 epoch 8 - iter 150/156 - loss 0.02186928 - samples/sec: 421.23\n",
            "2020-02-16 19:17:02,727 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:02,728 EPOCH 8 done: loss 0.0211 - lr 0.1500\n",
            "2020-02-16 19:17:02,865 DEV : loss 0.031417056918144226 - score 0.9916\n",
            "2020-02-16 19:17:02,872 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:17:04,781 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:06,028 epoch 9 - iter 15/156 - loss 0.01372362 - samples/sec: 386.18\n",
            "2020-02-16 19:17:07,325 epoch 9 - iter 30/156 - loss 0.01727855 - samples/sec: 412.80\n",
            "2020-02-16 19:17:08,705 epoch 9 - iter 45/156 - loss 0.01917411 - samples/sec: 388.32\n",
            "2020-02-16 19:17:10,008 epoch 9 - iter 60/156 - loss 0.01571290 - samples/sec: 404.41\n",
            "2020-02-16 19:17:11,262 epoch 9 - iter 75/156 - loss 0.01763375 - samples/sec: 419.30\n",
            "2020-02-16 19:17:12,538 epoch 9 - iter 90/156 - loss 0.01793996 - samples/sec: 414.42\n",
            "2020-02-16 19:17:13,862 epoch 9 - iter 105/156 - loss 0.01759273 - samples/sec: 403.66\n",
            "2020-02-16 19:17:15,155 epoch 9 - iter 120/156 - loss 0.01812951 - samples/sec: 405.13\n",
            "2020-02-16 19:17:16,500 epoch 9 - iter 135/156 - loss 0.01713591 - samples/sec: 392.64\n",
            "2020-02-16 19:17:17,794 epoch 9 - iter 150/156 - loss 0.01604181 - samples/sec: 413.58\n",
            "2020-02-16 19:17:18,314 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:18,315 EPOCH 9 done: loss 0.0155 - lr 0.1500\n",
            "2020-02-16 19:17:18,458 DEV : loss 0.04400639235973358 - score 0.9916\n",
            "2020-02-16 19:17:18,462 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:17:20,363 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:21,628 epoch 10 - iter 15/156 - loss 0.01496108 - samples/sec: 380.46\n",
            "2020-02-16 19:17:22,946 epoch 10 - iter 30/156 - loss 0.01540477 - samples/sec: 405.37\n",
            "2020-02-16 19:17:25,603 epoch 10 - iter 60/156 - loss 0.02110197 - samples/sec: 400.00\n",
            "2020-02-16 19:17:26,882 epoch 10 - iter 75/156 - loss 0.02114808 - samples/sec: 420.20\n",
            "2020-02-16 19:17:28,174 epoch 10 - iter 90/156 - loss 0.02155584 - samples/sec: 413.62\n",
            "2020-02-16 19:17:29,480 epoch 10 - iter 105/156 - loss 0.02208549 - samples/sec: 406.41\n",
            "2020-02-16 19:17:30,773 epoch 10 - iter 120/156 - loss 0.02559977 - samples/sec: 404.87\n",
            "2020-02-16 19:17:32,080 epoch 10 - iter 135/156 - loss 0.02305675 - samples/sec: 399.42\n",
            "2020-02-16 19:17:33,392 epoch 10 - iter 150/156 - loss 0.02246921 - samples/sec: 406.38\n",
            "2020-02-16 19:17:33,896 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:33,897 EPOCH 10 done: loss 0.0218 - lr 0.1500\n",
            "2020-02-16 19:17:34,039 DEV : loss 0.028845446184277534 - score 0.9916\n",
            "2020-02-16 19:17:34,045 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:17:35,955 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:35,960 Testing using best model ...\n",
            "2020-02-16 19:17:35,966 loading file corpus_splits/split_3/model/best-model.pt\n",
            "2020-02-16 19:17:39,987 1.0\t1.0\t1.0\n",
            "2020-02-16 19:17:39,988 \n",
            "MICRO_AVG: acc 1.0 - f1-score 1.0\n",
            "MACRO_AVG: acc 1.0 - f1-score 1.0\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Certificats,_lÃ©galisation_de_signature tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 13 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 7 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Enregistrement_de_PACS tp: 14 - fp: 0 - fn: 0 - tn: 222 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 14 - fp: 0 - fn: 0 - tn: 222 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 7 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Mariage    tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 17 - fp: 0 - fn: 0 - tn: 219 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 7 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 17 - fp: 0 - fn: 0 - tn: 219 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 11 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 5 - fp: 0 - fn: 0 - tn: 231 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 12 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 14 - fp: 0 - fn: 0 - tn: 222 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 19:17:39,989 ----------------------------------------------------------------------------------------------------\n",
            "Processing split_2 ...\n",
            "2020-02-16 19:17:43,241 Reading data from corpus_splits/split_2\n",
            "2020-02-16 19:17:43,242 Train: corpus_splits/split_2/train.txt\n",
            "2020-02-16 19:17:43,242 Dev: corpus_splits/split_2/dev.txt\n",
            "2020-02-16 19:17:43,243 Test: corpus_splits/split_2/test.txt\n",
            "2020-02-16 19:17:44,119 Computing label dictionary. Progress:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4970/4970 [00:00<00:00, 251984.76it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:17:44,146 [b'Certificats,_l\\xc3\\xa9galisation_de_signature', b'Inscription_P\\xc3\\xa9riscolaire_(Cantine_et_Accueil)', b'contentieux_locataire_parti_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Inscription_sur_liste_\\xc3\\xa9lectorale', b'D\\xc3\\xa9claration_de_d\\xc3\\xa9c\\xc3\\xa8s', b'R\\xc3\\xa8glement_cantine_en_esp\\xc3\\xa8ces', b'Enregistrement_de_PACS', b'd\\xc3\\xa9compte_de_sortie_(locataire_quittant_OPHEOR)', b'PACS_(D\\xc3\\xa9p\\xc3\\xb4t_de_dossier,_modification_ou_dissolution_)', b'relance_amiable_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_RC', b'Recensement_des_jeunes', b'Mariage', b'Commande_ou_d\\xc3\\xa9commande_de_repas', b'Changement_de_pr\\xc3\\xa9noms,_rectification_d\\xe2\\x80\\x99actes', b'mise_en_place_contrat_pr\\xc3\\xa9l\\xc3\\xa8vement', b'explication_r\\xc3\\xa9gularisation_des_charges', b'Renseignements,_modification_de_dossier', b\"Premi\\xc3\\xa8re_Inscription_scolaire-changement_d'\\xc3\\xa9cole\", b'explication_avis_\\xc3\\xa9ch\\xc3\\xa9ance_loyer', b\"demandes_d'attestations_diverses\", b'Livret_de_famille', b'contentieux_locataire_pr\\xc3\\xa9sent_:_r\\xc3\\xa9f\\xc3\\xa9rence_courrier_re\\xc3\\xa7u_FC', b'Actes_de_naissance,_mariage,_d\\xc3\\xa9c\\xc3\\xa8s', b'D\\xc3\\xa9claration_de_naissance,_Reconnaissance']\n",
            "2020-02-16 19:17:44,164 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:44,168 Model: \"TextClassifier(\n",
            "  (document_embeddings): DocumentRNNEmbeddings(\n",
            "    (embeddings): StackedEmbeddings(\n",
            "      (list_embedding_0): CamembertEmbeddings(\n",
            "        (model): CamembertModel(\n",
            "          (embeddings): RobertaEmbeddings(\n",
            "            (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
            "            (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "            (token_type_embeddings): Embedding(1, 768)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (encoder): BertEncoder(\n",
            "            (layer): ModuleList(\n",
            "              (0): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (1): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (2): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (3): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (4): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (5): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (6): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (7): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (8): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (9): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (10): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (11): BertLayer(\n",
            "                (attention): BertAttention(\n",
            "                  (self): BertSelfAttention(\n",
            "                    (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                  (output): BertSelfOutput(\n",
            "                    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                    (dropout): Dropout(p=0.1, inplace=False)\n",
            "                  )\n",
            "                )\n",
            "                (intermediate): BertIntermediate(\n",
            "                  (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "                )\n",
            "                (output): BertOutput(\n",
            "                  (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "          (pooler): BertPooler(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (activation): Tanh()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (word_reprojection_map): Linear(in_features=3072, out_features=3072, bias=True)\n",
            "    (rnn): GRU(3072, 750, num_layers=2, batch_first=True, bidirectional=True)\n",
            "    (dropout): Dropout(p=0.4, inplace=False)\n",
            "    (word_dropout): WordDropout(p=0.1)\n",
            "  )\n",
            "  (decoder): Linear(in_features=3000, out_features=24, bias=True)\n",
            "  (loss_function): CrossEntropyLoss()\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2020-02-16 19:17:44,170 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:44,171 Corpus: \"Corpus: 4970 train + 118 dev + 236 test sentences\"\n",
            "2020-02-16 19:17:44,172 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:44,173 Parameters:\n",
            "2020-02-16 19:17:44,175  - learning_rate: \"0.3\"\n",
            "2020-02-16 19:17:44,176  - mini_batch_size: \"32\"\n",
            "2020-02-16 19:17:44,177  - patience: \"5\"\n",
            "2020-02-16 19:17:44,178  - anneal_factor: \"0.5\"\n",
            "2020-02-16 19:17:44,181  - max_epochs: \"10\"\n",
            "2020-02-16 19:17:44,182  - shuffle: \"False\"\n",
            "2020-02-16 19:17:44,183  - train_with_dev: \"False\"\n",
            "2020-02-16 19:17:44,185  - batch_growth_annealing: \"False\"\n",
            "2020-02-16 19:17:44,186 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:44,187 Model training base path: \"corpus_splits/split_2/model\"\n",
            "2020-02-16 19:17:44,189 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:44,190 Device: cuda:0\n",
            "2020-02-16 19:17:44,191 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:17:44,193 Embeddings storage mode: cpu\n",
            "2020-02-16 19:17:44,196 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-02-16 19:17:52,152 epoch 1 - iter 15/156 - loss 0.50575357 - samples/sec: 60.36\n",
            "2020-02-16 19:18:00,975 epoch 1 - iter 30/156 - loss 0.27881936 - samples/sec: 55.49\n",
            "2020-02-16 19:18:09,005 epoch 1 - iter 45/156 - loss 0.20843795 - samples/sec: 60.64\n",
            "2020-02-16 19:18:16,870 epoch 1 - iter 60/156 - loss 0.17055582 - samples/sec: 62.01\n",
            "2020-02-16 19:18:24,637 epoch 1 - iter 75/156 - loss 0.14397726 - samples/sec: 62.67\n",
            "2020-02-16 19:18:32,281 epoch 1 - iter 90/156 - loss 0.12824199 - samples/sec: 63.86\n",
            "2020-02-16 19:18:40,015 epoch 1 - iter 105/156 - loss 0.11617981 - samples/sec: 63.41\n",
            "2020-02-16 19:18:47,942 epoch 1 - iter 120/156 - loss 0.10323548 - samples/sec: 61.48\n",
            "2020-02-16 19:18:55,917 epoch 1 - iter 135/156 - loss 0.09271934 - samples/sec: 61.33\n",
            "2020-02-16 19:19:03,959 epoch 1 - iter 150/156 - loss 0.08664010 - samples/sec: 60.50\n",
            "2020-02-16 19:19:06,633 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:06,634 EPOCH 1 done: loss 0.0851 - lr 0.3000\n",
            "2020-02-16 19:19:08,436 DEV : loss 0.014533095993101597 - score 0.9915\n",
            "2020-02-16 19:19:08,440 BAD EPOCHS (no improvement): 0\n",
            "2020-02-16 19:19:10,207 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:11,392 epoch 2 - iter 15/156 - loss 0.01524821 - samples/sec: 406.18\n",
            "2020-02-16 19:19:12,822 epoch 2 - iter 30/156 - loss 0.02483541 - samples/sec: 372.66\n",
            "2020-02-16 19:19:14,270 epoch 2 - iter 45/156 - loss 0.03104936 - samples/sec: 366.96\n",
            "2020-02-16 19:19:15,524 epoch 2 - iter 60/156 - loss 0.03926380 - samples/sec: 420.12\n",
            "2020-02-16 19:19:16,845 epoch 2 - iter 75/156 - loss 0.03760730 - samples/sec: 415.72\n",
            "2020-02-16 19:19:18,100 epoch 2 - iter 90/156 - loss 0.03469819 - samples/sec: 421.54\n",
            "2020-02-16 19:19:19,409 epoch 2 - iter 105/156 - loss 0.03452218 - samples/sec: 409.67\n",
            "2020-02-16 19:19:20,727 epoch 2 - iter 120/156 - loss 0.03286397 - samples/sec: 406.25\n",
            "2020-02-16 19:19:22,057 epoch 2 - iter 135/156 - loss 0.03150998 - samples/sec: 399.74\n",
            "2020-02-16 19:19:23,366 epoch 2 - iter 150/156 - loss 0.03173267 - samples/sec: 399.56\n",
            "2020-02-16 19:19:23,917 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:23,918 EPOCH 2 done: loss 0.0327 - lr 0.3000\n",
            "2020-02-16 19:19:24,074 DEV : loss 0.025157105177640915 - score 0.9915\n",
            "2020-02-16 19:19:24,079 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:19:25,881 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:27,073 epoch 3 - iter 15/156 - loss 0.01317673 - samples/sec: 403.65\n",
            "2020-02-16 19:19:28,486 epoch 3 - iter 30/156 - loss 0.01681873 - samples/sec: 372.35\n",
            "2020-02-16 19:19:29,946 epoch 3 - iter 45/156 - loss 0.02629014 - samples/sec: 362.64\n",
            "2020-02-16 19:19:31,274 epoch 3 - iter 60/156 - loss 0.03404700 - samples/sec: 405.96\n",
            "2020-02-16 19:19:32,585 epoch 3 - iter 75/156 - loss 0.03253905 - samples/sec: 403.28\n",
            "2020-02-16 19:19:33,878 epoch 3 - iter 90/156 - loss 0.03082233 - samples/sec: 420.50\n",
            "2020-02-16 19:19:35,160 epoch 3 - iter 105/156 - loss 0.03665581 - samples/sec: 410.00\n",
            "2020-02-16 19:19:36,451 epoch 3 - iter 120/156 - loss 0.03342679 - samples/sec: 407.12\n",
            "2020-02-16 19:19:37,791 epoch 3 - iter 135/156 - loss 0.03028694 - samples/sec: 399.14\n",
            "2020-02-16 19:19:39,138 epoch 3 - iter 150/156 - loss 0.02888995 - samples/sec: 396.84\n",
            "2020-02-16 19:19:39,686 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:39,687 EPOCH 3 done: loss 0.0282 - lr 0.3000\n",
            "2020-02-16 19:19:39,848 DEV : loss 0.0420028492808342 - score 0.9831\n",
            "2020-02-16 19:19:39,855 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:19:39,856 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:40,979 epoch 4 - iter 15/156 - loss 0.01396500 - samples/sec: 428.73\n",
            "2020-02-16 19:19:42,434 epoch 4 - iter 30/156 - loss 0.03480406 - samples/sec: 366.09\n",
            "2020-02-16 19:19:43,826 epoch 4 - iter 45/156 - loss 0.03746381 - samples/sec: 374.40\n",
            "2020-02-16 19:19:45,120 epoch 4 - iter 60/156 - loss 0.04087302 - samples/sec: 414.06\n",
            "2020-02-16 19:19:46,433 epoch 4 - iter 75/156 - loss 0.03891723 - samples/sec: 410.28\n",
            "2020-02-16 19:19:47,728 epoch 4 - iter 90/156 - loss 0.03858805 - samples/sec: 415.34\n",
            "2020-02-16 19:19:49,044 epoch 4 - iter 105/156 - loss 0.03745148 - samples/sec: 405.85\n",
            "2020-02-16 19:19:50,377 epoch 4 - iter 120/156 - loss 0.03467530 - samples/sec: 395.68\n",
            "2020-02-16 19:19:51,722 epoch 4 - iter 135/156 - loss 0.03156112 - samples/sec: 397.70\n",
            "2020-02-16 19:19:53,035 epoch 4 - iter 150/156 - loss 0.03045427 - samples/sec: 399.82\n",
            "2020-02-16 19:19:53,594 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:53,595 EPOCH 4 done: loss 0.0306 - lr 0.3000\n",
            "2020-02-16 19:19:53,750 DEV : loss 0.03640308603644371 - score 0.9831\n",
            "2020-02-16 19:19:53,757 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:19:53,757 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:19:54,888 epoch 5 - iter 15/156 - loss 0.00763747 - samples/sec: 425.42\n",
            "2020-02-16 19:19:56,283 epoch 5 - iter 30/156 - loss 0.01418940 - samples/sec: 372.68\n",
            "2020-02-16 19:19:57,718 epoch 5 - iter 45/156 - loss 0.02536913 - samples/sec: 364.38\n",
            "2020-02-16 19:19:59,024 epoch 5 - iter 60/156 - loss 0.03012287 - samples/sec: 410.57\n",
            "2020-02-16 19:20:00,309 epoch 5 - iter 75/156 - loss 0.02829899 - samples/sec: 408.03\n",
            "2020-02-16 19:20:01,550 epoch 5 - iter 90/156 - loss 0.02839307 - samples/sec: 424.11\n",
            "2020-02-16 19:20:02,823 epoch 5 - iter 105/156 - loss 0.03185628 - samples/sec: 414.83\n",
            "2020-02-16 19:20:04,122 epoch 5 - iter 120/156 - loss 0.02962227 - samples/sec: 412.35\n",
            "2020-02-16 19:20:05,473 epoch 5 - iter 135/156 - loss 0.02724871 - samples/sec: 397.91\n",
            "2020-02-16 19:20:06,838 epoch 5 - iter 150/156 - loss 0.02687174 - samples/sec: 390.71\n",
            "2020-02-16 19:20:07,416 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:07,417 EPOCH 5 done: loss 0.0274 - lr 0.3000\n",
            "2020-02-16 19:20:07,573 DEV : loss 0.036293815821409225 - score 0.9831\n",
            "2020-02-16 19:20:07,579 BAD EPOCHS (no improvement): 4\n",
            "2020-02-16 19:20:07,580 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:08,698 epoch 6 - iter 15/156 - loss 0.05787386 - samples/sec: 430.36\n",
            "2020-02-16 19:20:10,100 epoch 6 - iter 30/156 - loss 0.04399240 - samples/sec: 375.15\n",
            "2020-02-16 19:20:11,548 epoch 6 - iter 45/156 - loss 0.04543577 - samples/sec: 362.68\n",
            "2020-02-16 19:20:12,858 epoch 6 - iter 60/156 - loss 0.04746676 - samples/sec: 408.46\n",
            "2020-02-16 19:20:14,166 epoch 6 - iter 75/156 - loss 0.04374836 - samples/sec: 409.44\n",
            "2020-02-16 19:20:15,431 epoch 6 - iter 90/156 - loss 0.04428639 - samples/sec: 414.95\n",
            "2020-02-16 19:20:16,780 epoch 6 - iter 105/156 - loss 0.04347256 - samples/sec: 406.77\n",
            "2020-02-16 19:20:18,102 epoch 6 - iter 120/156 - loss 0.03958223 - samples/sec: 409.28\n",
            "2020-02-16 19:20:19,428 epoch 6 - iter 135/156 - loss 0.03612231 - samples/sec: 398.64\n",
            "2020-02-16 19:20:20,792 epoch 6 - iter 150/156 - loss 0.03392241 - samples/sec: 391.60\n",
            "2020-02-16 19:20:21,400 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:21,400 EPOCH 6 done: loss 0.0334 - lr 0.3000\n",
            "2020-02-16 19:20:21,540 DEV : loss 0.017329469323158264 - score 0.9915\n",
            "2020-02-16 19:20:21,546 BAD EPOCHS (no improvement): 5\n",
            "2020-02-16 19:20:23,432 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:24,624 epoch 7 - iter 15/156 - loss 0.00460490 - samples/sec: 403.99\n",
            "2020-02-16 19:20:26,060 epoch 7 - iter 30/156 - loss 0.01591766 - samples/sec: 371.04\n",
            "2020-02-16 19:20:27,508 epoch 7 - iter 45/156 - loss 0.02778375 - samples/sec: 364.80\n",
            "2020-02-16 19:20:28,799 epoch 7 - iter 60/156 - loss 0.02720572 - samples/sec: 415.63\n",
            "2020-02-16 19:20:30,060 epoch 7 - iter 75/156 - loss 0.02738353 - samples/sec: 416.11\n",
            "2020-02-16 19:20:31,311 epoch 7 - iter 90/156 - loss 0.03090558 - samples/sec: 419.85\n",
            "2020-02-16 19:20:32,628 epoch 7 - iter 105/156 - loss 0.03105140 - samples/sec: 405.31\n",
            "2020-02-16 19:20:33,923 epoch 7 - iter 120/156 - loss 0.02872964 - samples/sec: 413.10\n",
            "2020-02-16 19:20:35,201 epoch 7 - iter 135/156 - loss 0.02696497 - samples/sec: 410.48\n",
            "2020-02-16 19:20:36,562 epoch 7 - iter 150/156 - loss 0.02638909 - samples/sec: 393.89\n",
            "2020-02-16 19:20:37,143 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:37,144 EPOCH 7 done: loss 0.0280 - lr 0.3000\n",
            "2020-02-16 19:20:37,285 DEV : loss 0.03984193131327629 - score 0.9831\n",
            "Epoch     7: reducing learning rate of group 0 to 1.5000e-01.\n",
            "2020-02-16 19:20:37,292 BAD EPOCHS (no improvement): 6\n",
            "2020-02-16 19:20:37,292 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:38,411 epoch 8 - iter 15/156 - loss 0.02189228 - samples/sec: 430.84\n",
            "2020-02-16 19:20:39,787 epoch 8 - iter 30/156 - loss 0.02110714 - samples/sec: 378.47\n",
            "2020-02-16 19:20:41,188 epoch 8 - iter 45/156 - loss 0.03123721 - samples/sec: 370.63\n",
            "2020-02-16 19:20:42,477 epoch 8 - iter 60/156 - loss 0.02485502 - samples/sec: 416.17\n",
            "2020-02-16 19:20:43,741 epoch 8 - iter 75/156 - loss 0.02329234 - samples/sec: 415.09\n",
            "2020-02-16 19:20:45,030 epoch 8 - iter 90/156 - loss 0.02265930 - samples/sec: 415.25\n",
            "2020-02-16 19:20:46,304 epoch 8 - iter 105/156 - loss 0.02141558 - samples/sec: 412.42\n",
            "2020-02-16 19:20:47,641 epoch 8 - iter 120/156 - loss 0.01926829 - samples/sec: 398.16\n",
            "2020-02-16 19:20:48,954 epoch 8 - iter 135/156 - loss 0.01852963 - samples/sec: 405.60\n",
            "2020-02-16 19:20:50,313 epoch 8 - iter 150/156 - loss 0.01801643 - samples/sec: 388.71\n",
            "2020-02-16 19:20:50,911 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:50,912 EPOCH 8 done: loss 0.0176 - lr 0.1500\n",
            "2020-02-16 19:20:51,071 DEV : loss 0.028066392987966537 - score 0.9915\n",
            "2020-02-16 19:20:51,074 BAD EPOCHS (no improvement): 1\n",
            "2020-02-16 19:20:53,046 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:20:54,239 epoch 9 - iter 15/156 - loss 0.01059357 - samples/sec: 403.61\n",
            "2020-02-16 19:20:55,643 epoch 9 - iter 30/156 - loss 0.01913452 - samples/sec: 370.26\n",
            "2020-02-16 19:20:57,077 epoch 9 - iter 45/156 - loss 0.02224456 - samples/sec: 370.61\n",
            "2020-02-16 19:20:58,319 epoch 9 - iter 60/156 - loss 0.01892031 - samples/sec: 422.43\n",
            "2020-02-16 19:20:59,585 epoch 9 - iter 75/156 - loss 0.01905811 - samples/sec: 414.13\n",
            "2020-02-16 19:21:00,883 epoch 9 - iter 90/156 - loss 0.01919881 - samples/sec: 411.96\n",
            "2020-02-16 19:21:02,182 epoch 9 - iter 105/156 - loss 0.01994449 - samples/sec: 411.80\n",
            "2020-02-16 19:21:03,508 epoch 9 - iter 120/156 - loss 0.01819014 - samples/sec: 404.31\n",
            "2020-02-16 19:21:04,826 epoch 9 - iter 135/156 - loss 0.01690520 - samples/sec: 405.17\n",
            "2020-02-16 19:21:06,139 epoch 9 - iter 150/156 - loss 0.01604815 - samples/sec: 398.40\n",
            "2020-02-16 19:21:06,691 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:21:06,692 EPOCH 9 done: loss 0.0165 - lr 0.1500\n",
            "2020-02-16 19:21:06,839 DEV : loss 0.02661437727510929 - score 0.9915\n",
            "2020-02-16 19:21:06,845 BAD EPOCHS (no improvement): 2\n",
            "2020-02-16 19:21:08,767 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:21:09,966 epoch 10 - iter 15/156 - loss 0.01279153 - samples/sec: 401.52\n",
            "2020-02-16 19:21:11,389 epoch 10 - iter 30/156 - loss 0.01505672 - samples/sec: 372.60\n",
            "2020-02-16 19:21:12,853 epoch 10 - iter 45/156 - loss 0.02324294 - samples/sec: 361.83\n",
            "2020-02-16 19:21:14,199 epoch 10 - iter 60/156 - loss 0.02271942 - samples/sec: 404.83\n",
            "2020-02-16 19:21:15,471 epoch 10 - iter 75/156 - loss 0.02359622 - samples/sec: 412.25\n",
            "2020-02-16 19:21:16,818 epoch 10 - iter 90/156 - loss 0.02239502 - samples/sec: 409.44\n",
            "2020-02-16 19:21:18,107 epoch 10 - iter 105/156 - loss 0.02070431 - samples/sec: 416.95\n",
            "2020-02-16 19:21:19,450 epoch 10 - iter 120/156 - loss 0.01899181 - samples/sec: 398.75\n",
            "2020-02-16 19:21:20,793 epoch 10 - iter 135/156 - loss 0.01748408 - samples/sec: 397.54\n",
            "2020-02-16 19:21:22,140 epoch 10 - iter 150/156 - loss 0.01714067 - samples/sec: 400.72\n",
            "2020-02-16 19:21:22,722 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:21:22,723 EPOCH 10 done: loss 0.0179 - lr 0.1500\n",
            "2020-02-16 19:21:22,870 DEV : loss 0.025420300662517548 - score 0.9915\n",
            "2020-02-16 19:21:22,876 BAD EPOCHS (no improvement): 3\n",
            "2020-02-16 19:21:24,842 ----------------------------------------------------------------------------------------------------\n",
            "2020-02-16 19:21:24,843 Testing using best model ...\n",
            "2020-02-16 19:21:24,846 loading file corpus_splits/split_2/model/best-model.pt\n",
            "2020-02-16 19:21:29,046 0.9915\t0.9915\t0.9915\n",
            "2020-02-16 19:21:29,047 \n",
            "MICRO_AVG: acc 0.9832 - f1-score 0.9915\n",
            "MACRO_AVG: acc 0.9868 - f1-score 0.9931291666666667\n",
            "Actes_de_naissance,_mariage,_dÃ©cÃ¨s tp: 16 - fp: 1 - fn: 0 - tn: 219 - precision: 0.9412 - recall: 1.0000 - accuracy: 0.9412 - f1-score: 0.9697\n",
            "Certificats,_lÃ©galisation_de_signature tp: 8 - fp: 0 - fn: 1 - tn: 227 - precision: 1.0000 - recall: 0.8889 - accuracy: 0.8889 - f1-score: 0.9412\n",
            "Changement_de_prÃ©noms,_rectification_dâ€™actes tp: 12 - fp: 0 - fn: 0 - tn: 224 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Commande_ou_dÃ©commande_de_repas tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_dÃ©cÃ¨s tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "DÃ©claration_de_naissance,_Reconnaissance tp: 11 - fp: 1 - fn: 0 - tn: 224 - precision: 0.9167 - recall: 1.0000 - accuracy: 0.9167 - f1-score: 0.9565\n",
            "Enregistrement_de_PACS tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_PÃ©riscolaire_(Cantine_et_Accueil) tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Inscription_sur_liste_Ã©lectorale tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Livret_de_famille tp: 15 - fp: 0 - fn: 1 - tn: 220 - precision: 1.0000 - recall: 0.9375 - accuracy: 0.9375 - f1-score: 0.9677\n",
            "Mariage    tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PACS_(DÃ©pÃ´t_de_dossier,_modification_ou_dissolution_) tp: 11 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "PremiÃ¨re_Inscription_scolaire-changement_d'Ã©cole tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Recensement_des_jeunes tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "Renseignements,_modification_de_dossier tp: 11 - fp: 0 - fn: 0 - tn: 225 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "RÃ¨glement_cantine_en_espÃ¨ces tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_parti_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 7 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "contentieux_locataire_prÃ©sent_:_rÃ©fÃ©rence_courrier_reÃ§u_FC tp: 6 - fp: 0 - fn: 0 - tn: 230 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "demandes_d'attestations_diverses tp: 8 - fp: 0 - fn: 0 - tn: 228 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "dÃ©compte_de_sortie_(locataire_quittant_OPHEOR) tp: 7 - fp: 0 - fn: 0 - tn: 229 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_avis_Ã©chÃ©ance_loyer tp: 13 - fp: 0 - fn: 0 - tn: 223 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "explication_rÃ©gularisation_des_charges tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "mise_en_place_contrat_prÃ©lÃ¨vement tp: 9 - fp: 0 - fn: 0 - tn: 227 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "relance_amiable_:_rÃ©fÃ©rence_courrier_reÃ§u_RC tp: 10 - fp: 0 - fn: 0 - tn: 226 - precision: 1.0000 - recall: 1.0000 - accuracy: 1.0000 - f1-score: 1.0000\n",
            "2020-02-16 19:21:29,049 ----------------------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgFwHfdiHYLT",
        "colab_type": "code",
        "outputId": "df9149a2-9e38-468f-fff9-088f1eeec0a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "accuracies = []\n",
        "f1s = []\n",
        "for split in results:\n",
        "    accuracies.append(split['test_score'])\n",
        "    f1s.append(split['test_f1'])\n",
        "\n",
        "print(\"| {:.3f} +- {:.3f} | {:.3f} +- {:.3f} |\".format(float(np.mean(accuracies)), float(np.std(accuracies)), float(np.mean(f1s)), float(np.std(f1s))))\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| 0.988 +- 0.015 | 0.988 +- 0.015 |\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}